---
title: "Blog 2"
date: 
weight: 1
chapter: false
pre: " <b> 3.2. </b> "
---



# Thúc đẩy việc ứng dụng AI ở quy mô lớn thông qua khung quản lý rủi ro doanh nghiệp – Phần 2

Trong Phần 1 của loạt bài này, chúng ta đã khám phá các rủi ro cơ bản và các yếu tố cần cân nhắc trong quản trị. Trong phần này, chúng ta sẽ xem xét các chiến lược thực tiễn để điều chỉnh Enterprise Risk Management Framework (ERMF) của doanh nghiệp, nhằm khai thác sức mạnh của Generative AI trong khi vẫn duy trì các biện pháp kiểm soát chặt chẽ.

Phần này bao gồm:

* Điều chỉnh ERMF cho môi trường cloud
* Điều chỉnh ERMF cho generative AI
* Quản lý rủi ro bền vững

Kết thúc bài viết này, bạn sẽ có một lộ trình để mở rộng việc ứng dụng generative AI một cách an toàn và có trách nhiệm.

---

## Điều chỉnh ERMF cho môi trường Cloud

Trước khi đi sâu vào các biện pháp kiểm soát cụ thể cho generative AI, điều quan trọng là phải hiểu hạ tầng cơ bản tạo điều kiện cho các công nghệ này. Cloud computing chính là nền tảng hạ tầng đã giúp generative AI trở nên khả thi và có thể mở rộng. Việc phát triển và triển khai large language models và các hệ thống generative AI khác đòi hỏi nguồn tài nguyên tính toán khổng lồ, dung lượng lưu trữ dữ liệu lớn, và khả năng xử lý phân tán tinh vi — tất cả đều được cloud systems cung cấp hiệu quả.

Công nghệ cloud khác với các giải pháp on-premises IT, và mối quan hệ giữa các tổ chức tài chính với cloud service providers cũng khác với mối quan hệ truyền thống với outsourcing providers.

Những khác biệt này làm thay đổi bản chất của nhiều rủi ro mà các tổ chức tài chính phải đối mặt cũng như cách họ quản lý rủi ro. Tuy nhiên, nếu được triển khai đúng cách, cloud technology có thể giảm thiểu rủi ro và đồng thời cung cấp các công cụ giúp Chief Risk Officers (CROs) quản lý rủi ro tốt hơn.

Bạn có thể đọc thêm về cách ERMF cần thay đổi để phù hợp với việc ứng dụng cloud ở quy mô lớn trong bài viết Is your Enterprise Risk Management Framework ready for the Cloud?

---

## Điều chỉnh ERMF cho Generative AI

Các tổ chức đang áp dụng generative AI có thể sử dụng ERMF của mình để khai thác giá trị kinh doanh trong khi vẫn duy trì các biện pháp kiểm soát phù hợp. Cách tiếp cận này cho phép doanh nghiệp xây dựng dựa trên các quy trình quản lý rủi ro hiện có, đồng thời xử lý các đặc thù riêng của generative AI.
Đối với phương pháp tiếp cận có cấu trúc nhằm chuyển đổi AI dựa trên cloud, AWS Cloud Adoption Framework for AI, ML, and generative AI (AWS CAF for AI) cung cấp hướng dẫn triển khai chi tiết phù hợp với các nguyên tắc của quản lý rủi ro doanh nghiệp. Để có hướng dẫn cụ thể hơn, hãy xem AWS User Guide to Governance, Risk and Compliance for Responsible AI Adoption within Financial Services Industries, có sẵn trong AWS Artifact khi bạn đăng nhập AWS account. AWS Artifact cung cấp các báo cáo bảo mật và tuân thủ của AWS, giúp tổ chức duy trì tuân thủ thông qua best practices.
Đối với quản lý mô hình và vòng đời hệ thống AI, khách hàng có thể tham khảo ISO42001 AI Management, Section A6. Phần này bao gồm việc xác định mục tiêu và quy trình cho thiết kế, phát triển AI có trách nhiệm, bao gồm tiêu chí và yêu cầu cho từng giai đoạn của vòng đời hệ thống AI. Hướng dẫn này giúp tổ chức đảm bảo rằng các thực hành quản lý mô hình của họ phù hợp với tiêu chuẩn ngành về phát triển Responsible AI.
Từ góc nhìn của nhà lãnh đạo doanh nghiệp, việc tích hợp các yếu tố generative AI vào ERMF giúp thiết lập các good practices được ghi nhận, triển khai các biện pháp kiểm soát hiệu quả và duy trì tính minh bạch trong toàn doanh nghiệp. Điều này vừa thúc đẩy đổi mới có trách nhiệm vừa đảm bảo quản lý rủi ro thận trọng. Dưới đây là cách các tổ chức đang tiếp cận vấn đề này:

---

## Cơ sở chính sách và quản trị Generative AI trong ERMF
Trong lĩnh vực generative AI, các tổ chức thiết lập cả guardrails cho đổi mới và accountability rõ ràng cho quản lý rủi ro. Three lines of defense model cung cấp cấu trúc để triển khai những yếu tố nền tảng này:

* Khung sử dụng hợp lý cho tổ chức: Định hướng rõ ràng về việc sử dụng generative AI giúp quản lý rủi ro trong khi vẫn khuyến khích đổi mới. Phạm vi ứng dụng của generative AI rất rộng và sẽ tiếp tục mở rộng, nên việc có hướng dẫn cụ thể về những ứng dụng được phép và trong điều kiện nào là điều thiết yếu. Khi các tổ chức khám phá cơ hội này, khung đó có thể phát triển theo mức độ kinh nghiệm và trưởng thành của họ.
* Trách nhiệm quản lý rủi ro: Vòng đời của Generative AI — từ việc lựa chọn use case, triển khai, cho đến giám sát liên tục — đòi hỏi phải có sự sở hữu rõ ràng giữa các bộ phận kinh doanh và các chức năng kiểm soát. Mặc dù tổ chức có thể thiết lập các cơ chế giám sát riêng cho Generative AI, nhưng những cơ chế này nên được tích hợp vào cấu trúc quản trị hiện có. Các báo cáo rủi ro và trách nhiệm giải trình liên quan đến các sáng kiến Generative AI cần được chuyển qua các ủy ban rủi ro doanh nghiệp (enterprise risk committees) và hội đồng quản trị rủi ro (governance boards) hiện hành, giúp đảm bảo quản lý rủi ro nhất quán trên toàn tổ chức, thay vì tạo ra các khu vực giám sát rời rạc.

---

## Cách triển khai Generative AI: Đưa nguyên tắc vào thực tiễn

Dựa trên three lines of defense model, các tổ chức có thể điều chỉnh thực hành quản lý rủi ro để đáp ứng các đặc điểm riêng của generative AI, đồng thời sử dụng industry best practices và frameworks hiện có. Điều này thường bao gồm việc phát triển thêm các biện pháp kiểm soát sẵn có và bổ sung các biện pháp mới dành riêng cho generative AI. Các dịch vụ của AWS tích hợp sẵn các năng lực hỗ trợ cho các yêu cầu về governance, risk management, và compliance, giúp tổ chức triển khai generative AI một cách có kiểm soát và có trách nhiệm — ví dụ như  Amazon Bedrock Guardrails, cùng nhiều dịch vụ khác.

Dựa trên các khu vực rủi ro đã được xác định trước đó, chúng ta sẽ khám phá cách các tổ chức có thể triển khai controls cho từng khu vực. Với mỗi khu vực, bài viết mô tả nguyên tắc và các yếu tố cần xem xét khi triển khai thực tế.Mặc dù mức độ ưu tiên có thể khác nhau tùy theo use case và risk appetite, nhưng tổng thể, chúng hình thành nên một framework cho việc ứng dụng generative AI có trách nhiệm thông qua ERMF.

Trong khi bài viết tập trung vào các nguyên tắc kiểm soát ở cấp cao, các nhóm kỹ thuật có thể tham khảo AWS Well-Architected Framework – Generative AI Lens để có hướng dẫn chi tiết về kiến trúc hỗ trợ các mục tiêu quản trị này.

---

## Công bằng

Hệ thống Generative AI có thể mang lại kết quả công bằng giữa các nhóm bên liên quan khác nhau, giúp tổ chức xây dựng niềm tin và đáp ứng kỳ vọng. Các tổ chức có thể hỗ trợ điều này bằng cách thiết lập các chỉ số công bằng rõ ràng cho từng use case cụ thể, đánh giá thường xuyên dữ liệu huấn luyện để phát hiện thiên vị, và giám sát hiệu suất giữa các nhóm người dùng khác nhau. Đối với các ứng dụng có mức độ ảnh hưởng cao, việc bổ sung kiểm tra bổ sung giúp đảm bảo đối xử công bằng giữa các nhóm dân cư đa dạng.

Amazon Bedrock Guardrails cung cấp các biện pháp bảo vệ có thể cấu hình để duy trì kết quả đầu ra công bằng và không thiên vị, cùng với các ngưỡng tùy chỉnh phù hợp với yêu cầu của từng use case. Amazon Bedrock còn cung cấp các công cụ đánh giá mô hình toàn diện, bao gồm model card chứa các chỉ số thiên vị chi tiết, giúp đánh giá thiên vị theo các nhóm nhân khẩu học. Ngoài ra, Bedrock bao gồm bộ dữ liệu prompt sẵn có như Bias in Open-ended Language Generation Dataset (BOLD), cho phép tự động đánh giá công bằng trong các lĩnh vực như nghề nghiệp, giới tính, chủng tộc và hệ tư tưởng. Những khả năng này tích hợp với Amazon SageMaker Clarify để hỗ trợ phát hiện và giảm thiểu thiên vị, với các chỉ số và báo cáo tích hợp sẵn.

---

## Giải thích

Hệ thống Generative AI cần cung cấp khả năng giải thích quy trình ra quyết định, nhằm đảm bảo trách nhiệm giải trình và giám sát hiệu quả. Tính giải thích là yếu tố thiết yếu trong mọi hệ thống Generative AI — dù được tùy chỉnh riêng hay sử dụng sẵn, đặc biệt đối với các mô hình phức tạp như Transformer networks.

Tổ chức có thể triển khai kiểm soát thực tế bằng cách xác lập ngưỡng giải thích rõ ràng dựa trên mức độ rủi ro của từng use case. Đây vẫn là một thách thức trong ngành, với nhiều nghiên cứu và phương pháp tiếp cận đang phát triển. Đối với các ứng dụng kinh doanh quan trọng, tùy chỉnh phần giải thích theo từng nhóm đối tượng trong khi vẫn duy trì độ chính xác giúp cải thiện sự hiểu biết và niềm tin.

Amazon Bedrock cung cấp các công cụ xác định yếu tố ảnh hưởng đến quyết định của mô hình, đồng thời lưu trữ chi tiết đầu vào và đầu ra của hệ thống. Đối với các quy trình phức tạp, Amazon Bedrock Agents hỗ trợ Chain-of-Thought (CoT) reasoning traces, giúp minh họa logic từng bước của mô hình trong quá trình suy luận. Các tổ chức có thể theo dõi phản hồi theo thời gian thực, đặc biệt trong ứng dụng Retrieval-Augmented Generation (RAG), nơi Amazon Bedrock Knowledge Bases tự động chèn nguồn tham chiếu và liên kết tài liệu gốc được sử dụng trong quá trình tạo phản hồi.

---

## Bảo mật và quyền riêng tư

Các hệ thống Generative AI cần được bảo vệ bằng biện pháp bảo mật và quyền riêng tư mạnh mẽ để bảo vệ thông tin nhạy cảm và ngăn ngừa truy cập trái phép hoặc rò rỉ dữ liệu. Các hệ thống này có thể vô tình tạo ra nội dung hoặc tiết lộ dữ liệu mật, điều mà tổ chức cần chủ động kiểm soát.
Tổ chức có thể thiết lập chiến lược bảo vệ đa tầng, bao gồm kiểm soát truy cập, lọc nội dung, và các biện pháp bảo vệ dữ liệu cá nhân. Điều này có thể bao gồm việc tạo chuẩn chung cho prompt engineering để tránh đầu ra độc hại, sử dụng RAG để kiểm soát nguồn thông tin, và triển khai hệ thống tự động phát hiện – bảo vệ dữ liệu cá nhân. Kiểm thử và xác thực định kỳ, đặc biệt để tuân thủ các quy định như GDPR, là một phần trong quá trình phát triển và triển khai.
Amazon Bedrock áp dụng nhiều lớp bảo mật, bao gồm private endpoints với sự hỗ trợ của Amazon Virtual Private Cloud (Amazon VPC),  AWS Identity and Access Management (IAM), và mã hóa đầu cuối. Đặc biệt, Bedrock không lưu trữ lâu dài dữ liệu prompt hoặc completion và duy trì sự tách biệt giữa các nhà cung cấp mô hình.
Amazon Bedrock Guardrails hỗ trợ lọc thông tin nhạy cảm (PII) thông qua tự động từ chối đầu vào, ẩn dữ liệu trong phản hồi, và mẫu regex tùy chỉnh, đáp ứng nhiều use case mà vẫn đảm bảo bảo mật dữ liệu. Ví dụ, Genesys đã minh chứng khả năng này ở quy mô lớn khi duy trì tuân thủ GDPR trong khi xử lý hơn 1,5 tỷ tương tác khách hàng mỗi tháng thông qua Amazon Bedrock.
Để biết thêm chi tiết, xem Generative AI Security Scoping Matrix, cung cấp khung đánh giá toàn diện cho các rủi ro bảo mật trong Generative AI.

## An toàn

Hệ thống Generative AI cần được thiết kế và vận hành với các cơ chế bảo vệ để tránh gây hại cho cá nhân và cộng đồng. Điều này bao gồm ngăn chặn việc tạo ra nội dung nguy hiểm, bất hợp pháp hoặc lạm dụng, và phòng tránh việc sử dụng sai mục đích hệ thống.

Tổ chức có thể triển khai biện pháp an toàn cụ thể như lọc nội dung trước khi triển khai, giới hạn thời gian thực qua prompt constraints, và phân loại đầu ra để phát hiện – chặn nội dung nguy hiểm. Kiểm duyệt nội dung theo ngữ cảnh giúp phù hợp với lĩnh vực ứng dụng, trong khi phát hiện tự động giúp nhận biết vi phạm an toàn tiềm ẩn trước khi nội dung được tạo ra. Giám sát liên tục và cập nhật định kỳ giúp giảm thiểu các rủi ro mới nổi từ khả năng tiến hóa của mô hình Generative AI.

Amazon Bedrock Guardrails mang lại khả năng bảo vệ an toàn hàng đầu ngành cho cả văn bản và hình ảnh, ngăn chặn hơn 85% nội dung độc hại ngoài khả năng bảo vệ gốc của các foundation model (FM).Các biện pháp an toàn bổ sung bao gồm giới hạn token, rate limiting, và moderation endpoints để kiểm duyệt nội dung.

Để biết hướng dẫn chi tiết về triển khai, xem Build safe and responsible generative AI applications with guardrails.

## Khả năng kiểm soát

Các tổ chức có thể duy trì mức độ kiểm soát phù hợp đối với hệ thống Generative AI để đảm bảo rằng chúng hoạt động như mong đợi và có thể được điều chỉnh hoặc dừng lại khi xảy ra sự cố. Điều này giúp quản lý rủi ro và duy trì độ tin cậy của hệ thống.

Cách tiếp cận đa tầng trong kiểm soát bao gồm việc triển khai các biện pháp kỹ thuật và quy trình vận hành. Các tổ chức có thể kiểm soát hành vi của mô hình bằng cách điều chỉnh các tham số như temperature (kiểm soát mức độ ngẫu nhiên của đầu ra) và các phương pháp sampling như top-k hoặc top-p (quản lý mức độ đa dạng của đầu ra). Việc xác định ranh giới vận hành rõ ràng giúp định nghĩa phạm vi hành động của hệ thống, trong khi human-in-the-loop validation cung cấp lớp giám sát bổ sung cho các ứng dụng quan trọng.

Để đạt được hiệu quả kiểm soát cao, tổ chức có thể thiết lập ngưỡng tham số riêng cho từng use case, triển khai cơ chế điều chỉnh nhanh, và tạo quy trình xử lý leo thang rõ ràng. Amazon Bedrock tăng cường khả năng kiểm soát thông qua tùy chỉnh agent prompt, kỹ thuật reasoning, và khả năng chia nhỏ các tác vụ phức tạp thành các thành phần nhỏ dễ quản lý hơn. Các tổ chức có thể lựa chọn giữa workflow có cấu trúc hoặc phương pháp linh hoạt dựa trên agent. Việc so sánh định kỳ đầu ra với các benchmark chuẩn giúp duy trì tính ổn định và độ tin cậy của hệ thống.

Cách tiếp cận cân bằng này hỗ trợ sự sáng tạo trong đầu ra AI đồng thời giúp đảm bảo hiệu suất ổn định trong giới hạn chất lượng đã xác định, qua đó ngăn ngừa suy giảm dịch vụ và gián đoạn kinh doanh trong khi giảm thiểu lãng phí tài nguyên.

Khả năng kiểm soát còn được tăng cường thông qua tích hợp giám sát với Amazon CloudWatch và cơ chế kiểm soát phiên bản của knowledge base. Các tính năng của Amazon Bedrock, bao gồm LLM-as-a-judge features, giúp tổ chức đánh giá và tối ưu hóa ứng dụng Generative AI một cách hiệu quả và có kiểm soát.

## Tính xác thực và độ vững chắc

Các hệ thống Generative AI có thể tạo ra kết quả đáng tin cậy và chính xác, ngay cả khi gặp đầu vào bất ngờ hoặc phức tạp. Điều này giúp duy trì niềm tin và bảo đảm tính hữu dụng của hệ thống trong nhiều loại ứng dụng khác nhau.
Các tổ chức có thể triển khai sự kết hợp giữa kiểm soát kỹ thuật và quy trình để nâng cao độ vững chắc của hệ thống cũng như độ tin cậy của đầu ra. Điều này bao gồm việc thiết lập ngưỡng tham số rõ ràng cho từng use case, triển khai human-in-the-loop validation cho các ứng dụng quan trọng, và so sánh định kỳ đầu ra với ground truth đã được xác lập. Khung quản lý này xác định khi nào và cách thức áp dụng các biện pháp kiểm soát dựa trên mức độ quan trọng của use case và yêu cầu về độ chính xác.

Amazon Bedrock Guardrails cải thiện tính xác thực bằng cách ngăn ngừa lỗi sai thực tế thông qua kiểm tra suy luận tự động, đạt độ chính xác lên đến 99% trong việc phát hiện phản hồi chính xác từ mô hình, bằng cách sử dụng logic toán học và kỹ thuật xác minh hình thức (formal verification). Khả năng này hỗ trợ xử lý tài liệu lớn lên đến 80.000 tokens, đồng thời bao gồm tự động tạo kịch bản kiểm thử (scenario generation) để đảm bảo kiểm thử toàn diện.
Amazon Bedrock cũng tích hợp tính năng làm sạch đầu vào (input sanitization) nâng cao và hỗ trợ kiểm thử đối kháng (adversarial testing) thông qua tích hợp với các công cụ kiểm thử AWS.

## Quản trị

Việc quản trị hiệu quả các hệ thống Generative AI giúp quản lý rủi ro, duy trì trách nhiệm giải trình, và đảm bảo việc sử dụng AI phù hợp với các giá trị và quy định của tổ chức. Quản trị bao phủ toàn bộ vòng đời của AI, từ giai đoạn phát triển, triển khai cho đến vận hành liên tục.

Các tổ chức có thể xây dựng cấu trúc quản trị rõ ràng, bao gồm xác định vai trò trong việc giám sát AI, thực hiện đánh giá rủi ro định kỳ, và tăng cường tương tác với các bên liên quan. Điều này đòi hỏi tích hợp quản trị AI vào các thực tiễn quản lý rủi ro hiện có, đồng thời đảm bảo tuân thủ các luật và tiêu chuẩn liên quan. Do công nghệ AI đang phát triển nhanh chóng, việc đánh giá và cập nhật thường xuyên các quy trình quản trị là điều cần thiết để giải quyết các năng lực mới, rủi ro phát sinh, và các yêu cầu pháp lý thay đổi. Điều này cũng bao gồm đào tạo và phát triển kỹ năng phù hợp cho người sử dụng hệ thống.

AWS đã nhận được chứng chỉ ISO/IEC 42001 , thể hiện cam kết đối với phương pháp quản trị có hệ thống trong triển khai AI. Các tính năng quản trị trong Amazon Bedrock bao gồm: Theo dõi nguồn gốc mô hình (model provenance tracking) toàn diện, ghi nhật ký kiểm toán chi tiết qua AWS CloudTrail, luồng phê duyệt triển khai mô hình tích hợp với AWS Organizations. Ngoài ra, AWS Audit Manager cung cấp các framework dựng sẵn để đánh giá việc triển khai Generative AI so với các thực tiễn tốt nhất.

## Tính minh bạch

Các hệ thống Generative AI có thể vận hành một cách minh bạch, giúp các bên liên quan hiểu rõ năng lực, giới hạn và ngữ cảnh của các đầu ra do AI tạo ra. Điều này góp phần xây dựng niềm tin và cho phép người dùng cũng như các bên bị ảnh hưởng đưa ra quyết định có cơ sở hơn.
Các tổ chức có thể thực hiện các biện pháp minh bạch cụ thể, bao gồm việc xây dựng tài liệu mô hình toàn diện mô tả chi tiết mục đích sử dụng, giới hạn đã biết và phạm vi hiệu suất của mô hình. Việc công bố rõ ràng về việc sử dụng AI cần nêu rõ thời điểm, cách thức và loại dữ liệu được xử lý. Ngoài ra, các báo cáo hiệu suất định kỳ có thể bao gồm tỷ lệ chính xác, các mẫu lỗi và đánh giá thiên vị (bias).
Đối với các ứng dụng hướng đến khách hàng, tính minh bạch còn bao gồm việc cung cấp chỉ báo rõ ràng về nội dung do AI tạo ra, giải thích cách thức ra quyết định của hệ thống, và thiết lập quy trình để người dùng có thể đặt câu hỏi hoặc phản hồi về kết quả đầu ra. Việc duy trì lịch sử chi tiết về các phiên bản mô hình và thay đổi trong hành vi hệ thống giúp theo dõi sự tiến hóa của năng lực AI và tác động của chúng theo thời gian.
Từ phía AWS, trong khuôn khổ Shared Responsibility Model, tính minh bạch được hỗ trợ thông qua AWS AI Service Cards và tài liệu chi tiết mô tả đặc tính của mô hình. Amazon Bedrock tăng cường điều này bằng khả năng ghi nhật ký và giám sát toàn diện, giúp theo dõi hành vi của mô hình và các chỉ số hiệu suất một cách hiệu quả.

## Quản lý rủi ro thống nhất

Tám khía cạnh trên liên kết chặt chẽ và củng cố lẫn nhau trong khuôn khổ quản lý rủi ro doanh nghiệp (enterprise risk management framework). Mặc dù các tổ chức có thể ưu tiên khác nhau tùy theo use case và mức độ chấp nhận rủi ro, nhưng khi kết hợp, chúng cung cấp cách tiếp cận toàn diện để triển khai Generative AI có trách nhiệm. Để biết thêm hướng dẫn kỹ thuật chi tiết, tiêu chuẩn, và yêu cầu tuân thủ, vui lòng tham khảo các tài liệu hướng dẫn AWS trong phần Resources ở cuối bài blog, hỗ trợ việc triển khai trên tất cả các lĩnh vực này.

## Quản lý rủi ro AI trong thực tiễn: Xây dựng năng lực tổ chức

Việc triển khai thành công các hệ thống AI sinh sinh đòi hỏi phải tích hợp các thực tiễn quản lý rủi ro trên toàn tổ chức. Điều này bao gồm việc thiết lập các quy trình để đo lường kết quả và rủi ro, cũng như chuẩn bị cho tổ chức thích ứng khi công nghệ phát triển. Quản lý rủi ro hiệu quả phụ thuộc vào việc xây dựng kiến thức và kỹ năng phù hợp ở mọi cấp độ trong tổ chức.

Các tổ chức có thể tạo ra lộ trình rõ ràng từ giai đoạn thử nghiệm khái niệm (proof of concept) đến triển khai thực tế bằng cách tuân theo mô hình “ba tuyến phòng thủ” (three lines of defense model). Khung ERMF cung cấp các tham số tổng thể về độ tin cậy, an toàn và quyền riêng tư, mà các đơn vị kinh doanh có thể điều chỉnh để phù hợp với từng trường hợp sử dụng cụ thể.

Để xây dựng và duy trì năng lực bền vững cho việc áp dụng AI sinh sinh trong hiện tại và tương lai, các tổ chức có thể tập trung vào:
* Phát triển các kế hoạch ứng phó sự cố dành riêng cho các tình huống liên quan đến AI
* Xây dựng chuyên môn thông qua các chương trình đào tạo và chứng nhận
* Đánh giá và cập nhật thường xuyên các thực tiễn quản lý rủi ro

Khi những yếu tố này được tích hợp vào cấu trúc vận hành của tổ chức, chúng sẽ tạo ra các thực tiễn bền vững có thể phát triển song song với sự tiến bộ của công nghệ và sự xuất hiện của các rủi ro mới.
Quản lý rủi ro bền vững: Chuẩn bị ERMF của bạn sẵn sàng cho Generative AI
Các lãnh đạo phụ trách quản trị, rủi ro và tuân thủ (GRC), cùng với Giám đốc Quản lý Rủi ro (CRO) và Giám đốc Kiểm toán Nội bộ (CIA) có thể đóng vai trò bảo trợ chiến lược lâu dài cho việc áp dụng Generative AI. Việc xây dựng năng lực dài hạn cần được mở rộng ra ngoài phạm vi công nghệ và đổi mới sáng tạo, bao gồm cả các chức năng kinh doanh và kiểm soát nội bộ. Sự định hướng rõ ràng từ ban lãnh đạo giúp tổ chức cân bằng giữa cơ hội và rủi ro khi áp dụng Generative AI.

Các tổ chức được hưởng lợi khi xem Generative AI như một năng lực chuyển đổi toàn diện có ảnh hưởng đến nhiều bộ phận, thay vì coi đây là một sáng kiến tách biệt. Cách tiếp cận này giúp tích hợp bền vững các cơ chế quản trị doanh nghiệp cho Generative AI, đồng thời tránh hạn chế của các dự án ngắn hạn với phạm vi và tác động hạn chế.

Các tổ chức có thể triển khai Generative AI một cách có kiểm soát và có trách nhiệm, đồng thời duy trì nghĩa vụ quản lý rủi ro thông qua những trường hợp sử dụng được xác định rõ ràng. Ví dụ, Parameta, một bộ phận thuộc TP ICAP, đã thể hiện phương pháp này trong việc triển khai AI phục vụ tuân thủ quy định pháp lý. Bằng cách tập trung trước tiên vào lĩnh vực có mức độ điều tiết cao, duy trì cơ chế quản trị chặt chẽ và đảm bảo sự giám sát của con người trong quá trình kiểm duyệt, họ đã xây dựng khung quản trị cho việc áp dụng AI có trách nhiệm — đồng thời tạo ra các vai trò giám sát chuyên biệt cho các sáng kiến AI trong tương lai.

Tương tự, Rocket Mortgage đã triển khai Amazon Bedrock for responsible AI một cách có trách nhiệm và ở quy mô lớn cho công cụ Rocket Logic – Synopsis. Cách tiếp cận này giúp họ duy trì các biện pháp bảo mật và tuân thủ nghiêm ngặt, đồng thời tiết kiệm 40.000 giờ làm việc mỗi năm nhờ tự động hóa quy trình.

## Danh sách hành động cho việc triển khai Generative AI bền vững:
* Nền tảng ERMF: Đánh giá và nâng cao mức độ sẵn sàng của khung quản lý rủi ro cho Generative AI, bao gồm hướng dẫn sử dụng hợp lý và phân định rõ trách nhiệm.
* Kiểm soát kỹ thuật: Bắt đầu với các biện pháp kiểm soát cốt lõi như Amazon Bedrock Guardrails, sau đó mở rộng theo trường hợp sử dụng và hồ sơ rủi ro cụ thể.
* Năng lực tổ chức: Phát triển chuyên môn toàn diện thông qua đào tạo và cơ chế giám sát giữa các bộ phận kinh doanh và kiểm soát.
* Giám sát và đo lường: Xây dựng bảng điều khiển (dashboard) để theo dõi các chỉ số rủi ro chính (KRI) và tiến hành đánh giá định kỳ.
* Chiến lược tích hợp: Liên kết các biện pháp kiểm soát Generative AI với quy trình và chiến lược tổ chức hiện có, đảm bảo sự thống nhất và hiệu quả dài hạn.
## Kết luận
Chuỗi bài viết gồm hai phần này đã khám phá tầm quan trọng cốt lõi của việc tích hợp quản trị AI sinh sinh vào trong các khung quản lý rủi ro doanh nghiệp (ERMF). Trong Phần 1, chúng tôi đã giới thiệu các rủi ro đặc thù và những yếu tố quản trị cần xem xét khi áp dụng AI sinh sinh. Phần 2 cung cấp hướng dẫn toàn diện để điều chỉnh ERMF nhằm giải quyết hiệu quả những thách thức này.

Chúng tôi đã trình bày các chiến lược thực tiễn giúp mở rộng việc áp dụng AI sinh sinh một cách an toàn và có trách nhiệm, bao gồm các lĩnh vực then chốt như công bằng, khả năng giải thích, quyền riêng tư và bảo mật, an toàn, khả năng kiểm soát, tính xác thực và độ vững chắc, quản trị và tính minh bạch. Bằng cách triển khai các chiến lược này và làm theo danh sách hành động được cung cấp, các tổ chức có thể xây dựng các thực tiễn bền vững phát triển song song với sự tiến bộ của công nghệ và sự xuất hiện của các rủi ro mới.

Những tổ chức tích hợp quản trị AI sinh sinh vào ERMF như được mô tả trong bài viết này sẽ có vị thế tốt hơn để thúc đẩy đổi mới và hiệu quả vận hành, đồng thời bảo vệ trước các rủi ro trọng yếu như rò rỉ dữ liệu, hiện tượng “ảo giác” của mô hình (model hallucinations) và việc không tuân thủ quy định. Cách tiếp cận cân bằng này cho phép các tổ chức khai thác tiềm năng chuyển đổi của AI sinh sinh trong khi vẫn duy trì các cơ chế kiểm soát mạnh mẽ — điều đặc biệt quan trọng đối với các tổ chức trong lĩnh vực dịch vụ tài chính.

Để tìm hiểu về các khái niệm nền tảng và các yếu tố rủi ro, vui lòng xem Phần 1.