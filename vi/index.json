[{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Đặng Minh Hoàng\nSố điện thoại: 0979091813\nEmail: Hoangsusp@gmail.com\nTrường: Đại học FPT\nNgành: Kỹ thuật phần mềm\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/4-eventparticipated/4.2-event2/","title":"Sự kiện 2","tags":[],"description":"","content":"Báo cáo Tổng kết: Workshop “Khám Phá Agentic AI – Amazon QuickSuite” Mục tiêu Sự kiện Làm rõ khái niệm Agentic AI: Định nghĩa sự chuyển dịch từ AI Tạo sinh (Generative AI) thụ động sang AI Tác tử (Agentic AI) tự chủ. Ra mắt Amazon QuickSuite: Thực hiện buổi trình diễn trực tiếp (live demo) đầu tiên của giải pháp này tại Việt Nam. Thúc đẩy ứng dụng: Giảm thiểu rào cản tài chính thông qua Chương trình AWS LIFT (gói tín dụng lên tới $80,000 USD). Thực hành chuyên sâu: Cung cấp môi trường thực tế để xây dựng các mô hình AI dưới sự hướng dẫn của chuyên gia. Diễn giả Vivien Nguyen – Territory Manager (Quản lý Vùng), AWS Tung Cao – Solution Architect (Kiến trúc sư Giải pháp), AWS Đội ngũ Cloud Kinetics – Đối tác Triển khai Chiến lược Điểm nhấn Chính Sự thay đổi mô hình: Từ Generative sang Agentic Workshop đã thiết lập sự phân biệt rõ ràng giữa các thế hệ AI:\nGenerative AI (AI Tạo sinh): Tập trung vào việc tạo ra nội dung (văn bản, hình ảnh, mã nguồn) dựa trên các câu lệnh (prompts). Agentic AI (AI Tác tử): Tập trung vào sự tự chủ và hành động. Các hệ thống này có thể nhận thức môi trường, suy luận qua các quy trình làm việc phức tạp và thực thi nhiệm vụ một cách độc lập mà không cần sự can thiệp liên tục của con người. Giới thiệu Amazon QuickSuite Sự kiện đánh dấu lần đầu tiên Amazon QuickSuite được trình diễn trực tiếp tại Việt Nam.\nHệ sinh thái hợp nhất: Tích hợp liền mạch khả năng trực quan hóa dữ liệu (QuickSight) với năng lực tạo sinh (Quick Suite Q). Tốc độ và sự linh hoạt: Thương hiệu \u0026ldquo;Quick\u0026rdquo; nhấn mạnh khả năng triển khai nhanh chóng, cho phép doanh nghiệp đi từ ý tưởng đến thực thi trong thời gian ngắn. Lấy dữ liệu làm trung tâm: Bộ giải pháp được thiết kế để xử lý khối lượng dữ liệu lớn, điều kiện tiên quyết để các tác tử thông minh (agents) đưa ra quyết định chính xác. Quan hệ Đối tác \u0026amp; Hỗ trợ Chiến lược Hợp tác với Cloud Kinetics: Sự kiện nhấn mạnh rằng trong khi AWS cung cấp nền tảng, các đối tác như Cloud Kinetics đóng vai trò thiết yếu trong việc tư vấn kiến trúc và triển khai \u0026ldquo;bước cuối cùng\u0026rdquo; (last-mile). Hỗ trợ hai lớp: Người tham dự nhận được sự hỗ trợ từ cả chuyên gia nền tảng (AWS) và đối tác tư vấn, giúp giảm thiểu rủi ro kỹ thuật khi áp dụng công nghệ mới. Hỗ trợ Tài chính: Chương trình AWS LIFT Tín dụng $80,000 USD: Một gói ưu đãi tài chính lớn được giới thiệu nhằm hỗ trợ khách hàng mới và các doanh nghiệp vừa \u0026amp; nhỏ (SMBs). Giảm thiểu rủi ro: Nguồn tài trợ này cho phép các công ty thử nghiệm các hệ thống tính toán hiệu năng cao và R\u0026amp;D mà không phải chịu gánh nặng chi phí hạ tầng ngay lập tức. Bài học Chính (Key Takeaways) Tư duy Thiết kế (Design Mindset) Tập trung vào sự tự chủ: Khi thiết kế Agentic AI, mục tiêu là xây dựng các hệ thống hoạt động thay mặt người dùng, chứ không chỉ hỗ trợ họ. Ứng dụng thực tế: Vượt qua sự \u0026ldquo;hào nhoáng\u0026rdquo; của công nghệ bằng cách xác định các nút thắt vận hành cụ thể nơi một tác tử tự chủ có thể tạo ra giá trị (ví dụ: báo cáo tự động, điều chỉnh chuỗi cung ứng). Kiến trúc Kỹ thuật Tiếp cận theo hệ sinh thái: Các tác tử hiệu quả cần một mạng lưới công cụ được kết nối. QuickSuite đóng vai trò là mạch kết nối giữa nguồn dữ liệu và logic hành động. Sẵn sàng về hạ tầng: Việc tạo tài khoản AWS và thiết lập môi trường chính xác là bước đi đầu tiên quan trọng để tiếp cận các năng lực nâng cao này. Chiến lược Triển khai Lợi thế thông tin: Những người sớm tiếp cận QuickSuite sẽ có lợi thế cạnh tranh bằng cách sử dụng các công cụ mà thị trường rộng lớn chưa thành thạo. Quản lý chi phí: Tận dụng các chương trình như LIFT là yếu tố then chốt để tăng tốc thời gian đưa sản phẩm ra thị trường (time-to-market) trong khi vẫn quản lý tốt dòng tiền. Ứng dụng vào Công việc Tìm hiểu QuickSuite: Nghiên cứu cách tích hợp QuickSight và Quick Suite Q vào quy trình phân tích dữ liệu hiện tại để tạo ra các \u0026ldquo;Analyst Agents\u0026rdquo; (Tác tử phân tích). Tận dụng ưu đãi tài chính: Đăng ký tham gia Chương trình AWS LIFT để đảm bảo nguồn tín dụng cho các dự án R\u0026amp;D sắp tới. Xác định tình huống sử dụng (Use Cases): Rà soát quy trình vận hành nội bộ để tìm ra các tác vụ lặp lại, nhiều bước phù hợp cho việc thực thi tự động bởi Agentic AI. Hợp tác với đối tác: Kết nối với các đối tác giải pháp như Cloud Kinetics cho các nhu cầu kiến trúc phức tạp thay vì tự xây dựng toàn bộ (in-house). Trải nghiệm Sự kiện Tham dự workshop “Khám Phá Agentic AI” tại Bitexco Financial Tower là một trải nghiệm chuyên nghiệp và sâu sắc, cung cấp một lộ trình rõ ràng cho tương lai của AI doanh nghiệp. Các trải nghiệm chính bao gồm:\nTiếp cận Độc quyền và Đổi mới Việc tham gia vào buổi demo trực tiếp đầu tiên của Amazon QuickSuite tại Việt Nam mang lại cảm giác dẫn đầu về công nghệ. Địa điểm tổ chức tại Văn phòng AWS Việt Nam khẳng định cam kết của AWS đối với thị trường nội địa và cung cấp một môi trường chuyên nghiệp chất lượng cao. Học tập qua Thực hành (Hands-on) Giá trị cao Phiên workshop 90 phút thực sự hữu ích. Khác với các hội thảo thụ động, việc trực tiếp xây dựng các khái niệm với Quick Sight + Quick Suite Q giúp củng cố kiến thức lý thuyết vững chắc. Sự hiện diện của các chuyên gia kỹ thuật AWS để hướng dẫn trực tiếp \u0026ldquo;cầm tay chỉ việc\u0026rdquo; cho phép giải quyết sự cố ngay lập tức và thảo luận kỹ thuật sâu hơn. Kết nối (Networking) và Hệ sinh thái Giờ nghỉ trưa kéo dài và các phiên networking tạo điều kiện quý báu để thảo luận chiến lược với các đồng nghiệp và chuyên gia trong ngành. Hiểu rõ vai trò của đối tác Cloud Kinetics giúp làm sáng tỏ cách thu hẹp khoảng cách giữa khả năng nền tảng trừu tượng và các giải pháp kinh doanh cụ thể. Bài học rút ra Agentic AI là tương lai của vận hành: Sự chuyển dịch từ việc \u0026ldquo;trò chuyện với AI\u0026rdquo; sang \u0026ldquo;AI thực hiện công việc\u0026rdquo; là tất yếu và mang tính cách mạng. Tốc độ là yếu tố then chốt: Các công cụ được thiết kế để triển khai nhanh (\u0026ldquo;QuickSuite\u0026rdquo;), cho thấy sự linh hoạt (agility) là thước đo mới cho thành công. Nguồn vốn thúc đẩy đổi mới: Chương trình LIFT thay đổi câu hỏi từ \u0026ldquo;Chúng ta có đủ khả năng chi trả không?\u0026rdquo; thành \u0026ldquo;Chúng ta có thể bắt đầu nhanh đến mức nào?\u0026rdquo; Nhìn chung, workshop đã thành công trong việc làm sáng tỏ khái niệm phức tạp về Agentic AI và cung cấp các công cụ cụ thể, nguồn vốn và chuyên môn cần thiết để bắt đầu xây dựng ngay lập tức. Đây là một bước đi chiến lược giúp trao quyền cho người tham dự chuyển đổi hoạt động kinh doanh của họ.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/4-eventparticipated/4.1-event1/","title":"Sự kiện 1","tags":[],"description":"","content":"Báo cáo thu hoạch: “AWS Cloud Day Vietnam - AI Edition 2025” Tên sự kiện: Vietnam Cloud Day 2025 Ngày: 18 tháng 9 năm 2025 Địa điểm: Số 2 đường Hải Triều, Phường Bến Nghé, Quận 1, TP. Hồ Chí Minh Vai trò trong sự kiện: Người tham dự Mục tiêu sự kiện Sự kiện AWS Cloud Day Vietnam - AI Edition 2025 được định vị là một cuộc tụ họp quan trọng của cộng đồng công nghệ và kinh doanh tại Việt Nam. Mục tiêu chính của sự kiện là thúc đẩy quá trình chuyển đổi số của nền kinh tế Việt Nam bằng cách tận dụng sức mạnh cộng hưởng của Điện toán đám mây (Cloud Computing) và Trí tuệ nhân tạo (AI).\nCác mục tiêu bao trùm của sự kiện có thể được phân thành bốn trụ cột chiến lược:\nPhổ cập AI Tạo sinh cho Doanh nghiệp: Đưa AI Tạo sinh (GenAI) vượt ra khỏi sự hào nhoáng ban đầu để đi vào triển khai thực tế. Mục tiêu là chứng minh cách các doanh nghiệp có thể biến đổi các giải pháp AI chung chung thành các chương trình tinh vi, nhận biết ngữ cảnh, nhấn mạnh \u0026ldquo;chiến lược dữ liệu toàn diện\u0026rdquo; là yếu tố tạo nên sự khác biệt then chốt. Xóa bỏ ranh giới giữa Kinh doanh và CNTT: Đặc biệt trong lĩnh vực Dịch vụ Tài chính, nhằm thu hẹp khoảng cách truyền thống giữa mục tiêu vận hành kinh doanh và công nghệ thông tin. Mục tiêu là cho thấy công nghệ đám mây không chỉ là cơ sở hạ tầng mà còn là động lực tạo ra giá trị kinh doanh, cho phép các mô hình \u0026ldquo;Ngân hàng Hệ sinh thái\u0026rdquo; (Ecosystem Banking) và \u0026ldquo;Tài chính Nhúng\u0026rdquo; (Embedded Finance). Tăng tốc hiện đại hóa theo đặc thù ngành: Cung cấp lộ trình phù hợp cho các ngành công nghiệp đa dạng (Bán lẻ, Năng lượng, Viễn thông, Khu vực công). Nêu bật các câu chuyện thành công như Xanh SM, Honda Việt Nam, và Masterise Group để chứng minh rằng hiện đại hóa đòi hỏi các con đường cụ thể, cho dù thông qua việc di chuyển (migration) hay xây dựng các ứng dụng thuần đám mây (cloud-native) hoàn toàn mới. Củng cố An ninh và Khả năng phục hồi: Thiết lập tư duy \u0026ldquo;bảo mật ngay từ thiết kế\u0026rdquo; (security by design). Mục đích là hướng dẫn người tham dự cách tích hợp các phương pháp bảo mật tốt nhất trong suốt vòng đời ứng dụng—từ phát triển đến vận hành thực tế. Diễn giả Sự kiện quy tụ danh sách đầy đủ gồm 24 diễn giả, từ các quan chức chính phủ cấp cao đến các giám đốc điều hành C-level và các chuyên gia kỹ thuật.\nTên diễn giả Chức danh Tổ chức H.E. Pham Duc Long Thứ trưởng Bộ Khoa học và Công nghệ Bộ Khoa học và Công nghệ H.E. Marc E. Knapper Đại sứ Hoa Kỳ tại Việt Nam Đại sứ quán Hoa Kỳ tại Việt Nam Jaime Valles Phó Chủ tịch, TGĐ Châu Á Thái Bình Dương \u0026amp; Nhật Bản AWS Jeff Johnson Giám đốc điều hành khu vực ASEAN AWS Dr. Jens Lottner Tổng Giám đốc (CEO) Techcombank Dieter Botha CEO TymeX Trang Phung CEO U2U Network Vu Van Đồng sáng lập \u0026amp; CEO ELSA Corp Nguyen Hoa Binh Chủ tịch Nexttech Group Gia Hieu Dinh Giám đốc Công nghệ thông tin (CIO) F88 Nguyen Hong Phuong Huy Trưởng bộ phận Hạ tầng Đám mây \u0026amp; An ninh Mạng Masterise Group Nguyen Vu Hoang Trưởng bộ phận Công nghệ VTV Digital Ha Anh Van Trưởng phòng: Bộ phận Giải pháp CNTT Honda Việt Nam Nguyen Tuan Huy Giám đốc Chuyển đổi số Mobifone Minh Hoang Giám đốc Dữ liệu (CDO) Techcom Securities Vincent Nguyen Giám đốc điều hành Nam Long Commercial Property Seunghoon Chae Tổng Giám đốc MegazoneCloud Vietnam Uy Tran Đồng sáng lập \u0026amp; COO Katalon Thai Huy Chuong Trưởng bộ phận Phát triển Ứng dụng Bảo Việt Holdings Tran Dinh Khiem Giám đốc Ngân hàng Số Techcombank Christopher Bennett Giám đốc Công nghệ (CTO) TymeX Selma Belhadjamor Chuyên gia Khoa học Dữ liệu Chính Onebyzero Ngo Manh Ha Đồng CEO, CTO TechX Corp Nguyen Thanh Binh Trưởng bộ phận DevOps Renova Cloud Điểm nhấn chính Sự hội tụ chiến lược: Chính sách và Lãnh đạo Sự bảo trợ của Chính phủ: Bài phát biểu khai mạc của Thứ trưởng Phạm Đức Long và Đại sứ Marc E. Knapper báo hiệu sự ủng hộ song phương mạnh mẽ đối với cơ sở hạ tầng kỹ thuật số của Việt Nam. Tọa đàm Lãnh đạo: Các thảo luận được điều phối bởi Jeff Johnson với các lãnh đạo như Vũ Văn (ELSA Corp) và Nguyễn Hòa Bình (Nexttech Group) tập trung vào khía cạnh văn hóa của sự đổi mới, khám phá cách \u0026ldquo;Con người và Văn hóa\u0026rdquo; thúc đẩy việc áp dụng đám mây. Nhóm 1: Dịch vụ Tài chính (FSI) – Mô hình Ngân hàng Mới Đổi mới trong Ngân hàng \u0026amp; Bảo hiểm: Techcombank và Bảo Việt Holdings thảo luận về sự chuyển dịch sang \u0026ldquo;Ngân hàng Hệ sinh thái\u0026rdquo;. Triển khai XGenAI: Ngô Mạnh Hà (TechX) trình bày về XGenAI, chứng minh cách các đối tác địa phương đang xây dựng trên nền tảng AWS để mang lại trải nghiệm khách hàng vượt trội trong lĩnh vực tài chính. Nhóm 2: Hiện đại hóa Đa ngành Câu chuyện thành công về Di chuyển lên đám mây: Hà Anh Văn chia sẻ kế hoạch chi tiết của Honda Việt Nam về việc di chuyển SAP, chuyển cuộc thảo luận từ việc đơn thuần \u0026ldquo;nhấc và đặt\u0026rdquo; (lift and shift) sang nâng cao giá trị doanh nghiệp. Truyền thông Kỹ thuật số \u0026amp; Viễn thông: VTV Digital và Mobifone chia sẻ hành trình chuyển đổi số \u0026ldquo;Từ Tầm nhìn đến Giá trị\u0026rdquo;. Vận hành Xuất sắc: MegazoneCloud nhấn mạnh việc sử dụng AI để tinh giản quy trình và tối ưu hóa chi phí sau khi di chuyển lên đám mây. Sự linh hoạt trong kinh doanh: Masterise Group trình bày chiến lược mạnh mẽ trong việc di chuyển hàng trăm khối lượng công việc VMware sang AWS. Nhóm 3 \u0026amp; 4: Dữ liệu, AI và DevOps Chiến lược Dữ liệu: Các chuyên gia từ Onebyzero và Techcom Securities nhấn mạnh rằng \u0026ldquo;dữ liệu đóng vai trò là yếu tố khác biệt quan trọng\u0026rdquo; đối với AI Tạo sinh. Cuộc cách mạng DevOps: Katalon và Renova Cloud khám phá việc tích hợp GenAI vào vòng đời DevOps để tự động hóa kiểm thử và tạo mã. Bài học chính Tư duy thiết kế Công nghệ dẫn dắt bởi kinh doanh: Chuyển tư duy từ tập trung vào CNTT sang tập trung vào kinh doanh (ví dụ: F88 cải thiện khả năng tiếp cận tài chính, Nam Long tối ưu hóa quản lý bất động sản). Khả năng phục hồi là tiêu chuẩn: Khả năng phục hồi liên tục đòi hỏi một thiết kế có chủ đích sử dụng các công nghệ thuần đám mây. Kiến trúc kỹ thuật Sự phụ thuộc giữa Dữ liệu và AI: AI Tạo sinh không thể hoạt động nếu không có Chiến lược Dữ liệu. Chất lượng đầu ra tỷ lệ thuận với chất lượng dữ liệu đầu vào. Các lộ trình lai: Tái cấu trúc sang vi dịch vụ/serverless (ví dụ: TymeX). Tái nền tảng (ví dụ: Masterise Group chuyển VMware sang AWS). Chiến lược hiện đại hóa Hơn cả việc di chuyển: Chiến lược là \u0026ldquo;Di chuyển để Vận hành\u0026rdquo; (Migrate to Operate)—tập trung vào đổi mới liên tục sau khi di chuyển. Tích hợp hệ sinh thái: Đối với FSI, chiến lược là Ngân hàng Mở (Open Banking)—cung cấp dịch vụ thông qua API. Ứng dụng vào công việc Kiểm toán độ sẵn sàng của dữ liệu: Thực hiện kiểm toán dữ liệu để đảm bảo có \u0026ldquo;chiến lược dữ liệu toàn diện\u0026rdquo; trước khi bắt đầu các dự án GenAI. Thử nghiệm GenAI trong DevOps: Thử nghiệm tạo mã và kiểm thử tự động để đo lường tốc độ phân phối. Đánh giá các khối lượng công việc cũ: Phân tích các phiên trình bày của Honda Việt Nam và Masterise Group để đối chiếu lộ trình SAP/VMware hiện tại với các phương pháp tốt nhất. Triển khai \u0026ldquo;Bảo mật ở quy mô lớn\u0026rdquo;: Tích hợp các công cụ bảo mật trong suốt vòng đời ứng dụng. Trải nghiệm sự kiện Tham dự AWS Cloud Day Vietnam - AI Edition 2025 mang lại cái nhìn toàn diện về tương lai nền kinh tế số của Việt Nam. Sự kiện không chỉ là nơi trưng bày sản phẩm mà còn là diễn đàn chiến lược liên kết chính sách quốc gia, chuyển đổi doanh nghiệp và triển khai kỹ thuật.\nHọc hỏi từ các diễn giả có chuyên môn cao: Một góc nhìn cân bằng giữa chiến lược và thực thi được cung cấp bởi các diễn giả như Dr. Jens Lottner (Techcombank) và các chuyên gia kỹ thuật từ TechX và Masterise. Tiếp cận kỹ thuật thực tế: Thu được những hiểu biết sâu sắc về kỹ thuật, đặc biệt là về \u0026ldquo;AI Tạo sinh trong Vòng đời DevOps,\u0026rdquo; cho thấy sự chuyển dịch từ viết mã thủ công sang phát triển có sự hỗ trợ của AI. Kết nối và thảo luận: Sự kiện thúc đẩy đối thoại giữa các quan chức chính phủ, lãnh đạo ngân hàng và kiến trúc sư kỹ thuật, làm nổi bật rằng chuyển đổi liên quan đến văn hóa cũng nhiều như mã lệnh. Bài học rút ra Dữ liệu là yếu tố khác biệt then chốt: Nếu không có dữ liệu chất lượng cao, GenAI chỉ là một sự mới lạ. Hiện đại hóa là liên tục: Nó đòi hỏi sự chuyển dịch sang \u0026ldquo;vận hành thông minh hơn\u0026rdquo;. Bảo mật là việc của mọi người: Nó phải được tích hợp từ dòng mã đầu tiên. Kết luận: Nhìn chung, sự kiện đã chứng minh hiệu quả rằng sự hội tụ của cơ sở hạ tầng đám mây AWS và AI Tạo sinh là động cơ chính cho giai đoạn tăng trưởng kinh tế tiếp theo của Việt Nam, cung cấp một lộ trình rõ ràng, khả thi cho các tổ chức sẵn sàng hiện đại hóa.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.3-network/5.3.1-vpc/","title":"Cấu hình VPC, Subnets &amp; Routing","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ thiết lập môi trường mạng cô lập cho IELTS BandUp. Chúng ta sẽ khởi tạo một Virtual Private Cloud (VPC), phân chia nó thành các subnet trên nhiều Availability Zones, và cấu hình định tuyến để truy cập Internet.\n1. Khởi tạo VPC Đầu tiên, chúng ta cần một không gian mạng riêng tư.\nTruy cập VPC Dashboard. Chọn Create VPC. Chọn mục VPC only. Name tag: Điền band-up-vpc. IPv4 CIDR block: Điền 10.0.0.0/16 (Dải mạng này cung cấp 65,536 địa chỉ IP, đủ cho việc mở rộng sau này). Giữ nguyên các cài đặt khác và nhấn Create VPC. 2. Tạo Subnets (Phân vùng mạng) Tiếp theo, chúng ta chia VPC thành các mạng nhỏ hơn (Subnets) phân tán trên hai Availability Zones (AZs) để đảm bảo tính sẵn sàng cao (High Availability). Chúng ta sẽ tuân theo sơ đồ IP sau:\nTên Subnet Loại CIDR Block Availability Zone public-subnet-1 Public 10.0.0.0/24 ap-southeast-1a public-subnet-2 Public 10.0.1.0/24 ap-southeast-1b private-app-subnet-1 Private 10.0.2.0/24 ap-southeast-1a private-app-subnet-2 Private 10.0.3.0/24 ap-southeast-1b private-database-subnet-1 Database 10.0.4.0/24 ap-southeast-1a private-database-subnet-2 Database 10.0.5.0/24 ap-southeast-1b Các bước thực hiện:\nVào menu Subnets \u0026gt; Create subnet. Chọn VPC ID: band-up-vpc. Nhập Subnet name, Availability Zone, và IPv4 CIDR block cho từng subnet theo bảng trên. Lặp lại quy trình cho đến khi tạo đủ 6 subnets. 3. Tạo Internet Gateway (IGW) Mặc định, một VPC hoàn toàn khép kín. Để các tài nguyên trong Public Subnet có thể giao tiếp với thế giới bên ngoài, ta cần một Internet Gateway.\nVào menu Internet gateways \u0026gt; Create internet gateway. Name tag: Điền band-up-igw. Nhấn Create internet gateway. Sau khi tạo xong, nhấn Actions \u0026gt; Attach to VPC. Chọn band-up-vpc và nhấn Attach internet gateway. 4. Cấu hình Route Tables (Bảng định tuyến) Cuối cùng, ta cần điều hướng lưu lượng từ Public Subnets ra Internet Gateway.\nVào menu Route tables \u0026gt; Create route table. Name: public-route-table. VPC: band-up-vpc. Nhấn Create route table. Thêm Route ra Internet:\nChọn public-route-table vừa tạo. Chuyển sang tab Routes \u0026gt; Edit routes. Thêm một route mới: Destination: 0.0.0.0/0 (Tất cả lưu lượng). Target: Chọn Internet Gateway -\u0026gt; band-up-igw. Nhấn Save changes. Liên kết Subnets (Subnet Association):\nChuyển sang tab Subnet associations \u0026gt; Edit subnet associations. Tích chọn các Public Subnets (public-subnet-1 và public-subnet-2). Nhấn Save associations. 5. Kiểm tra cấu hình Để kiểm chứng kiến trúc mạng đã được thiết lập chính xác hay chưa, hãy quay lại VPC Dashboard, chọn band-up-vpc và xem tab Resource map. Bạn sẽ thấy một sơ đồ rõ ràng liên kết các Public Subnet với Route Table và Internet Gateway.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"1. Kiến trúc tổng quan Nền tảng IELTS BandUp được xây dựng trên một kiến trúc mạnh mẽ, có tính sẵn sàng cao (High Availability) trên AWS. Hệ thống được thiết kế để xử lý lưu lượng người dùng một cách an toàn, đồng thời đảm bảo độ trễ thấp khi truy cập tài liệu học tập và các tính năng AI.\n2. Các dịch vụ AWS cốt lõi Để đạt được các mục tiêu về khả năng mở rộng, bảo mật và hiệu năng, chúng tôi sử dụng các nhóm dịch vụ chính sau:\nMạng \u0026amp; Phân phối nội dung (Networking) Amazon VPC (Virtual Private Cloud): Lớp mạng nền tảng. Chúng tôi sử dụng VPC tùy chỉnh với các Public Subnet và Private Subnet riêng biệt để kiểm soát chặt chẽ luồng truy cập. NAT Gateway: Cho phép các tài nguyên trong Private Subnet (như Backend) kết nối ra Internet (để tải thư viện, gọi API ngoài) mà không để lộ IP ra môi trường Public. Application Load Balancer (ALB): Phân phối lưu lượng truy cập ứng dụng đến các container trên nhiều Availability Zones (AZ), đảm bảo khả năng chịu lỗi của hệ thống. Amazon Route 53: Dịch vụ DNS giúp định tuyến tên miền và quản lý lưu lượng truy cập người dùng. Tính toán \u0026amp; Container (Compute) Amazon ECS (Elastic Container Service) với Fargate: Công cụ điều phối container serverless. Chúng tôi sử dụng Fargate để vận hành cả Next.js Frontend và Spring Boot Backend, giúp loại bỏ gánh nặng quản lý máy chủ vật lý (EC2). Amazon ECR (Elastic Container Registry): Kho lưu trữ container được quản lý hoàn toàn, nơi chứa các Docker image của ứng dụng trước khi deploy. Cơ sở dữ liệu \u0026amp; Lưu trữ (Database \u0026amp; Storage) Amazon RDS (Relational Database Service): Sử dụng PostgreSQL với mô hình Multi-AZ (Primary và Standby) để đảm bảo an toàn dữ liệu và khả năng khôi phục sau thảm họa. Amazon ElastiCache (Redis): Đóng vai trò bộ nhớ đệm (cache) trong bộ nhớ, giúp tăng tốc độ truy vấn và quản lý phiên đăng nhập (session) của người dùng. Amazon S3 (Simple Storage Service): Lưu trữ tài nguyên tĩnh, file media (file nghe) và dữ liệu người dùng tải lên với độ bền cao. AI \u0026amp; Tích hợp Serverless Để vận hành các tính năng thông minh của BandUp (Chấm điểm Writing/Speaking, Tạo Flashcard), chúng tôi áp dụng kiến trúc Serverless:\nAmazon Bedrock \u0026amp; Google Gemini API: Các mô hình Generative AI cốt lõi dùng để phân tích bài làm và đưa ra phản hồi cá nhân hóa. AWS Lambda: Các hàm tính toán serverless đóng vai trò điều phối quy trình AI, kết nối ứng dụng với các mô hình ngôn ngữ lớn. Amazon SQS (Simple Queue Service): Hàng đợi thông điệp giúp phân tách (decouple) backend và lớp xử lý AI, cho phép xử lý bất đồng bộ và tránh quá tải hệ thống. Amazon API Gateway: Cổng giao tiếp bảo mật (RESTful API) để gọi các dịch vụ AI từ ứng dụng chính. DevOps \u0026amp; CI/CD AWS CodePipeline: Tự động hóa quy trình phát hành phần mềm, đảm bảo cập nhật nhanh chóng và tin cậy. AWS CodeBuild: Biên dịch mã nguồn, chạy kiểm thử và đóng gói phần mềm (Docker images) sẵn sàng cho việc triển khai. Bảo mật (Security) AWS WAF (Web Application Firewall): Bảo vệ ứng dụng web khỏi các lỗ hổng bảo mật phổ biến. AWS Secrets Manager: Lưu trữ và quản lý an toàn các thông tin nhạy cảm (mật khẩu database, API keys) trong suốt vòng đời ứng dụng. "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.4-setup-fe/5.4.1-docker/","title":"Thiết lập ECR &amp; Đẩy Image","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ tiến hành đóng gói ứng dụng Frontend (Next.js) thành Docker container và đẩy (push) image đó lên Amazon Elastic Container Registry (ECR). Image này sẽ được ECS Fargate sử dụng để khởi chạy ứng dụng sau này.\n1. Chuẩn bị Dockerfile Chúng tôi sử dụng Dockerfile đa tầng (multi-stage) được tối ưu hóa cho Bun (một JavaScript runtime tốc độ cao) và Next.js. Cấu hình này giúp giảm kích thước image cuối cùng và tăng cường bảo mật.\nBase Image: oven/bun:1.1.26 Builder: Thực hiện biên dịch ứng dụng Next.js. Runner: Môi trường production nhẹ nhàng, mở cổng 3000. 2. Build Docker Image Chạy lệnh sau tại thư mục gốc của dự án để build image. Chúng ta sẽ đặt tag là band-up-frontend.\ndocker build -t band-up-frontend . Quá trình build sẽ cài đặt các thư viện phụ thuộc bằng bun install và biên dịch dự án.\n3. Kiểm tra Image tại Local Sau khi build xong, hãy kiểm tra xem image đã được tạo thành công hay chưa.\ndocker image ls Bạn sẽ thấy band-up-frontend với tag latest trong danh sách.\nChạy thử nghiệm: Bạn có thể chạy thử container trên máy local để đảm bảo ứng dụng khởi động đúng cách trước khi đẩy lên AWS.\ndocker run -p 3000:3000 band-up-frontend:latest 4. Đẩy Image lên Amazon ECR Bây giờ chúng ta cần tải image này lên AWS.\nBước 1: Tạo Repository\nTruy cập Amazon ECR \u0026gt; Repositories. Nhấn Create repository. Visibility settings: Chọn Private. Repository name: Nhập band-up-frontend. Nhấn Create repository. Bước 2: Push Image Sử dụng AWS CLI để xác thực và đẩy image. Hãy thay thế [AWS_ACCOUNT_ID] và [REGION] bằng thông tin tài khoản của bạn.\nĐăng nhập vào ECR:\naws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin [AWS_ACCOUNT_ID].dkr.ecr.ap-southeast-1.amazonaws.com Gán Tag cho Image:\ndocker tag band-up-frontend:latest [AWS_ACCOUNT_ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-frontend:latest Đẩy Image lên ECR:\ndocker push [AWS_ACCOUNT_ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-frontend:latest Sau khi quá trình push hoàn tất, image của bạn đã được lưu trữ an toàn trên AWS ECR và sẵn sàng để triển khai.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.5-setup-be/5.5.1-ecr/","title":"Thiết lập ECR &amp; Đẩy Image","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ đóng gói ứng dụng Backend (Spring Boot) và đẩy Docker image đã được tối ưu hóa lên Amazon ECR.\n1. Chiến lược Dockerfile Đối với Backend, chúng ta sử dụng chiến lược Multi-Stage Build với eclipse-temurin:21 (Java 21). Điều này giúp tạo ra image cuối cùng nhỏ gọn và bảo mật.\nStage 1 (Deps): Tải về các thư viện phụ thuộc (dependencies) của Maven. Stage 2 (Package): Build ứng dụng và trích xuất Spring Boot Layered Jar. Kỹ thuật này tách ứng dụng thành các lớp riêng biệt (dependencies, spring-boot-loader, code ứng dụng), giúp Docker cache hiệu quả các phần ít thay đổi. Stage 3 (Final): Sao chép các lớp đã trích xuất vào một JRE image nhẹ. Đồng thời tạo một user không có quyền quản trị (appuser) để tăng cường bảo mật. 2. Build Docker Image Chạy lệnh build tại thư mục gốc của dự án backend. Chúng ta đặt tag là band-up-backend.\ndocker build -t band-up-backend . Docker sẽ thực thi các bước biên dịch và đóng gói như đã định nghĩa.\n3. Tạo ECR Repository Chúng ta cần một kho chứa cho image này.\nTruy cập Amazon ECR \u0026gt; Create repository. Repository name: Nhập band-up-backend. Visibility: Private. Image tag mutability: Mutable. Nhấn Create repository. 4. Đẩy Image lên ECR (Push) Sau khi build xong và repository đã sẵn sàng, chúng ta tiến hành đẩy image.\nBước 1: Gán Tag (Tagging) Gán tag phiên bản (ví dụ: v1.0.0) cho image local.\ndocker tag band-up-backend:latest [Account-ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-backend:v1.0.0 Bước 2: Push lên ECR Tải các layer lên AWS.\ndocker push [Account-ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-backend:v1.0.0 5. Kiểm tra kết quả Truy cập Amazon ECR Console và chọn repository bandup-backend. Bạn sẽ thấy image với tag v1.0.0 đã được tải lên thành công.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Tìm hiểu về tổ chức và các dịch vụ cơ bản của AWS. Các công việc cần triển khai trong tuần này Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tham gia buổi kick-off của FCJ\n- Tìm hiểu về tổ chức\n- Tạo nhóm cùng thực hiện các dự án 06/09/2025 06/09/2025 3 - Tạo tài khoản AWS\n- Xem và vẽ lại kiến trúc mẫu trên phần mềm draw.io\n- Tìm hiểu về điện toán đám mây 09/09/2025 09/09/2025 cloudjourney.awsstudygroup.com 4 - Tìm hiểu về mục tiêu của chương trình The First Cloud Journey và website AWS\n- Thực hiện các thao tác đầu trên tài khoản đã tạo:\n+ Tạo budget\n+ Tạo groups\n+ Thiết lập bảo mật hai lớp\n- Tìm hiểu về Support Centre của website AWS, cách hoạt động và cách gửi yêu cầu hỗ trợ 10/09/2025 10/09/2025 cloudjourney.awsstudygroup.com 5 - Tạo VPC\n- Chỉnh cấu hình cho VPC\n- Tạo Subnet\n- Cấu hình Subnet public để tự động cấp phát IP công cộng\n- Tạo Internet Gateway\n- Cấu hình Internet Gateway để kết nối với VPC\n- Tạo Route Table\n- Cấu hình Route Table để kết nối với Internet Gateway\n- Cấu hình Subnet Associations thành công\n- Tạo Security Group (public)\n- Tạo Security Group (private) 11/09/2025 14/09/2025 cloudjourney.awsstudygroup.com Kết quả đạt được tuần 1 Tham gia buổi kick-off và làm quen với các thành viên trong First Cloud Journey. Hiểu về tổ chức và các mục tiêu của chương trình. Thành công tạo nhóm để thực hiện các dự án. Tạo tài khoản AWS thành công và thực hiện các thao tác cơ bản: Thiết lập budget. Tạo groups. Kích hoạt bảo mật hai lớp (2FA). Tìm hiểu và vẽ lại kiến trúc mẫu trên draw.io. Nắm được khái niệm cơ bản về điện toán đám mây. Hiểu cách sử dụng Support Centre của AWS và cách gửi yêu cầu hỗ trợ. Thành công thực hiện các tác vụ liên quan đến VPC: Tạo và cấu hình VPC. Tạo và cấu hình Subnet (bao gồm Subnet public với IP công cộng tự động). Tạo và gắn Internet Gateway vào VPC. Tạo và cấu hình Route Table, kết nối với Internet Gateway. Cấu hình Subnet Associations thành công. Tạo Security Group cho cả public và private. "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Trang này ghi lại toàn bộ Nhật ký công việc (Worklog) được thực hiện trong suốt chương trình thực tập First Cloud Journey (FCJ) tại AWS. Đây là tài liệu chi tiết hóa quá trình học tập, triển khai dự án Bandup IELTS, khắc phục lỗi hệ thống và tham gia các sự kiện chuyên môn trong vòng 12 tuần (khoảng 3 tháng).\nTrong 12 tuần này, tôi đã chuyển đổi từ việc làm quen với các khái niệm Cloud cơ bản sang việc xây dựng và tối ưu hóa một ứng dụng Serverless tích hợp AI hoàn chỉnh trên AWS, hoàn thành hơn 50 khóa học AWS Skill Builder trong quá trình này.\nTóm tắt công việc theo tuần: Tuần Công việc trọng tâm Tuần 1 Làm quen FCJ, tạo tài khoản AWS, và thiết lập môi trường mạng cơ bản (VPC, Subnets, Internet Gateway). Tuần 2 Nắm vững Amazon EC2 và VPC, hoàn thành các khóa AWS Skill Builder về IAM, Budgets, EC2, và tham gia sự kiện Cloud Day để học hỏi về AI/Data. Tuần 3 Khắc phục sự cố tài khoản AWS, cấu hình Hybrid DNS với Route 53 Resolver và VPC Peering, học CloudFormation và Cloud9 cho phát triển IaC. Tuần 4 Thành thạo AWS Transit Gateway cho quản lý mạng tập trung, nghiên cứu sâu EC2 Auto Scaling, Lightsail, và các dịch vụ Migration (DMS, VM Import/Export). Tuần 5 Phân tích và tối ưu chi phí AWS, thiết kế kiến trúc hạ tầng Serverless, học RDS, DynamoDB, ElastiCache, và thiết lập AWS Toolkit cho VS Code. Tuần 6 Thành thạo dịch vụ Storage AWS (S3, Glacier, Storage Gateway), nâng cao kỹ năng Python, hoàn thiện kiến trúc dự án, và tham gia webinar về DevSecOps và Amazon Q Developer. Tuần 7 Ôn tập toàn diện và củng cố kiến thức các dịch vụ AWS cơ bản (Compute, Storage, Networking, Database, Security) để chuẩn bị cho kỳ thi giữa kỳ. Tuần 8 Hoàn thành thi giữa kỳ, bắt đầu triển khai các chức năng CRUD nền tảng, nghiên cứu kiến trúc serverless (Lambda, API Gateway, DynamoDB), và thiết lập môi trường phát triển. Tuần 9 Chuyển đổi sang AWS SAM, tái cấu trúc các chức năng CRUD, tích hợp Docker cho môi trường build, và triển khai thành công dự án lên AWS vượt qua các thách thức gỡ lỗi Local. Tuần 10 Gỡ lỗi CORS và template validation errors, tích hợp Frontend/Backend, hoàn thành chức năng Read/Delete, giải quyết vấn đề xác thực Cognito, và tham gia AWS Cloud Mastery Series #1. Tuần 11 Triển khai kiến trúc Multi-Stack để tối ưu hóa, khắc phục triệt để lỗi CORS, và bắt đầu tích hợp AI Services (Lambda, Bedrock). Tuần 12 Hoàn thiện Lambda functions tích hợp AI, tích hợp Gemini API cho đánh giá IELTS, hoàn thành RAG pipeline cho tạo flashcard, và tham gia AWS Cloud Mastery Series cuối cùng. Lộ trình học AWS Skill Builder (Tuần 2-5) Danh mục Các khóa học đã hoàn thành Networking VPC, Route 53, VPC Peering, Transit Gateway, Networking Workshop Compute EC2, EC2 Auto Scaling, Lightsail, Lightsail Containers Security IAM, IAM Roles cho EC2 Database RDS, DynamoDB, ElastiCache Migration VM Import/Export, DMS, SCT, Elastic Disaster Recovery DevOps CloudFormation, Cloud9, AWS CLI, AWS Toolkit cho VS Code Quản lý chi phí AWS Budgets, Cost Explorer, Service Quotas, Right-Sizing Architecture Building Highly Available Web Applications Lộ trình học AWS Skill Builder (Tuần 6-10) Danh mục Các khóa học đã hoàn thành Storage Static Website Hosting với S3, AWS Backup, CloudFront Reliability Data Protection với AWS Backup Development AWS Toolkit cho VS Code, Serverless patterns Tiến trình Học tập Tuần 1-5: Nền tảng \u0026amp; Khám phá\nDịch vụ AWS cơ bản (EC2, S3, VPC, IAM) Networking fundamentals (VPC, Route 53, Transit Gateway) Tối ưu chi phí và thiết kế kiến trúc Infrastructure as Code (CloudFormation, Cloud9) Tuần 6-7: Củng cố \u0026amp; Đánh giá\nThành thạo dịch vụ Storage (S3, Glacier, Storage Gateway) Chiến lược disaster recovery và backup Ôn tập toàn diện cho kỳ thi Hoàn thành thi giữa kỳ Tuần 8-10: Triển khai \u0026amp; Deployment\nTriển khai kiến trúc Serverless (Lambda, API Gateway, DynamoDB) Áp dụng framework AWS SAM Tích hợp Docker cho builds nhất quán Tích hợp Frontend-Backend Production deployment và debugging Tuần 11-12: Tính năng Nâng cao \u0026amp; Tích hợp AI\nTối ưu hóa kiến trúc Multi-stack Tích hợp dịch vụ AI (Bedrock, Gemini API) Triển khai RAG pipeline Hoàn thiện dự án cuối cùng "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.6-ai-service/5.6.1-api-gateway/","title":"API Gateway","tags":[],"description":"","content":"Tổng Quan Tạo Amazon API Gateway làm entry point cho AI service requests.\nTạo REST API Điều hướng đến API Gateway → Create API → REST API Cài Đặt Giá Trị API name ielts-ai-api API type REST API Endpoint type Regional Tạo Resources và Methods Endpoints:\nMethod Path Description POST /writing/evaluate Submit writing sample POST /speaking/evaluate Submit audio recording POST /flashcards/generate Generate flashcard POST /upload/audio Upload audio POST /upload/document Upload document Cấu Hình SQS Integration Cho mỗi POST endpoint, cấu hình SQS integration:\nChọn method → Integration Request Integration type: AWS Service AWS Service: SQS HTTP method: POST Action: SendMessage Execution role: API Gateway role với SQS permissions Request Mapping Template:\nAction=SendMessage\u0026amp;MessageBody=$util.urlEncode($input.body)\u0026amp;QueueUrl=$util.urlEncode(\u0026#39;https://sqs.ap-southeast-1.amazonaws.com/{account}/ielts-writing-queue\u0026#39;) Enable CORS Chọn resource → Enable CORS Access-Control-Allow-Origin: * (hoặc specific domain) Access-Control-Allow-Methods: POST, GET, OPTIONS Deploy API Actions → Deploy API Stage name: prod Ghi lại invoke URL: https://{api-id}.execute-api.ap-southeast-1.amazonaws.com/prod AWS CLI Commands # Tạo REST API API_ID=$(aws apigateway create-rest-api \\ --name ielts-ai-api \\ --endpoint-configuration types=REGIONAL \\ --query \u0026#39;id\u0026#39; --output text) # Lấy root resource ROOT_ID=$(aws apigateway get-resources \\ --rest-api-id $API_ID \\ --query \u0026#39;items[?path==`/`].id\u0026#39; --output text) # Tạo /ai resource AI_RESOURCE=$(aws apigateway create-resource \\ --rest-api-id $API_ID \\ --parent-id $ROOT_ID \\ --path-part ai \\ --query \u0026#39;id\u0026#39; --output text) # Tạo /ai/writing-assessment resource aws apigateway create-resource \\ --rest-api-id $API_ID \\ --parent-id $AI_RESOURCE \\ --path-part writing-assessment Bước Tiếp Theo Tiến hành đến SQS Queues.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Tăng tốc quy trình xử lý yêu cầu quyền lợi với Amazon Bedrock Data Automation Trong ngành quản lý quyền lợi nhân sự (benefits administration), xử lý yêu cầu quyền lợi (claims processing) là một trụ cột vận hành quan trọng, đảm bảo rằng nhân viên và người thụ hưởng nhận được quyền lợi đúng hạn — chẳng hạn như thanh toán bảo hiểm y tế, nha khoa hoặc tàn tật — đồng thời kiểm soát chi phí và tuân thủ các quy định như HIPAA và ERISA. Các doanh nghiệp hướng đến việc tối ưu hóa quy trình làm việc — bao gồm nộp yêu cầu, xác minh, thẩm định, thanh toán và khiếu nại — nhằm nâng cao sự hài lòng của nhân viên, củng cố mối quan hệ với nhà cung cấp dịch vụ, và giảm thiểu rủi ro tài chính. Quy trình này bao gồm các bước cụ thể như nộp yêu cầu (thông qua cổng trực tuyến hoặc biểu mẫu giấy), xác minh dữ liệu (kiểm tra tính hợp lệ và chính xác), thẩm định (đánh giá phạm vi quyền lợi dựa trên quy tắc của gói bảo hiểm), thanh toán hoặc từ chối (bao gồm xử lý chi phiếu hoàn tiền), và xử lý khiếu nại. Một quy trình xử lý hiệu quả hỗ trợ cung cấp các chương trình phúc lợi cạnh tranh — yếu tố quan trọng để thu hút và giữ chân nhân tài, cũng như củng cố thương hiệu nhà tuyển dụng — nhưng đồng thời yêu cầu cân bằng giữa tốc độ, độ chính xác và chi phí trong một môi trường được quản lý nghiêm ngặt.\nMặc dù có tầm quan trọng lớn, quy trình xử lý yêu cầu vẫn gặp nhiều thách thức trong nhiều tổ chức. Đáng chú ý nhất là sự phụ thuộc vào hệ thống kế thừa (legacy systems) và quy trình thủ công (manual processes) dẫn đến thời gian xử lý chậm, tỷ lệ lỗi cao và chi phí hành chính tăng. Các yêu cầu không đầy đủ hoặc sai sót — chẳng hạn như thiếu mã chẩn đoán hoặc không khớp điều kiện hưởng — thường dẫn đến việc từ chối và xử lý lại, gây ra sự khó chịu cho cả nhân viên lẫn nhà cung cấp dịch vụ y tế. Bên cạnh đó, gian lận, lãng phí và lạm dụng (fraud, waste, and abuse) tiếp tục làm tăng chi phí, trong khi việc phát hiện những vấn đề này mà không trì hoãn các yêu cầu hợp lệ vẫn là một thách thức. Các yêu cầu pháp lý phức tạp đòi hỏi hệ thống phải được cập nhật liên tục, và việc tích hợp kém giữa các hệ thống — chẳng hạn giữa Human Resource Information Systems (HRIS) và các hệ thống xử lý kế tiếp — hạn chế nghiêm trọng khả năng mở rộng. Những vấn đề này làm tăng chi phí vận hành, xói mòn niềm tin vào chương trình phúc lợi, và khiến các nhóm hỗ trợ khách hàng bị quá tải, đặc biệt trong các giai đoạn xử lý khiếu nại hoặc cao điểm yêu cầu quyền lợi.\nGenerative AI có thể giúp giải quyết những thách thức này. Với Amazon Bedrock Data Automation, bạn có thể tự động hóa việc tạo ra các insight hữu ích từ nội dung phi cấu trúc đa phương tiện như tài liệu, hình ảnh, âm thanh và video. Amazon Bedrock Data Automation có thể được sử dụng trong quy trình xử lý yêu cầu quyền lợi để tự động hóa việc xử lý tài liệu bằng cách trích xuất và phân loại tài liệu từ các gói yêu cầu, đơn đăng ký chính sách và tài liệu hỗ trợ với độ chính xác hàng đầu trong ngành, giúp giảm thiểu lỗi thủ công và tăng tốc thời gian xử lý. Khả năng xử lý ngôn ngữ tự nhiên (Natural Language Processing - NLP) của Amazon Bedrock Data Automation cho phép hiểu và diễn giải dữ liệu phi cấu trúc như ghi chú của nhà cung cấp, hỗ trợ tuân thủ các quy tắc và quy định của chương trình phúc lợi. Bằng cách tự động hóa các nhiệm vụ lặp lại và cung cấp insight, Amazon Bedrock Data Automation giúp giảm gánh nặng hành chính, cải thiện trải nghiệm của cả nhân viên và nhà cung cấp, đồng thời hỗ trợ tuân thủ quy định với chi phí hiệu quả. Hơn nữa, kiến trúc có khả năng mở rộng (scalable architecture) của nó cho phép tích hợp liền mạch với các hệ thống hiện có, cải thiện luồng dữ liệu giữa HRIS, hệ thống xử lý yêu cầu và mạng lưới nhà cung cấp. Các phân tích nâng cao (advanced analytics) cũng giúp phát hiện các mô hình gian lận để tối ưu hóa kiểm soát chi phí.\nTrong bài viết này, chúng ta sẽ xem xét quy trình xử lý yêu cầu quyền lợi điển hình và xác định nơi mà tự động hóa được hỗ trợ bởi Generative AI có thể mang lại tác động lớn nhất.\nXử lý yêu cầu bồi hoàn quyền lợi Khi một nhân viên hoặc người thụ hưởng tự chi trả cho một khoản chi phí nằm trong phạm vi quyền lợi bảo hiểm y tế của họ, họ sẽ gửi yêu cầu bồi hoàn (claim) để được hoàn tiền. Quy trình này yêu cầu nhiều tài liệu hỗ trợ, bao gồm đơn thuốc của bác sĩ và bằng chứng thanh toán — có thể là hình ảnh séc, biên lai hoặc xác nhận thanh toán điện tử. Quy trình xử lý yêu cầu bồi hoàn bao gồm một số bước quan trọng sau:\nTiếp nhận và xử lý tài liệu – Hệ thống nhận và phân loại các tài liệu được gửi, bao gồm: Hồ sơ y tế và đơn thuốc Tài liệu chứng minh thanh toán Các biểu mẫu hỗ trợ và xác minh quyền đủ điều kiện Xử lý xác minh thanh toán – Đối với các khoản bồi hoàn dựa trên séc, hệ thống cần thực hiện các bước sau: Trích xuất thông tin từ hình ảnh séc, bao gồm số tài khoản và số định tuyến (routing number) trong dòng MICR Xác minh tên người nhận và người chi trả dựa trên thông tin được cung cấp trong quá trình gửi yêu cầu Xác nhận rằng số tiền thanh toán khớp với chi phí được yêu cầu bồi hoàn Đánh dấu các sai lệch để chuyển cho nhân viên kiểm tra thủ công Thẩm định và hoàn tiền – Khi quá trình xác minh hoàn tất, hệ thống thực hiện các hành động sau: Xác định quyền lợi dựa trên quy định của gói bảo hiểm và giới hạn chi trả Tính toán số tiền hoàn trả phù hợp Khởi tạo quy trình thanh toán thông qua chuyển khoản trực tiếp hoặc phát hành séc Gửi thông báo đến người yêu cầu về trạng thái hoàn tiền của họ Trong bài viết này, chúng tôi sẽ trình bày một ví dụ thực tế để giúp làm rõ tính phức tạp của quy trình nhiều bước này. Ví dụ sau minh họa cách Amazon Bedrock Data Automation có thể tối ưu hóa quy trình xử lý yêu cầu bồi hoàn, từ bước gửi ban đầu đến khi hoàn tất chi trả.\nTổng quan giải pháp Giả sử một người tham gia chương trình quyền lợi bảo hiểm đến khám bác sĩ và tự chi trả bằng séc. Sau đó, họ mua thuốc được bác sĩ kê tại nhà thuốc. Sau cùng, họ đăng nhập vào cổng thông tin của nhà cung cấp quyền lợi và gửi yêu cầu bồi hoàn kèm hình ảnh séc và biên lai thanh toán tiền thuốc. Giải pháp này sử dụng Amazon Bedrock Data Automation để tự động hóa hai khía cạnh quan trọng và tốn thời gian nhất trong quy trình: tiếp nhận tài liệu và xác minh thanh toán. Sơ đồ sau minh họa kiến trúc xử lý yêu cầu bồi hoàn quyền lợi.\nQuy trình tổng thể hoạt động qua bốn giai đoạn tích hợp: nhập dữ liệu, trích xuất dữ liệu, kiểm tra, và tích hợp.\nNhập dữ liệu Khi người thụ hưởng tải lên các tài liệu hỗ trợ (hình ảnh séc và biên lai nhà thuốc) thông qua cổng thông tin yêu cầu bồi hoàn của công ty, các tài liệu này sẽ được lưu trữ an toàn trong một Amazon Simple Storage Service (Amazon S3) bucket, kích hoạt pipeline tự động xử lý yêu cầu hoàn tiền.\nTrích xuất dữ liệu Sau khi các tài liệu được tải lên, hệ thống ngay lập tức bắt đầu quá trình trích xuất dữ liệu thông minh: Tải đối tượng S3 (S3 object upload) kích hoạt một AWS Lambda function, hàm này sẽ gọi Amazon Bedrock Data Automation project. Amazon Bedrock Data Automation sử dụng các blueprints để xử lý và trích xuất dữ liệu từ tệp. Blueprints là các cấu phần (artifact) được dùng để cấu hình logic nghiệp vụ xử lý tệp bằng cách chỉ định danh sách các trường dữ liệu cần trích xuất, định dạng dữ liệu mong muốn (string, number hoặc Boolean), cùng ngữ cảnh ngôn ngữ tự nhiên phục vụ chuẩn hóa dữ liệu và thiết lập quy tắc xác thực. Amazon Bedrock Data Automation cung cấp sẵn một danh mục các blueprint mẫu. Bạn có thể tạo blueprint tùy chỉnh cho các loại tài liệu đặc thù không có trong danh mục mặc định. Trong giải pháp này, hai blueprint được sử dụng tương ứng cho các loại tài liệu khác nhau, như minh họa trong hình dưới:\nUS-Bank-Check: blueprint có sẵn trong danh mục để xử lý séc ngân hàng. benefit-claims-pharmacy-receipt-blueprint: blueprint tùy chỉnh dành cho biên lai nhà thuốc. US-Bank-Check là một blueprint tiêu chuẩn được cung cấp sẵn bởi Amazon Bedrock Data Automation. Trong khi đó, blueprint tùy chỉnh benefit-claims-pharmacy-receipt-blueprint được tạo thông qua AWS CloudFormation template để xử lý biên lai nhà thuốc — một loại tài liệu chưa được hỗ trợ trong danh mục blueprint mặc định. Quản trị viên quyền lợi (benefit administrator) muốn trích xuất thông tin liên quan đến nhà cung cấp (vendor) như tên, địa chỉ và số điện thoại trong quá trình xử lý yêu cầu bồi hoàn. Blueprint tùy chỉnh này định nghĩa schema chứa mô tả ngôn ngữ tự nhiên cho các trường dữ liệu như VendorName, VendorAddress, VendorPhone, và các trường bổ sung khác — nêu rõ ý nghĩa, kiểu dữ liệu mong đợi, và loại suy luận (inference type) của từng trường trích xuất (như được mô tả trong phần Creating Blueprints for Extraction), được minh họa trong hình dưới:\nHai blueprint này được thêm vào Amazon Bedrock Data Automation project. Một project trong Amazon Bedrock Data Automation là tập hợp các blueprint chuẩn và tùy chỉnh, cho phép xử lý nhiều loại tệp khác nhau (ví dụ: tài liệu, âm thanh, hình ảnh) với cấu hình riêng biệt. Bạn có thể kiểm soát loại thông tin cần trích xuất từ từng loại tệp. Khi project được kích hoạt bất đồng bộ (asynchronously invoked), hệ thống sẽ tự động áp dụng blueprint phù hợp, trích xuất các thông tin như confidence scores và bounding box details cho từng trường dữ liệu, rồi lưu kết quả vào một S3 bucket riêng biệt. Cơ chế phân loại thông minh này giúp loại bỏ nhu cầu viết thủ công các thuật toán phân loại tài liệu phức tạp.\nHình dưới đây minh họa quá trình phân loại tài liệu bởi blueprint tiêu chuẩn US-Bank-Check:\nHình tiếp theo thể hiện kết quả phân loại tài liệu sử dụng blueprint tùy chỉnh\nbenefit-claims-pharmacy-receipt-blueprint:\nSau khi dữ liệu được trích xuất, hệ thống chuyển sang giai đoạn xác thực và ra quyết định, dựa trên các quy tắc nghiệp vụ (business rules) được định nghĩa riêng cho từng loại tài liệu.\nCác quy tắc nghiệp vụ này được mô tả trong các tài liệu quy trình vận hành tiêu chuẩn (AnyCompany Benefit Checks Standard Operating procedure.docx và AnyCompany Benefit Claims Standard Operating procedure.docx) và được tải lên Amazon S3 bucket. Sau đó hệ thống tạo knowledge base cho Amazon Bedrock, sử dụng bucket này làm nguồn dữ liệu, như minh họa trong hình bên dưới:\nKhi kết quả trích xuất từ Amazon Bedrock Data Automation được lưu trong S3 bucket đã cấu hình, một AWS Lambda function sẽ được tự động kích hoạt. Dựa trên các quy tắc nghiệp vụ lấy từ knowledge base tương ứng với từng loại tài liệu và dữ liệu đầu ra từ Amazon Bedrock Data Automation, mô hình ngôn ngữ lớn Amazon Nova Lite sẽ thực hiện tự động phê duyệt hoặc từ chối (approve/deny) các yêu cầu hoàn tiền.\nHình dưới đây minh họa kết quả tự động phê duyệt yêu cầu bồi hoàn cho blueprint US-Bank-Check:\nHình tiếp theo minh họa kết quả tự động phê duyệt cho blueprint benefit-claims-pharmacy-receipt-blueprint:\nTích hợp Hệ thống được thiết kế để tích hợp liền mạch với quy trình nghiệp vụ hiện có.\nKhi quá trình xác thực hoàn tất, một sự kiện (event) sẽ được gửi đến Amazon EventBridge, kích hoạt Lambda function để xử lý tích hợp downstream. Trong triển khai này, hệ thống sử dụng Amazon DynamoDB và Amazon Simple Notification Service (Amazon SNS) để phục vụ việc tích hợp. Một bảng DynamoDB được tạo như một phần của deployment stack, dùng để lưu thông tin như phân loại tài liệu, dữ liệu trích xuất, và quyết định tự động. Thông báo email được gửi thông qua Amazon SNS cho cả trường hợp séc và biên lai sau khi hệ thống đưa ra quyết định cuối cùng.\nHình dưới minh họa ví dụ email thông báo phê duyệt cho biên lai nhà thuốc:\nKiến trúc linh hoạt này cho phép bạn tích hợp với các ứng dụng nội bộ thông qua API hoặc sự kiện (event) để cập nhật trạng thái yêu cầu hoàn tiề hoặc kích hoạt quy trình bổ sung khi việc xác thực không thành công.\nGiảm thiểu nỗ lực thủ công bằng quản lý quy tắc nghiệp vụ thông minh Bên cạnh việc tự động hóa xử lý tài liệu, giải pháp này còn giải quyết một thách thức vận hành phổ biến: Trước đây, khách hàng phải tự viết và duy trì mã nguồn (code) để xử lý các quy tắc nghiệp vụ (business rules) liên quan đến xét duyệt (adjudication) và xử lý yêu cầu bồi hoàn (claims processing). Mỗi khi có sự thay đổi về quy tắc nghiệp vụ, nhóm phát triển phải cập nhật mã, dẫn đến tăng thời gian triển khai, giảm tốc độ đưa sản phẩm ra thị trường (time-to-market), và gia tăng chi phí bảo trì.\nCách tiếp cận mới sử dụng Amazon Bedrock Knowledge Bases để chuyển đổi các quy tắc nghiệp vụ và tài liệu quy trình vận hành tiêu chuẩn (Standard Operating Procedures - SOPs) thành cơ sở tri thức (knowledge bases) phục vụ tự động ra quyết định (automated decision-making). Cách tiếp cận này có thể rút ngắn đáng kể thời gian triển khai khi có thay đổi về quy tắc nghiệp vụ, vì các cập nhật có thể được thực hiện thông qua quản lý tri thức thay vì triển khai lại mã nguồn.\nTrong các phần tiếp theo, chúng tôi sẽ hướng dẫn bạn từng bước triển khai giải pháp vào tài khoản AWS của riêng bạn.\nYêu cầu ban đầu Để triển khai giải pháp được trình bày trong bài viết này, bạn cần:\nMột tài khoản AWS account Quyền truy cập Amazon Titan Text Embeddings V2 và Amazon Nova Lite foundation models (FMs) đã được kích hoạt trong Amazon Bedrock Giải pháp này sử dụng Python 3.13 với Boto3 phiên bản 1.38 hoặc cao hơn, cùng AWS Serverless Application Model Command Line Interface (AWS SAM CLI) phiên bản 1.138.0. Chúng tôi giả định bạn đã cài đặt các công cụ này trên máy cục bộ. Nếu chưa, hãy tham khảo các hướng dẫn sau:\nPython 3.13 installation Install the AWS SAM CLI Thiết lập mã nguồn trong máy cục bộ Để thiết lập mã, clone GitHub repository chứa mã nguồn của giải pháp.\nSau khi clone về máy, cấu trúc thư mục dự án sẽ giống như ví dụ trong tệp README:\nTriển khai giải pháp trong tài khoản của bạn Mã mẫu đi kèm với CloudFormation template, giúp tự động tạo các tài nguyên cần thiết.Để triển khai giải pháp trên tài khoản AWS của bạn, hãy làm theo hướng dẫn triển khai trong README file.\nDọn dẹp Việc triển khai giải pháp này trong tài khoản AWS sẽ phát sinh chi phí sử dụng dịch vụ. Hãy làm theo hướng dẫn dọn dẹp trong README file để tránh bị tính phí sau khi bạn đã hoàn tất thử nghiệm.\nKết luận Các công ty trong lĩnh vực quản lý quyền lợi nhân viên (benefits administration) có thể nâng cao đáng kể hiệu quả vận hành bằng cách tự động hóa xử lý yêu cầu bồi hoàn (claims processing) thông qua giải pháp được trình bày trong bài viết này. Cách tiếp cận chiến lược này trực tiếp giải quyết các thách thức cốt lõi của ngành, mang lại nhiều lợi ích then chốt:\nNâng cao hiệu suất xử lý nhờ tăng tốc thời gian giải quyết yêu cầu, giảm lỗi thủ công, và tăng tỷ lệ xử lý tự động (straight-through processing rate), giúp loại bỏ tình trạng chậm trễ và khối lượng tái xử lý lớn từ các hệ thống cũ. Hợp nhất xử lý tài liệu và phát hiện gian lận nhờ các blueprint mới trong Amazon Bedrock Data Automation, cho phép tích hợp nhanh các loại tài liệu hỗ trợ mới, đồng thời AI-powered analytics phát hiện mẫu gian lận (fraud patterns) mà không làm chậm yêu cầu hợp lệ, giảm thiểu chi phí gian lận, lãng phí và sai phạm.\nQuản lý quy tắc nghiệp vụ linh hoạt (Agile business rule management) cho phép thích ứng nhanh với các yêu cầu thay đổi của HIPAA và ERISA, giúp giảm chi phí vận hành, rút ngắn thời gian triển khai, tăng khả năng mở rộng và tích hợp với các hệ thống HRIS và claims hiện có. Điều này giúp nâng cao sự hài lòng của nhân viên, củng cố mối quan hệ với nhà cung cấp dịch vụ, và duy trì sức cạnh tranh trong chính sách phúc lợi, yếu tố quan trọng trong giữ chân nhân tài và xây dựng thương hiệu nhà tuyển dụng (employer branding).\nĐể bắt đầu với giải pháp này, hãy tham khảo GitHub repo được cung cấp. Để tìm hiểu thêm về Amazon Bedrock Data Automation, vui lòng xem bài viết “Transform unstructured data into meaningful insights using Amazon Bedrock Data Automation” và tham gia workshop “Document Processing Using Amazon Bedrock Data Automation”.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Thúc đẩy việc ứng dụng AI ở quy mô lớn thông qua khung quản lý rủi ro doanh nghiệp – Phần 2 Trong Phần 1 của loạt bài này, chúng ta đã khám phá các rủi ro cơ bản và các yếu tố cần cân nhắc trong quản trị. Trong phần này, chúng ta sẽ xem xét các chiến lược thực tiễn để điều chỉnh Enterprise Risk Management Framework (ERMF) của doanh nghiệp, nhằm khai thác sức mạnh của Generative AI trong khi vẫn duy trì các biện pháp kiểm soát chặt chẽ.\nPhần này bao gồm:\nĐiều chỉnh ERMF cho môi trường cloud Điều chỉnh ERMF cho generative AI Quản lý rủi ro bền vững Kết thúc bài viết này, bạn sẽ có một lộ trình để mở rộng việc ứng dụng generative AI một cách an toàn và có trách nhiệm.\nĐiều chỉnh ERMF cho môi trường Cloud Trước khi đi sâu vào các biện pháp kiểm soát cụ thể cho generative AI, điều quan trọng là phải hiểu hạ tầng cơ bản tạo điều kiện cho các công nghệ này. Cloud computing chính là nền tảng hạ tầng đã giúp generative AI trở nên khả thi và có thể mở rộng. Việc phát triển và triển khai large language models và các hệ thống generative AI khác đòi hỏi nguồn tài nguyên tính toán khổng lồ, dung lượng lưu trữ dữ liệu lớn, và khả năng xử lý phân tán tinh vi — tất cả đều được cloud systems cung cấp hiệu quả.\nCông nghệ cloud khác với các giải pháp on-premises IT, và mối quan hệ giữa các tổ chức tài chính với cloud service providers cũng khác với mối quan hệ truyền thống với outsourcing providers.\nNhững khác biệt này làm thay đổi bản chất của nhiều rủi ro mà các tổ chức tài chính phải đối mặt cũng như cách họ quản lý rủi ro. Tuy nhiên, nếu được triển khai đúng cách, cloud technology có thể giảm thiểu rủi ro và đồng thời cung cấp các công cụ giúp Chief Risk Officers (CROs) quản lý rủi ro tốt hơn.\nBạn có thể đọc thêm về cách ERMF cần thay đổi để phù hợp với việc ứng dụng cloud ở quy mô lớn trong bài viết Is your Enterprise Risk Management Framework ready for the Cloud?\nĐiều chỉnh ERMF cho Generative AI Các tổ chức đang áp dụng generative AI có thể sử dụng ERMF của mình để khai thác giá trị kinh doanh trong khi vẫn duy trì các biện pháp kiểm soát phù hợp. Cách tiếp cận này cho phép doanh nghiệp xây dựng dựa trên các quy trình quản lý rủi ro hiện có, đồng thời xử lý các đặc thù riêng của generative AI. Đối với phương pháp tiếp cận có cấu trúc nhằm chuyển đổi AI dựa trên cloud, AWS Cloud Adoption Framework for AI, ML, and generative AI (AWS CAF for AI) cung cấp hướng dẫn triển khai chi tiết phù hợp với các nguyên tắc của quản lý rủi ro doanh nghiệp. Để có hướng dẫn cụ thể hơn, hãy xem AWS User Guide to Governance, Risk and Compliance for Responsible AI Adoption within Financial Services Industries, có sẵn trong AWS Artifact khi bạn đăng nhập AWS account. AWS Artifact cung cấp các báo cáo bảo mật và tuân thủ của AWS, giúp tổ chức duy trì tuân thủ thông qua best practices. Đối với quản lý mô hình và vòng đời hệ thống AI, khách hàng có thể tham khảo ISO42001 AI Management, Section A6. Phần này bao gồm việc xác định mục tiêu và quy trình cho thiết kế, phát triển AI có trách nhiệm, bao gồm tiêu chí và yêu cầu cho từng giai đoạn của vòng đời hệ thống AI. Hướng dẫn này giúp tổ chức đảm bảo rằng các thực hành quản lý mô hình của họ phù hợp với tiêu chuẩn ngành về phát triển Responsible AI. Từ góc nhìn của nhà lãnh đạo doanh nghiệp, việc tích hợp các yếu tố generative AI vào ERMF giúp thiết lập các good practices được ghi nhận, triển khai các biện pháp kiểm soát hiệu quả và duy trì tính minh bạch trong toàn doanh nghiệp. Điều này vừa thúc đẩy đổi mới có trách nhiệm vừa đảm bảo quản lý rủi ro thận trọng. Dưới đây là cách các tổ chức đang tiếp cận vấn đề này:\nCơ sở chính sách và quản trị Generative AI trong ERMF Trong lĩnh vực generative AI, các tổ chức thiết lập cả guardrails cho đổi mới và accountability rõ ràng cho quản lý rủi ro. Three lines of defense model cung cấp cấu trúc để triển khai những yếu tố nền tảng này:\nKhung sử dụng hợp lý cho tổ chức: Định hướng rõ ràng về việc sử dụng generative AI giúp quản lý rủi ro trong khi vẫn khuyến khích đổi mới. Phạm vi ứng dụng của generative AI rất rộng và sẽ tiếp tục mở rộng, nên việc có hướng dẫn cụ thể về những ứng dụng được phép và trong điều kiện nào là điều thiết yếu. Khi các tổ chức khám phá cơ hội này, khung đó có thể phát triển theo mức độ kinh nghiệm và trưởng thành của họ. Trách nhiệm quản lý rủi ro: Vòng đời của Generative AI — từ việc lựa chọn use case, triển khai, cho đến giám sát liên tục — đòi hỏi phải có sự sở hữu rõ ràng giữa các bộ phận kinh doanh và các chức năng kiểm soát. Mặc dù tổ chức có thể thiết lập các cơ chế giám sát riêng cho Generative AI, nhưng những cơ chế này nên được tích hợp vào cấu trúc quản trị hiện có. Các báo cáo rủi ro và trách nhiệm giải trình liên quan đến các sáng kiến Generative AI cần được chuyển qua các ủy ban rủi ro doanh nghiệp (enterprise risk committees) và hội đồng quản trị rủi ro (governance boards) hiện hành, giúp đảm bảo quản lý rủi ro nhất quán trên toàn tổ chức, thay vì tạo ra các khu vực giám sát rời rạc. Cách triển khai Generative AI: Đưa nguyên tắc vào thực tiễn Dựa trên three lines of defense model, các tổ chức có thể điều chỉnh thực hành quản lý rủi ro để đáp ứng các đặc điểm riêng của generative AI, đồng thời sử dụng industry best practices và frameworks hiện có. Điều này thường bao gồm việc phát triển thêm các biện pháp kiểm soát sẵn có và bổ sung các biện pháp mới dành riêng cho generative AI. Các dịch vụ của AWS tích hợp sẵn các năng lực hỗ trợ cho các yêu cầu về governance, risk management, và compliance, giúp tổ chức triển khai generative AI một cách có kiểm soát và có trách nhiệm — ví dụ như Amazon Bedrock Guardrails, cùng nhiều dịch vụ khác.\nDựa trên các khu vực rủi ro đã được xác định trước đó, chúng ta sẽ khám phá cách các tổ chức có thể triển khai controls cho từng khu vực. Với mỗi khu vực, bài viết mô tả nguyên tắc và các yếu tố cần xem xét khi triển khai thực tế.Mặc dù mức độ ưu tiên có thể khác nhau tùy theo use case và risk appetite, nhưng tổng thể, chúng hình thành nên một framework cho việc ứng dụng generative AI có trách nhiệm thông qua ERMF.\nTrong khi bài viết tập trung vào các nguyên tắc kiểm soát ở cấp cao, các nhóm kỹ thuật có thể tham khảo AWS Well-Architected Framework – Generative AI Lens để có hướng dẫn chi tiết về kiến trúc hỗ trợ các mục tiêu quản trị này.\nCông bằng Hệ thống Generative AI có thể mang lại kết quả công bằng giữa các nhóm bên liên quan khác nhau, giúp tổ chức xây dựng niềm tin và đáp ứng kỳ vọng. Các tổ chức có thể hỗ trợ điều này bằng cách thiết lập các chỉ số công bằng rõ ràng cho từng use case cụ thể, đánh giá thường xuyên dữ liệu huấn luyện để phát hiện thiên vị, và giám sát hiệu suất giữa các nhóm người dùng khác nhau. Đối với các ứng dụng có mức độ ảnh hưởng cao, việc bổ sung kiểm tra bổ sung giúp đảm bảo đối xử công bằng giữa các nhóm dân cư đa dạng.\nAmazon Bedrock Guardrails cung cấp các biện pháp bảo vệ có thể cấu hình để duy trì kết quả đầu ra công bằng và không thiên vị, cùng với các ngưỡng tùy chỉnh phù hợp với yêu cầu của từng use case. Amazon Bedrock còn cung cấp các công cụ đánh giá mô hình toàn diện, bao gồm model card chứa các chỉ số thiên vị chi tiết, giúp đánh giá thiên vị theo các nhóm nhân khẩu học. Ngoài ra, Bedrock bao gồm bộ dữ liệu prompt sẵn có như Bias in Open-ended Language Generation Dataset (BOLD), cho phép tự động đánh giá công bằng trong các lĩnh vực như nghề nghiệp, giới tính, chủng tộc và hệ tư tưởng. Những khả năng này tích hợp với Amazon SageMaker Clarify để hỗ trợ phát hiện và giảm thiểu thiên vị, với các chỉ số và báo cáo tích hợp sẵn.\nGiải thích Hệ thống Generative AI cần cung cấp khả năng giải thích quy trình ra quyết định, nhằm đảm bảo trách nhiệm giải trình và giám sát hiệu quả. Tính giải thích là yếu tố thiết yếu trong mọi hệ thống Generative AI — dù được tùy chỉnh riêng hay sử dụng sẵn, đặc biệt đối với các mô hình phức tạp như Transformer networks.\nTổ chức có thể triển khai kiểm soát thực tế bằng cách xác lập ngưỡng giải thích rõ ràng dựa trên mức độ rủi ro của từng use case. Đây vẫn là một thách thức trong ngành, với nhiều nghiên cứu và phương pháp tiếp cận đang phát triển. Đối với các ứng dụng kinh doanh quan trọng, tùy chỉnh phần giải thích theo từng nhóm đối tượng trong khi vẫn duy trì độ chính xác giúp cải thiện sự hiểu biết và niềm tin.\nAmazon Bedrock cung cấp các công cụ xác định yếu tố ảnh hưởng đến quyết định của mô hình, đồng thời lưu trữ chi tiết đầu vào và đầu ra của hệ thống. Đối với các quy trình phức tạp, Amazon Bedrock Agents hỗ trợ Chain-of-Thought (CoT) reasoning traces, giúp minh họa logic từng bước của mô hình trong quá trình suy luận. Các tổ chức có thể theo dõi phản hồi theo thời gian thực, đặc biệt trong ứng dụng Retrieval-Augmented Generation (RAG), nơi Amazon Bedrock Knowledge Bases tự động chèn nguồn tham chiếu và liên kết tài liệu gốc được sử dụng trong quá trình tạo phản hồi.\nBảo mật và quyền riêng tư Các hệ thống Generative AI cần được bảo vệ bằng biện pháp bảo mật và quyền riêng tư mạnh mẽ để bảo vệ thông tin nhạy cảm và ngăn ngừa truy cập trái phép hoặc rò rỉ dữ liệu. Các hệ thống này có thể vô tình tạo ra nội dung hoặc tiết lộ dữ liệu mật, điều mà tổ chức cần chủ động kiểm soát. Tổ chức có thể thiết lập chiến lược bảo vệ đa tầng, bao gồm kiểm soát truy cập, lọc nội dung, và các biện pháp bảo vệ dữ liệu cá nhân. Điều này có thể bao gồm việc tạo chuẩn chung cho prompt engineering để tránh đầu ra độc hại, sử dụng RAG để kiểm soát nguồn thông tin, và triển khai hệ thống tự động phát hiện – bảo vệ dữ liệu cá nhân. Kiểm thử và xác thực định kỳ, đặc biệt để tuân thủ các quy định như GDPR, là một phần trong quá trình phát triển và triển khai. Amazon Bedrock áp dụng nhiều lớp bảo mật, bao gồm private endpoints với sự hỗ trợ của Amazon Virtual Private Cloud (Amazon VPC), AWS Identity and Access Management (IAM), và mã hóa đầu cuối. Đặc biệt, Bedrock không lưu trữ lâu dài dữ liệu prompt hoặc completion và duy trì sự tách biệt giữa các nhà cung cấp mô hình. Amazon Bedrock Guardrails hỗ trợ lọc thông tin nhạy cảm (PII) thông qua tự động từ chối đầu vào, ẩn dữ liệu trong phản hồi, và mẫu regex tùy chỉnh, đáp ứng nhiều use case mà vẫn đảm bảo bảo mật dữ liệu. Ví dụ, Genesys đã minh chứng khả năng này ở quy mô lớn khi duy trì tuân thủ GDPR trong khi xử lý hơn 1,5 tỷ tương tác khách hàng mỗi tháng thông qua Amazon Bedrock. Để biết thêm chi tiết, xem Generative AI Security Scoping Matrix, cung cấp khung đánh giá toàn diện cho các rủi ro bảo mật trong Generative AI.\nAn toàn Hệ thống Generative AI cần được thiết kế và vận hành với các cơ chế bảo vệ để tránh gây hại cho cá nhân và cộng đồng. Điều này bao gồm ngăn chặn việc tạo ra nội dung nguy hiểm, bất hợp pháp hoặc lạm dụng, và phòng tránh việc sử dụng sai mục đích hệ thống.\nTổ chức có thể triển khai biện pháp an toàn cụ thể như lọc nội dung trước khi triển khai, giới hạn thời gian thực qua prompt constraints, và phân loại đầu ra để phát hiện – chặn nội dung nguy hiểm. Kiểm duyệt nội dung theo ngữ cảnh giúp phù hợp với lĩnh vực ứng dụng, trong khi phát hiện tự động giúp nhận biết vi phạm an toàn tiềm ẩn trước khi nội dung được tạo ra. Giám sát liên tục và cập nhật định kỳ giúp giảm thiểu các rủi ro mới nổi từ khả năng tiến hóa của mô hình Generative AI.\nAmazon Bedrock Guardrails mang lại khả năng bảo vệ an toàn hàng đầu ngành cho cả văn bản và hình ảnh, ngăn chặn hơn 85% nội dung độc hại ngoài khả năng bảo vệ gốc của các foundation model (FM).Các biện pháp an toàn bổ sung bao gồm giới hạn token, rate limiting, và moderation endpoints để kiểm duyệt nội dung.\nĐể biết hướng dẫn chi tiết về triển khai, xem Build safe and responsible generative AI applications with guardrails.\nKhả năng kiểm soát Các tổ chức có thể duy trì mức độ kiểm soát phù hợp đối với hệ thống Generative AI để đảm bảo rằng chúng hoạt động như mong đợi và có thể được điều chỉnh hoặc dừng lại khi xảy ra sự cố. Điều này giúp quản lý rủi ro và duy trì độ tin cậy của hệ thống.\nCách tiếp cận đa tầng trong kiểm soát bao gồm việc triển khai các biện pháp kỹ thuật và quy trình vận hành. Các tổ chức có thể kiểm soát hành vi của mô hình bằng cách điều chỉnh các tham số như temperature (kiểm soát mức độ ngẫu nhiên của đầu ra) và các phương pháp sampling như top-k hoặc top-p (quản lý mức độ đa dạng của đầu ra). Việc xác định ranh giới vận hành rõ ràng giúp định nghĩa phạm vi hành động của hệ thống, trong khi human-in-the-loop validation cung cấp lớp giám sát bổ sung cho các ứng dụng quan trọng.\nĐể đạt được hiệu quả kiểm soát cao, tổ chức có thể thiết lập ngưỡng tham số riêng cho từng use case, triển khai cơ chế điều chỉnh nhanh, và tạo quy trình xử lý leo thang rõ ràng. Amazon Bedrock tăng cường khả năng kiểm soát thông qua tùy chỉnh agent prompt, kỹ thuật reasoning, và khả năng chia nhỏ các tác vụ phức tạp thành các thành phần nhỏ dễ quản lý hơn. Các tổ chức có thể lựa chọn giữa workflow có cấu trúc hoặc phương pháp linh hoạt dựa trên agent. Việc so sánh định kỳ đầu ra với các benchmark chuẩn giúp duy trì tính ổn định và độ tin cậy của hệ thống.\nCách tiếp cận cân bằng này hỗ trợ sự sáng tạo trong đầu ra AI đồng thời giúp đảm bảo hiệu suất ổn định trong giới hạn chất lượng đã xác định, qua đó ngăn ngừa suy giảm dịch vụ và gián đoạn kinh doanh trong khi giảm thiểu lãng phí tài nguyên.\nKhả năng kiểm soát còn được tăng cường thông qua tích hợp giám sát với Amazon CloudWatch và cơ chế kiểm soát phiên bản của knowledge base. Các tính năng của Amazon Bedrock, bao gồm LLM-as-a-judge features, giúp tổ chức đánh giá và tối ưu hóa ứng dụng Generative AI một cách hiệu quả và có kiểm soát.\nTính xác thực và độ vững chắc Các hệ thống Generative AI có thể tạo ra kết quả đáng tin cậy và chính xác, ngay cả khi gặp đầu vào bất ngờ hoặc phức tạp. Điều này giúp duy trì niềm tin và bảo đảm tính hữu dụng của hệ thống trong nhiều loại ứng dụng khác nhau. Các tổ chức có thể triển khai sự kết hợp giữa kiểm soát kỹ thuật và quy trình để nâng cao độ vững chắc của hệ thống cũng như độ tin cậy của đầu ra. Điều này bao gồm việc thiết lập ngưỡng tham số rõ ràng cho từng use case, triển khai human-in-the-loop validation cho các ứng dụng quan trọng, và so sánh định kỳ đầu ra với ground truth đã được xác lập. Khung quản lý này xác định khi nào và cách thức áp dụng các biện pháp kiểm soát dựa trên mức độ quan trọng của use case và yêu cầu về độ chính xác.\nAmazon Bedrock Guardrails cải thiện tính xác thực bằng cách ngăn ngừa lỗi sai thực tế thông qua kiểm tra suy luận tự động, đạt độ chính xác lên đến 99% trong việc phát hiện phản hồi chính xác từ mô hình, bằng cách sử dụng logic toán học và kỹ thuật xác minh hình thức (formal verification). Khả năng này hỗ trợ xử lý tài liệu lớn lên đến 80.000 tokens, đồng thời bao gồm tự động tạo kịch bản kiểm thử (scenario generation) để đảm bảo kiểm thử toàn diện. Amazon Bedrock cũng tích hợp tính năng làm sạch đầu vào (input sanitization) nâng cao và hỗ trợ kiểm thử đối kháng (adversarial testing) thông qua tích hợp với các công cụ kiểm thử AWS.\nQuản trị Việc quản trị hiệu quả các hệ thống Generative AI giúp quản lý rủi ro, duy trì trách nhiệm giải trình, và đảm bảo việc sử dụng AI phù hợp với các giá trị và quy định của tổ chức. Quản trị bao phủ toàn bộ vòng đời của AI, từ giai đoạn phát triển, triển khai cho đến vận hành liên tục.\nCác tổ chức có thể xây dựng cấu trúc quản trị rõ ràng, bao gồm xác định vai trò trong việc giám sát AI, thực hiện đánh giá rủi ro định kỳ, và tăng cường tương tác với các bên liên quan. Điều này đòi hỏi tích hợp quản trị AI vào các thực tiễn quản lý rủi ro hiện có, đồng thời đảm bảo tuân thủ các luật và tiêu chuẩn liên quan. Do công nghệ AI đang phát triển nhanh chóng, việc đánh giá và cập nhật thường xuyên các quy trình quản trị là điều cần thiết để giải quyết các năng lực mới, rủi ro phát sinh, và các yêu cầu pháp lý thay đổi. Điều này cũng bao gồm đào tạo và phát triển kỹ năng phù hợp cho người sử dụng hệ thống.\nAWS đã nhận được chứng chỉ ISO/IEC 42001 , thể hiện cam kết đối với phương pháp quản trị có hệ thống trong triển khai AI. Các tính năng quản trị trong Amazon Bedrock bao gồm: Theo dõi nguồn gốc mô hình (model provenance tracking) toàn diện, ghi nhật ký kiểm toán chi tiết qua AWS CloudTrail, luồng phê duyệt triển khai mô hình tích hợp với AWS Organizations. Ngoài ra, AWS Audit Manager cung cấp các framework dựng sẵn để đánh giá việc triển khai Generative AI so với các thực tiễn tốt nhất.\nTính minh bạch Các hệ thống Generative AI có thể vận hành một cách minh bạch, giúp các bên liên quan hiểu rõ năng lực, giới hạn và ngữ cảnh của các đầu ra do AI tạo ra. Điều này góp phần xây dựng niềm tin và cho phép người dùng cũng như các bên bị ảnh hưởng đưa ra quyết định có cơ sở hơn. Các tổ chức có thể thực hiện các biện pháp minh bạch cụ thể, bao gồm việc xây dựng tài liệu mô hình toàn diện mô tả chi tiết mục đích sử dụng, giới hạn đã biết và phạm vi hiệu suất của mô hình. Việc công bố rõ ràng về việc sử dụng AI cần nêu rõ thời điểm, cách thức và loại dữ liệu được xử lý. Ngoài ra, các báo cáo hiệu suất định kỳ có thể bao gồm tỷ lệ chính xác, các mẫu lỗi và đánh giá thiên vị (bias). Đối với các ứng dụng hướng đến khách hàng, tính minh bạch còn bao gồm việc cung cấp chỉ báo rõ ràng về nội dung do AI tạo ra, giải thích cách thức ra quyết định của hệ thống, và thiết lập quy trình để người dùng có thể đặt câu hỏi hoặc phản hồi về kết quả đầu ra. Việc duy trì lịch sử chi tiết về các phiên bản mô hình và thay đổi trong hành vi hệ thống giúp theo dõi sự tiến hóa của năng lực AI và tác động của chúng theo thời gian. Từ phía AWS, trong khuôn khổ Shared Responsibility Model, tính minh bạch được hỗ trợ thông qua AWS AI Service Cards và tài liệu chi tiết mô tả đặc tính của mô hình. Amazon Bedrock tăng cường điều này bằng khả năng ghi nhật ký và giám sát toàn diện, giúp theo dõi hành vi của mô hình và các chỉ số hiệu suất một cách hiệu quả.\nQuản lý rủi ro thống nhất Tám khía cạnh trên liên kết chặt chẽ và củng cố lẫn nhau trong khuôn khổ quản lý rủi ro doanh nghiệp (enterprise risk management framework). Mặc dù các tổ chức có thể ưu tiên khác nhau tùy theo use case và mức độ chấp nhận rủi ro, nhưng khi kết hợp, chúng cung cấp cách tiếp cận toàn diện để triển khai Generative AI có trách nhiệm. Để biết thêm hướng dẫn kỹ thuật chi tiết, tiêu chuẩn, và yêu cầu tuân thủ, vui lòng tham khảo các tài liệu hướng dẫn AWS trong phần Resources ở cuối bài blog, hỗ trợ việc triển khai trên tất cả các lĩnh vực này.\nQuản lý rủi ro AI trong thực tiễn: Xây dựng năng lực tổ chức Việc triển khai thành công các hệ thống AI sinh sinh đòi hỏi phải tích hợp các thực tiễn quản lý rủi ro trên toàn tổ chức. Điều này bao gồm việc thiết lập các quy trình để đo lường kết quả và rủi ro, cũng như chuẩn bị cho tổ chức thích ứng khi công nghệ phát triển. Quản lý rủi ro hiệu quả phụ thuộc vào việc xây dựng kiến thức và kỹ năng phù hợp ở mọi cấp độ trong tổ chức.\nCác tổ chức có thể tạo ra lộ trình rõ ràng từ giai đoạn thử nghiệm khái niệm (proof of concept) đến triển khai thực tế bằng cách tuân theo mô hình “ba tuyến phòng thủ” (three lines of defense model). Khung ERMF cung cấp các tham số tổng thể về độ tin cậy, an toàn và quyền riêng tư, mà các đơn vị kinh doanh có thể điều chỉnh để phù hợp với từng trường hợp sử dụng cụ thể.\nĐể xây dựng và duy trì năng lực bền vững cho việc áp dụng AI sinh sinh trong hiện tại và tương lai, các tổ chức có thể tập trung vào:\nPhát triển các kế hoạch ứng phó sự cố dành riêng cho các tình huống liên quan đến AI Xây dựng chuyên môn thông qua các chương trình đào tạo và chứng nhận Đánh giá và cập nhật thường xuyên các thực tiễn quản lý rủi ro Khi những yếu tố này được tích hợp vào cấu trúc vận hành của tổ chức, chúng sẽ tạo ra các thực tiễn bền vững có thể phát triển song song với sự tiến bộ của công nghệ và sự xuất hiện của các rủi ro mới. Quản lý rủi ro bền vững: Chuẩn bị ERMF của bạn sẵn sàng cho Generative AI Các lãnh đạo phụ trách quản trị, rủi ro và tuân thủ (GRC), cùng với Giám đốc Quản lý Rủi ro (CRO) và Giám đốc Kiểm toán Nội bộ (CIA) có thể đóng vai trò bảo trợ chiến lược lâu dài cho việc áp dụng Generative AI. Việc xây dựng năng lực dài hạn cần được mở rộng ra ngoài phạm vi công nghệ và đổi mới sáng tạo, bao gồm cả các chức năng kinh doanh và kiểm soát nội bộ. Sự định hướng rõ ràng từ ban lãnh đạo giúp tổ chức cân bằng giữa cơ hội và rủi ro khi áp dụng Generative AI.\nCác tổ chức được hưởng lợi khi xem Generative AI như một năng lực chuyển đổi toàn diện có ảnh hưởng đến nhiều bộ phận, thay vì coi đây là một sáng kiến tách biệt. Cách tiếp cận này giúp tích hợp bền vững các cơ chế quản trị doanh nghiệp cho Generative AI, đồng thời tránh hạn chế của các dự án ngắn hạn với phạm vi và tác động hạn chế.\nCác tổ chức có thể triển khai Generative AI một cách có kiểm soát và có trách nhiệm, đồng thời duy trì nghĩa vụ quản lý rủi ro thông qua những trường hợp sử dụng được xác định rõ ràng. Ví dụ, Parameta, một bộ phận thuộc TP ICAP, đã thể hiện phương pháp này trong việc triển khai AI phục vụ tuân thủ quy định pháp lý. Bằng cách tập trung trước tiên vào lĩnh vực có mức độ điều tiết cao, duy trì cơ chế quản trị chặt chẽ và đảm bảo sự giám sát của con người trong quá trình kiểm duyệt, họ đã xây dựng khung quản trị cho việc áp dụng AI có trách nhiệm — đồng thời tạo ra các vai trò giám sát chuyên biệt cho các sáng kiến AI trong tương lai.\nTương tự, Rocket Mortgage đã triển khai Amazon Bedrock for responsible AI một cách có trách nhiệm và ở quy mô lớn cho công cụ Rocket Logic – Synopsis. Cách tiếp cận này giúp họ duy trì các biện pháp bảo mật và tuân thủ nghiêm ngặt, đồng thời tiết kiệm 40.000 giờ làm việc mỗi năm nhờ tự động hóa quy trình.\nDanh sách hành động cho việc triển khai Generative AI bền vững: Nền tảng ERMF: Đánh giá và nâng cao mức độ sẵn sàng của khung quản lý rủi ro cho Generative AI, bao gồm hướng dẫn sử dụng hợp lý và phân định rõ trách nhiệm. Kiểm soát kỹ thuật: Bắt đầu với các biện pháp kiểm soát cốt lõi như Amazon Bedrock Guardrails, sau đó mở rộng theo trường hợp sử dụng và hồ sơ rủi ro cụ thể. Năng lực tổ chức: Phát triển chuyên môn toàn diện thông qua đào tạo và cơ chế giám sát giữa các bộ phận kinh doanh và kiểm soát. Giám sát và đo lường: Xây dựng bảng điều khiển (dashboard) để theo dõi các chỉ số rủi ro chính (KRI) và tiến hành đánh giá định kỳ. Chiến lược tích hợp: Liên kết các biện pháp kiểm soát Generative AI với quy trình và chiến lược tổ chức hiện có, đảm bảo sự thống nhất và hiệu quả dài hạn. Kết luận Chuỗi bài viết gồm hai phần này đã khám phá tầm quan trọng cốt lõi của việc tích hợp quản trị AI sinh sinh vào trong các khung quản lý rủi ro doanh nghiệp (ERMF). Trong Phần 1, chúng tôi đã giới thiệu các rủi ro đặc thù và những yếu tố quản trị cần xem xét khi áp dụng AI sinh sinh. Phần 2 cung cấp hướng dẫn toàn diện để điều chỉnh ERMF nhằm giải quyết hiệu quả những thách thức này.\nChúng tôi đã trình bày các chiến lược thực tiễn giúp mở rộng việc áp dụng AI sinh sinh một cách an toàn và có trách nhiệm, bao gồm các lĩnh vực then chốt như công bằng, khả năng giải thích, quyền riêng tư và bảo mật, an toàn, khả năng kiểm soát, tính xác thực và độ vững chắc, quản trị và tính minh bạch. Bằng cách triển khai các chiến lược này và làm theo danh sách hành động được cung cấp, các tổ chức có thể xây dựng các thực tiễn bền vững phát triển song song với sự tiến bộ của công nghệ và sự xuất hiện của các rủi ro mới.\nNhững tổ chức tích hợp quản trị AI sinh sinh vào ERMF như được mô tả trong bài viết này sẽ có vị thế tốt hơn để thúc đẩy đổi mới và hiệu quả vận hành, đồng thời bảo vệ trước các rủi ro trọng yếu như rò rỉ dữ liệu, hiện tượng “ảo giác” của mô hình (model hallucinations) và việc không tuân thủ quy định. Cách tiếp cận cân bằng này cho phép các tổ chức khai thác tiềm năng chuyển đổi của AI sinh sinh trong khi vẫn duy trì các cơ chế kiểm soát mạnh mẽ — điều đặc biệt quan trọng đối với các tổ chức trong lĩnh vực dịch vụ tài chính.\nĐể tìm hiểu về các khái niệm nền tảng và các yếu tố rủi ro, vui lòng xem Phần 1.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Cách PropHero xây dựng một cố vấn đầu tư bất động sản thông minh với khả năng đánh giá liên tục bằng Amazon Bedrock PropHero là một dịch vụ quản lý tài sản bất động sản hàng đầu, giúp dân chủ hóa khả năng tiếp cận các lời khuyên đầu tư bất động sản thông minh thông qua big data, AI và machine learning (ML). Đối với cơ sở khách hàng tại Tây Ban Nha và Úc, PropHero cần một hệ thống tư vấn được hỗ trợ bởi AI có khả năng tương tác với khách hàng trong các cuộc thảo luận đầu tư bất động sản một cách chính xác. Mục tiêu là cung cấp các phân tích đầu tư cá nhân hóa và hướng dẫn, hỗ trợ người dùng ở mọi giai đoạn hành trình đầu tư: từ việc hiểu quy trình, nắm rõ mốc thời gian, tải lên tài liệu một cách an toàn, đến theo dõi tiến độ theo thời gian thực.\nPropHero đã hợp tác với AWS Generative AI Innovation Center để triển khai một cố vấn đầu tư bất động sản thông minh sử dụng AWS generative AI services cùng với hệ thống đánh giá liên tục. Giải pháp cho phép người dùng tham gia các cuộc hội thoại bằng ngôn ngữ tự nhiên về các chiến lược đầu tư bất động sản và nhận các khuyến nghị cá nhân hóa dựa trên kiến thức thị trường toàn diện của PropHero.\nTrong bài viết này, chúng tôi trình bày cách xây dựng một hệ thống AI hội thoại đa tác nhân (multi-agent conversational AI system) sử dụng Amazon Bedrock nhằm cung cấp lời khuyên đầu tư bất động sản được grounding trên kiến thức (knowledge-grounded). Chúng tôi sẽ phân tích kiến trúc của các agent, chiến lược lựa chọn mô hình, và hệ thống đánh giá liên tục toàn diện — những thành phần giúp đảm bảo chất lượng các cuộc hội thoại đồng thời tạo điều kiện cho vòng lặp cải tiến và triển khai nhanh chóng.\nThách thức: Làm cho kiến thức đầu tư bất động sản trở nên dễ tiếp cận hơn Lĩnh vực đầu tư bất động sản đặt ra nhiều thách thức cho cả nhà đầu tư mới lẫn những người có kinh nghiệm. Sự bất cân xứng thông tin tạo ra rào cản khi dữ liệu thị trường toàn diện thường đắt đỏ hoặc khó tiếp cận. Các quy trình đầu tư truyền thống mang tính thủ công, tốn thời gian, và đòi hỏi kiến thức sâu rộng về thị trường để điều hướng hiệu quả.\nĐối với người tiêu dùng tại Tây Ban Nha và Úc, nhóm phát triển cần xây dựng một giải pháp có thể cung cấp lời khuyên đầu tư bất động sản chính xác, phù hợp với ngữ cảnh bằng tiếng Tây Ban Nha, đồng thời xử lý được các cuộc hội thoại phức tạp, nhiều lượt (multi-turn conversations) liên quan đến chiến lược đầu tư.\nHệ thống cần duy trì độ chính xác cao khi cung cấp phản hồi ở quy mô lớn, đồng thời không ngừng học hỏi và cải thiện thông qua tương tác của khách hàng. Quan trọng nhất, hệ thống phải có khả năng hỗ trợ người dùng trong mọi giai đoạn của hành trình đầu tư — từ giai đoạn khởi tạo (onboarding) đến khi hoàn tất giao dịch cuối cùng (final settlement), đảm bảo sự hỗ trợ toàn diện trong toàn bộ quá trình đầu tư.\nTổng quan giải pháp Chúng tôi đã xây dựng một giải pháp hoàn chỉnh end-to-end sử dụng AWS generative AI services, được thiết kế xoay quanh một multi-agent AI advisor với cơ chế continuous evaluation tích hợp. Hệ thống này cho phép luồng dữ liệu liền mạch từ khâu thu thập đến các cuộc hội thoại tư vấn thông minh, được giám sát chất lượng theo thời gian thực. Sơ đồ dưới đây minh họa kiến trúc tổng thể của giải pháp.\nKiến trúc giải pháp bao gồm bốn lớp ảo (virtual layers), mỗi lớp đảm nhận các chức năng riêng trong thiết kế tổng thể của hệ thống.\nData foundation layer Lớp nền tảng dữ liệu cung cấp hạ tầng lưu trữ và truy xuất cho các thành phần của hệ thống:\nAmazon DynamoDB – Lưu trữ nhanh cho lịch sử hội thoại, các chỉ số đánh giá (evaluation metrics), và dữ liệu tương tác người dùng. Amazon Relational Database (Amazon RDS) for PostgreSQL – Cơ sở dữ liệu PostgreSQL lưu trữ dữ liệu quan sát từ LangFuse, bao gồm trace của LLM và các chỉ số độ trễ (latency metrics). Amazon Simple Storage Service (Amazon S3) – Data lake trung tâm lưu trữ tài liệu FAQ tiếng Tây Ban Nha, hướng dẫn đầu tư bất động sản, và tập dữ liệu hội thoại. Multi-agent AI layer Lớp xử lý AI là trung tâm trí tuệ của hệ thống, điều khiển toàn bộ trải nghiệm hội thoại:\nAmazon Bedrock – Cung cấp foundation models (FMs) như LLMs và rerankers để vận hành các agent chuyên biệt. Amazon Bedrock Knowledge Bases – Công cụ tìm kiếm ngữ nghĩa (semantic search engine) với khả năng chia nhỏ dữ liệu theo ngữ nghĩa (semantic chunking) cho nội dung dạng FAQ. LangGraph – Điều phối luồng công việc giữa các agent (multi-agent workflows) và quản lý trạng thái hội thoại. AWS Lambda – AWS Lambda – Thực thi logic của multi-agent và truy xuất thông tin người dùng để cung cấp ngữ cảnh phong phú hơn. Continuous evaluation layer Lớp hạ tầng đánh giá hỗ trợ giám sát và cải thiện chất lượng liên tục thông qua các thành phần sau:\nAmazon CloudWatch – Giám sát theo thời gian thực các chỉ số chất lượng, với hệ thống cảnh báo và quản lý ngưỡng tự động. Amazon EventBridge – Kích hoạt sự kiện thời gian thực khi hoàn tất hội thoại và thực hiện đánh giá chất lượng. AWS Lambda – Các hàm đánh giá tự động đo lường mức độ liên quan của ngữ cảnh (context relevance), độ xác thực của phản hồi (response groundedness), và độ chính xác mục tiêu (goal accuracy). Amazon QuickSight – Cung cấp bảng điều khiển tương tác (interactive dashboards) và phân tích để theo dõi các chỉ số tương ứng. Application and integration layer Lớp tích hợp cung cấp các giao diện bảo mật cho việc giao tiếp bên ngoài:\nAmazon API Gateway – Cung cấp các endpoint API bảo mật cho giao diện hội thoại và webhook đánh giá. Kiến trúc cố vấn AI đa tác nhân Cố vấn thông minh sử dụng một hệ thống multi-agent được điều phối thông qua LangGraph, hoạt động trong một Lambda function duy nhất, trong đó mỗi agent được tối ưu hóa cho một tác vụ cụ thể. Sơ đồ dưới đây minh họa luồng giao tiếp giữa các agent khác nhau trong Lambda function. Thành phần agent và chiến lược lựa chọn mô hình Chiến lược lựa chọn mô hình của chúng tôi bao gồm quá trình thử nghiệm chuyên sâu nhằm khớp yêu cầu tính toán của từng thành phần với mô hình Amazon Bedrock hiệu quả nhất về chi phí. Chúng tôi đánh giá các yếu tố như chất lượng phản hồi, yêu cầu về độ trễ (latency), và chi phí trên mỗi token để xác định mô hình tối ưu cho từng loại agent. Mỗi thành phần trong hệ thống sử dụng mô hình phù hợp nhất với chức năng được chỉ định, như thể hiện trong bảng sau:\nLuồng hội thoại end-to-end Quy trình xử lý hội thoại tuân theo một luồng làm việc có cấu trúc nhằm đảm bảo phản hồi chính xác và duy trì tiêu chuẩn chất lượng:\nTruy vấn của người dùng được gửi qua API Gateway và được định tuyến đến router agent. Router agent xác định specialized agent phù hợp dựa trên phân tích truy vấn. Thông tin người dùng được truy xuất ngay từ đầu để cung cấp ngữ cảnh phong phú hơn; các truy vấn có tính chất chuyên sâu sẽ kích hoạt retriever truy cập Amazon Bedrock Knowledge Base. Các specialized agents xử lý truy vấn dựa trên thông tin người dùng và ngữ cảnh có liên quan từ knowledge base. định dạng và tạo phản hồi cuối cùng hiển thị cho người dùng với giọng điệu phù hợp. Quá trình đánh giá song song (parallel evaluation) được thực hiện để đo lường mức độ liên quan ngữ cảnh, tính xác thực của phản hồi và độ chính xác của mục tiêu. Dữ liệu hội thoại được lưu trữ trong DynamoDB để phục vụ phân tích và cải thiện sau này. Cấu hình Amazon Bedrock Knowledge Bases Knowledge base sử dụng nhiều dịch vụ AWS khác nhau để tối ưu hóa hiệu năng:\nData source – S3 bucket Chunking strategy – Semantic chunking được tối ưu cho nội dung dạng FAQ Embedding model – Cohere Embed Multilingual v3 để hiểu ngữ cảnh tiếng Tây Ban Nha Reranker – Cohere Rerank 3.5 để sắp xếp lại nội dung truy xuất bằng tiếng Tây Ban Nha Vector database – Amazon OpenSearch Serverless cho khả năng tìm kiếm ngữ nghĩa mở rộng (scalable semantic search) Trải nghiệm hội thoại mẫu Hệ thống xử lý trơn tru các cuộc hội thoại tự nhiên bằng tiếng Tây Ban Nha. Ví dụ:\nUsuario: “Hola, ¿qué es PropHero exactamente?”\nAsistente: “¡Hola! PropHero es una plataforma que te permite crear, optimizar y crecer tu patrimonio inmobiliario delegando todo el proceso en nuestro equipo de profesionales…”\nUsuario: “¿Y cómo funciona en la práctica?”\nAsistente: “Es muy sencillo. Comenzamos con una sesión con tu Property Coach para definir tu estrategia de inversión personalizada…”\nHệ thống đánh giá liên tục tích hợp Hệ thống đánh giá liên tục được tích hợp trực tiếp vào kiến trúc, đóng vai trò như một thành phần cốt lõi. Cách tiếp cận này cho phép giám sát chất lượng theo thời gian thực song song với quá trình xử lý hội thoại.\nCác chỉ số đánh giá Chúng tôi sử dụng các chỉ số đánh giá từ thư viện Ragas như sau:\nContext Relevance (0–1) – Đo lường mức độ liên quan của ngữ cảnh được truy xuất với truy vấn của người dùng, đánh giá hiệu quả của hệ thống RAG. Response Groundedness (0–1) – Đảm bảo phản hồi chính xác về mặt thông tin và được trích xuất từ dữ liệu chính thức của PropHero. Agent Goal Accuracy (0–1) – Chỉ số nhị phân thể hiện liệu phản hồi có giải quyết đúng mục tiêu đầu tư của người dùng hay không. Luồng đánh giá theo thời gian thực Hệ thống đánh giá vận hành liền mạch trong kiến trúc hội thoại với các cơ chế sau:\nAmazon DynamoDB Streams triggers – Dữ liệu hội thoại ghi vào DynamoDB sẽ tự động kích hoạt Lambda function để thực hiện đánh giá qua Amazon DynamoDB Streams. Parallel processing – Các Lambda functions thực thi logic đánh giá song song với quá trình phản hồi người dùng. Multi-dimensional assessment – Mỗi cuộc hội thoại được đánh giá đồng thời theo ba chiều chính. Intelligent scoring with LLM-as-a-judge – đóng vai trò như một “LLM judge”, cung cấp các tiêu chí đánh giá tiêu chuẩn cho mọi hội thoại. Monitoring and analytics – CloudWatch thu thập các chỉ số từ quá trình đánh giá, trong khi QuickSight cung cấp bảng điều khiển trực quan để phân tích xu hướng. Sơ đồ sau minh họa Lambda function chịu trách nhiệm cho quy trình đánh giá liên tục này. Các thông tin triển khai và thực tiễn tốt nhất Hành trình phát triển được thực hiện trong 6 tuần cùng đội kỹ thuật của PropHero. Nhóm tiến hành thử nghiệm với nhiều tổ hợp mô hình khác nhau và đánh giá các chiến lược chunking bằng dữ liệu FAQ thực tế từ khách hàng. Quá trình này mang lại nhiều tối ưu kiến trúc giúp cải thiện hiệu năng hệ thống, giảm chi phí đáng kể và nâng cao trải nghiệm người dùng.\nChiến lược lựa chọn mô hình Cách tiếp cận của chúng tôi nhấn mạnh tầm quan trọng của việc lựa chọn mô hình phù hợp với từng tác vụ cụ thể. Bằng cách sử dụng Amazon Nova Lite cho các tác vụ đơn giản và Amazon Nova Pro cho các tác vụ suy luận phức tạp, hệ thống đạt được sự cân bằng tối ưu giữa chi phí và hiệu suất, đồng thời duy trì độ chính xác cao.\nTối ưu hóa chunking và truy xuất Kỹ thuật semantic chunking cho kết quả vượt trội so với các phương pháp hierarchical và fixed chunking trong nội dung dạng FAQ. Mô hình Cohere Rerank 3.5 giúp hệ thống chỉ cần sử dụng 10 chunk thay vì 20 mà vẫn duy trì độ chính xác, qua đó giảm độ trễ (latency) và chi phí vận hành.\nKhả năng đa ngôn ngữ Hệ thống xử lý hiệu quả cả tiếng Tây Ban Nha và tiếng Anh bằng cách sử dụng các Foundation Models (FMs) hỗ trợ ngôn ngữ Tây Ban Nha trên Amazon Bedrock.\nTác động kinh doanh Cố vấn AI của PropHero mang lại giá trị kinh doanh rõ rệt:\nTăng cường mức độ tương tác của khách hàng – Tỷ lệ goal accuracy đạt 90% đảm bảo khách hàng nhận được lời khuyên đầu tư bất động sản phù hợp và có thể hành động. Hơn 50% người dùng (và hơn 70% người dùng trả phí) đang chủ động sử dụng cố vấn AI. Hiệu quả vận hành – Việc tự động phản hồi các câu hỏi thường gặp giúp giảm 30% khối lượng công việc của bộ phận hỗ trợ khách hàng, cho phép nhân viên tập trung vào các nhu cầu phức tạp hơn. Khả năng mở rộng – Kiến trúc serverless tự động mở rộng để đáp ứng nhu cầu gia tăng của khách hàng mà không cần can thiệp thủ công. Tối ưu hóa chi phí – Chiến lược lựa chọn mô hình hợp lý giúp đạt hiệu năng cao trong khi giảm 60% chi phí AI so với việc sử dụng toàn bộ mô hình cao cấp. Mở rộng cơ sở khách hàng – Việc hỗ trợ ngôn ngữ Tây Ban Nha thành công giúp PropHero mở rộng sang thị trường người dùng nói tiếng Tây Ban Nha với năng lực bản địa hóa mạnh mẽ. Kết luận Cố vấn AI của PropHero chứng minh cách AWS generative AI services có thể được sử dụng để xây dựng các conversational agents thông minh, nhận thức ngữ cảnh và mang lại giá trị kinh doanh thực tiễn. Bằng cách kết hợp kiến trúc agent mô-đun với hệ thống đánh giá mạnh mẽ, PropHero đã tạo ra một giải pháp vừa tăng cường tương tác khách hàng, vừa đảm bảo phản hồi chính xác và phù hợp. Đặc biệt, pipeline đánh giá toàn diện đóng vai trò quan trọng khi cung cấp các chỉ số rõ ràng để đo lường chất lượng hội thoại và định hướng cải tiến liên tục. Cách tiếp cận này đảm bảo rằng cố vấn AI sẽ tiếp tục phát triển và hoàn thiện theo thời gian. Để tìm hiểu thêm về cách xây dựng các cố vấn AI đa tác nhân với cơ chế đánh giá liên tục, vui lòng tham khảo các tài nguyên sau:\nRetrieve data and generate AI responses with Amazon Bedrock Knowledge Bases – Với Amazon Bedrock Knowledge Bases, bạn có thể triển khai tìm kiếm ngữ nghĩa với chiến lược chunking hiệu quả. LangGraph – Công cụ giúp bạn xây dựng các multi-agent workflows. Ragas – Cung cấp bộ chỉ số đánh giá LLM toàn diện bao gồm context relevance, groundedness, và goal accuracy như trong triển khai này. Để tìm hiểu thêm về Generative AI Innovation Center, hãy liên hệ với account team của bạn.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.7-cicd-pipeline/5.7.1-create-gwe/","title":"Kết nối repo GitLab &amp; tạo dự án CodeBuild","tags":[],"description":"","content":"Mục tiêu Cấu hình hai dự án CodeBuild (frontend và backend) và trigger từ sự kiện Release của GitLab để khởi chạy CodePipeline. CodePipeline gọi CodeBuild dựa trên frontend-buildspec.yml và backend-buildspec.yml có sẵn trong repository, sau đó deploy lên ECS.\nTài nguyên AWS Dự án CodeBuild: Frontend: Source = CodePipeline; Buildspec = frontend-buildspec.yml Backend: Source = CodePipeline; Buildspec = backend-buildspec.yml CodePipeline (bước sau) nhận artifact và deploy lên ECS Tạo dự án CodeBuild \u0026amp; kết nối repository GitLab Trong phần cấu hình tạo mới CodeBuild Project, chọn Default project. Ở mục Source, chọn GitLab và repository Band-Up. Giữ nguyên cấu hình mặc định cho Environment. Chỉ định buildspec của dự án Band-Up cho frontend/backend như hình: Gửi tạo và lặp lại cho dự án CodeBuild frontend/backend còn lại. Tóm tắt Bạn đã có hai dự án CodeBuild (frontend và backend) sẵn sàng được gọi bởi CodePipeline. Sự kiện Release từ GitLab có thể kích hoạt CodePipeline, sau đó chạy mỗi dự án với frontend-buildspec.yml và backend-buildspec.yml tương ứng. Ở các bước tiếp theo, CodePipeline sẽ lấy artifact sau build và deploy lên ECS.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2 Hoàn thành Module 2, nắm vững kiến thức nền tảng về Amazon EC2 và VPC. Chuẩn bị và cấu hình các tài nguyên cần thiết để khởi tạo EC2. Tìm hiểu Amazon Route 53 và các khái niệm quản lý DNS. Tham gia sự kiện Cloud Day để học hỏi về AI và Data. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Nghiên cứu sâu về kiến trúc VPC và các thành phần mạng.\n- Học nguyên tắc thiết kế kiến trúc AWS từ bài giảng của Mentor Gia Hung.\n- Hoàn thành AWS Skill Builder: Networking Essentials with Amazon VPC. 15/09/2025 16/09/2025 AWS VPC Documentation 3 - Tạo tài nguyên VPC để chuẩn bị cho việc triển khai EC2.\n- Khởi tạo EC2 instances từ các tài nguyên đã cấu hình.\n- Học về Security Groups và Network ACLs.\n- Hoàn thành: Compute Essentials with Amazon EC2. 16/09/2025 17/09/2025 AWS EC2 Documentation Introduction to Amazon EC2 Deploying FCJ Management Application with Auto Scaling Group 4 - Xử lý vấn đề xác thực tài khoản AWS bằng cách gửi giấy tờ xác minh.\n- Hoàn thành: Creating Your First AWS Account và Getting Help with AWS Support. 17/09/2025 20/09/2025 AWS Support\nYêu cầu Hỗ trợ từ AWS Support 5 - Tham gia sự kiện Cloud Day.\n- Thu thập kiến thức về xu hướng AI và Data.\n- Giao lưu với các mentor nổi bật trong cộng đồng AWS. 18/09/2025 18/09/2025 Cloud Day Event Khóa học AWS Skill Builder đã hoàn thành Khóa học Danh mục Trạng thái Creating Your First AWS Account Bắt đầu ✅ Managing Costs with AWS Budgets Quản lý chi phí ✅ Getting Help with AWS Support Hỗ trợ ✅ Access Management with AWS IAM Bảo mật ✅ Networking Essentials with Amazon VPC Mạng ✅ Compute Essentials with Amazon EC2 Compute ✅ Instance Profiling with IAM Roles for EC2 Bảo mật ✅ Kết quả đạt được tuần 2 Kỹ năng kỹ thuật đã tiếp thu:\nNắm vững kiến trúc VPC và các nguyên tắc cơ bản của EC2 Thành thạo quy trình chuẩn bị tài nguyên để triển khai EC2: Tạo và cấu hình Subnets để phân đoạn mạng Thiết lập Internet Gateway cho kết nối ra bên ngoài Cấu hình Route Tables để quản lý định tuyến traffic Triển khai Security Groups để kiểm soát traffic vào/ra Hiểu về IAM roles và instance profiles cho truy cập EC2 an toàn Học các chiến lược quản lý chi phí AWS sử dụng AWS Budgets Điểm nổi bật sự kiện Cloud Day:\nTham gia các phiên networking với mentors AWS và chuyên gia trong ngành Thu được kiến thức quý giá về xu hướng thị trường AI và Data Hiểu được tiềm năng tương lai và nhu cầu thị trường đối với công nghệ AI Nhận quà lưu niệm từ ban tổ chức sự kiện Bài học chính:\nVPC là nền tảng cho tất cả networking trên AWS - hiểu nó là cực kỳ quan trọng Security Groups hoạt động như tường lửa ảo ở cấp instance IAM roles loại bỏ nhu cầu hardcode credentials trong EC2 instances AWS Budgets giúp ngăn chặn chi phí không mong muốn thông qua giám sát chủ động "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.2-prerequiste/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"Workshop này được thiết kế dành cho Kỹ sư DevOps, Kiến trúc sư Cloud và Lập trình viên Full-stack mong muốn tìm hiểu quy trình triển khai một ứng dụng hiện đại tích hợp AI trên nền tảng AWS.\nĐể hoàn thành tốt workshop này, người tham gia cần trang bị các kiến thức, kỹ năng và công cụ sau đây.\n1. Yêu cầu về kiến thức kỹ thuật Kiến thức nền tảng AWS (AWS Fundamentals) Thao tác trên Console: Làm quen với giao diện quản trị AWS Management Console. Dịch vụ cốt lõi: Hiểu biết cơ bản về dịch vụ tính toán như Amazon EC2 và AWS Fargate, các khái niệm mạng trong Amazon VPC, và lưu trữ với Amazon S3. IAM \u0026amp; Bảo mật: Hiểu về AWS Identity and Access Management (IAM), cụ thể là vai trò (Roles), chính sách (Policies), và nguyên tắc đặc quyền tối thiểu (least privilege). Container \u0026amp; Điều phối (Containerization \u0026amp; Orchestration) Docker: Thành thạo trong việc tạo Dockerfile, build images và chạy container trên môi trường local. Cần nắm vững các khái niệm như layers, cổng kết nối (ports) và biến môi trường. Tham khảo Tài liệu Docker. Khái niệm ECS: Làm quen với các thuật ngữ của Amazon ECS bao gồm Task Definitions, Services, Clusters, và sự khác biệt giữa hai loại hình khởi chạy EC2 và Fargate. DevOps \u0026amp; CI/CD Git: Thành thạo quản lý mã nguồn (commit, push, branching) để kích hoạt các quy trình tự động hóa. Luồng CI/CD: Hiểu về nguyên lý Tích hợp liên tục (Continuous Integration) và Chuyển giao liên tục (Continuous Delivery) sử dụng các công cụ như AWS CodePipeline và AWS CodeBuild. Kiến thức cơ bản về mạng (Networking) Giao thức: Hiểu về HTTP/HTTPS, phân giải tên miền DNS với Amazon Route 53, và các khái niệm cân bằng tải sử dụng Application Load Balancer. Bảo mật mạng: Kiến thức về địa chỉ IP (CIDR blocks) và kiểm soát lưu lượng sử dụng Security Groups. 2. Thiết lập môi trường Trước khi bắt đầu workshop, hãy đảm bảo môi trường phát triển cục bộ của bạn đã được cài đặt đầy đủ các công cụ sau:\nTài khoản AWS: Một tài khoản AWS đang hoạt động với quyền Quản trị viên (Administrator access) để khởi tạo tài nguyên. IDE: Một trình soạn thảo mã nguồn như Visual Studio Code hoặc IntelliJ IDEA. Công cụ dòng lệnh (Command Line Tools): AWS CLI (v2): Đã cài đặt và cấu hình với thông tin đăng nhập của bạn. Hướng dẫn cài đặt. Git: Đã cài đặt để sao chép (clone) kho mã nguồn. Tải về. Docker Desktop: Đang chạy trên máy local để kiểm tra hoặc build images nếu cần thiết. Tải Docker. 3. Hạn mức dịch vụ \u0026amp; Chi phí Lưu ý về chi phí: Workshop này sử dụng các tài nguyên không nằm trong gói miễn phí (AWS Free Tier), bao gồm:\nNAT Gateways (Phí theo giờ + Phí xử lý dữ liệu) Application Load Balancers ECS Fargate Tasks (Tính theo vCPU/Memory sử dụng) Amazon RDS \u0026amp; ElastiCache Vui lòng đảm bảo dọn dẹp tài nguyên ngay sau khi hoàn thành workshop để tránh phát sinh chi phí không mong muốn. Hướng dẫn dọn dẹp sẽ được cung cấp ở phần cuối của tài liệu này.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.3-network/5.3.2-alb/","title":"Cấu hình Application Load Balancer (ALB)","tags":[],"description":"","content":"Application Load Balancer (ALB) đóng vai trò là cổng vào duy nhất cho mọi lưu lượng truy cập đến nền tảng. Nó chịu trách nhiệm phân phối yêu cầu đến các container phù hợp (Frontend hoặc Backend) và xử lý mã hóa SSL.\n1. Tạo Security Group cho ALB Trước khi tạo Load Balancer, chúng ta cần một lớp tường lửa cho phép truy cập từ Internet.\nTruy cập EC2 Dashboard \u0026gt; Security Groups \u0026gt; Create security group. Security group name: alb-sg. Description: Allow http and https traffic. VPC: Chọn band-up-vpc. Inbound rules: Thêm các quy tắc sau để cho phép truy cập từ bất kỳ đâu: Type: HTTP | Port: 80 | Source: Anywhere-IPv4 (0.0.0.0/0). Type: HTTPS | Port: 443 | Source: Anywhere-IPv4 (0.0.0.0/0). Nhấn Create security group. 2. Tạo Target Group ALB cần biết nơi để chuyển tiếp lưu lượng truy cập. Chúng ta sẽ tạo Target Group cho dịch vụ Frontend trước (Backend sẽ cấu hình sau).\nTruy cập EC2 Dashboard \u0026gt; Target groups \u0026gt; Create target group. Choose a target type: Chọn IP addresses (Bắt buộc cho ECS Fargate). Target group name: target-bandup-fe. Protocol: HTTP. Port: 3000 (Next.js frontend của chúng ta chạy trên port 3000). VPC: Chọn band-up-vpc. Nhấn Next. Register targets: Vì chúng ta chưa triển khai ECS task nào, hãy bỏ qua bước này và nhấn Create target group. 3. Khởi tạo Application Load Balancer Bây giờ, chúng ta sẽ kết hợp mọi thứ vào Load Balancer.\nBước 1: Cấu hình cơ bản (Basic Configuration)\nTruy cập Load Balancers \u0026gt; Create load balancer. Chọn Application Load Balancer và nhấn Create. Load balancer name: bandup-public-alb. Scheme: Internet-facing (Cho phép truy cập công khai). IP address type: IPv4. Bước 2: Ánh xạ mạng (Network Mapping)\nVPC: Chọn band-up-vpc. Mappings: Chọn hai Availability Zones (ap-southeast-1a và ap-southeast-1b). Subnets: QUAN TRỌNG - Phải chọn các Public Subnets (public-subnet-1 và public-subnet-2) đã tạo ở phần trước. Lưu ý: Nếu chọn nhầm Private subnets, ALB sẽ không thể nhận truy cập từ Internet. Bước 3: Security Groups \u0026amp; Listeners\nSecurity groups: Bỏ chọn default và chọn alb-sg vừa tạo. Listeners and routing: Protocol: HTTP | Port: 80. Default action: Forward to target-bandup-fe. Nhấn Create load balancer. ALB của bạn đang được khởi tạo. Sau khi chuyển sang trạng thái Active, nó sẽ sẵn sàng điều hướng lưu lượng đến ứng dụng Frontend.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.5-setup-be/5.5.2-rds/","title":"Tạo PostgreSQL RDS","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ khởi tạo một Amazon RDS cho PostgreSQL. Đây sẽ là nơi lưu trữ dữ liệu bền vững chính cho nền tảng IELTS BandUp. Chúng ta sẽ cấu hình nó với tính sẵn sàng cao (High Availability) và bảo mật trong VPC.\n1. Cấu hình Security Group Trước khi tạo cơ sở dữ liệu, chúng ta cần xác định các quy tắc tường lửa.\nBước 1.1: Tạo Backend Security Group Nhóm này dành cho ECS Fargate tasks (lớp ứng dụng).\nTên: ecs-backend-sg. Inbound: Cho phép cổng 8080 (Mặc định của Spring Boot) từ ALB. Bước 1.2: Tạo RDS Security Group Nhóm này được gắn vào chính database.\nTên: rds-sg. Inbound: Cho phép lưu lượng PostgreSQL (Cổng 5432) chỉ từ ecs-backend-sg vừa tạo ở trên. Điều này đảm bảo chỉ ứng dụng của chúng ta mới có thể giao tiếp với database. 2. Tạo DB Subnet Group RDS cần biết những subnet nào nó được phép sử dụng. Chúng ta sẽ gom nhóm các subnet database riêng tư lại với nhau.\nTruy cập Amazon RDS \u0026gt; Subnet groups \u0026gt; Create DB subnet group. Tên: bandup-db-subnet-group. VPC: Chọn band-up-vpc. Add subnets: Chọn các Availability Zone và chọn private-database-subnet-1 cùng private-database-subnet-2. 3. Khởi tạo Database Bây giờ, chúng ta sẽ khởi tạo instance PostgreSQL.\nTruy cập Databases \u0026gt; Create database. Phương thức tạo: Standard create. Engine options: PostgreSQL (Phiên bản 17.6 hoặc mới nhất). Availability and durability: Chọn Multi-AZ DB instance. Tùy chọn này tạo một DB chính và một bản sao đồng bộ (standby) ở một Availability Zone khác để tự động chuyển đổi khi có sự cố. Settings: DB instance identifier: bandup-db. Master username: postgres. Credential management: Self managed. Master password: Đặt mật khẩu mạnh (hãy lưu lại để dùng sau này). Instance configuration: DB instance class: Burstable classes -\u0026gt; db.t4g.micro (Tiết kiệm chi phí cho workshop). Storage: gp3 (General Purpose SSD) với dung lượng 20 GiB. Connectivity: Compute resource: Chọn Don\u0026rsquo;t connect to an EC2 compute resource. VPC: band-up-vpc. DB subnet group: bandup-db-subnet-group (Đã tạo ở bước 2). Public access: No (Rất quan trọng để bảo mật). VPC security group: Chọn existing -\u0026gt; rds-sg. Database authentication: Password authentication. Monitoring: Bật Performance Insights (lưu trữ 7 ngày). Additional configuration: Initial database name: band_up (Quan trọng: Hibernate sẽ tìm tên DB này khi khởi động). Backup: Bật sao lưu tự động. Encryption: Bật mã hóa. Nhấn Create database. Quá trình khởi tạo sẽ mất vài phút để hoàn tất. "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.4-setup-fe/5.4.2-ecr/","title":"Thiết lập ECR &amp; IAM Role","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ chuẩn bị hạ tầng AWS cần thiết để lưu trữ các container image. Quá trình này bao gồm việc kiểm tra trạng thái ban đầu, tạo IAM Role cần thiết cho tính năng sao chép của ECR, và khởi tạo repository.\n1. Kiểm tra trạng thái ECR Đầu tiên, kiểm tra trạng thái hiện tại của Private Registry. Ban đầu, chưa có repository nào được tạo.\n2. Tạo IAM Role cho ECR Chúng ta cần tạo một Service-Linked Role cho phép Amazon ECR thực hiện các hành động sao chép (replication) qua các region hoặc tài khoản khác.\nTruy cập IAM \u0026gt; Roles \u0026gt; Create role. Select trusted entity: Chọn AWS service. Service or use case: Chọn Elastic Container Registry từ danh sách. Use case: Chọn Elastic Container Registry - Replication để cho phép ECR sao chép image. Add permissions: Xác nhận rằng chính sách ECRReplicationServiceRolePolicy đã được đính kèm. Đây là policy mặc định cấp các quyền cần thiết. Name, review, and create: Tên role được đặt tự động là AWSServiceRoleForECRReplication. Xem lại cấu hình và tạo role. Kết quả: Role đã được tạo thành công và xuất hiện trong danh sách IAM Roles. 3. Tạo ECR Repository Tiếp theo, chúng ta tạo kho lưu trữ cho image frontend.\nTruy cập Amazon ECR \u0026gt; Create repository. General settings: Repository name: band-up-frontend. Visibility settings: Private. Image tag settings: Giữ chế độ Mutable để cho phép ghi đè các image tag. Kết quả: Repository band-up-frontend đã được tạo thành công với mã hóa mặc định AES-256. 4. Cấu hình Truy cập CLI (CLI Access) Để đẩy image từ máy local lên AWS, bạn cần quyền truy cập thông qua AWS CLI. Chúng ta sẽ tạo Access Key cho IAM User của bạn.\nTruy cập IAM Dashboard \u0026gt; Users \u0026gt; Chọn user của bạn (ví dụ: NamDang). Chuyển sang tab Security credentials và nhấn Create access key. Use case: Chọn Command Line Interface (CLI). Description tag: Nhập mô tả (ví dụ: ECR Push Key) và nhấn Create access key. Lấy khóa: Quan trọng! Hãy sao chép hoặc tải về Access Key ID và Secret Access Key ngay lập tức, vì bạn sẽ không thể xem lại Secret Key sau này. 5. Cấu hình AWS CLI Mở terminal trên máy của bạn và cấu hình AWS CLI với thông tin xác thực vừa tạo.\naws configure Nhập các thông tin sau khi được hỏi:\nAWS Access Key ID: [Dán Key ID của bạn] AWS Secret Access Key: [Dán Secret Key của bạn] Default region name: ap-southeast-1 Default output format: json 6. Đẩy Image lên ECR (Push) Khi CLI đã được cấu hình, chúng ta tiến hành xác thực Docker và đẩy image lên.\nBước 1: Đăng nhập vào ECR Chạy lệnh đăng nhập để xác thực Docker client với registry của AWS.\naws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin [Account-ID]https://www.google.com/search?q=.dkr.ecr.ap-southeast-1.amazonaws.com Kết quả mong đợi: Login Succeeded\nBước 2: Gán Tag cho Image Gán tag cho image local band-up-frontend:latest với đường dẫn URI đầy đủ của ECR và phiên bản (ví dụ: v1.0.0).\ndocker tag band-up-frontend:latest [Account-ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-frontend:v1.0.0 Bước 3: Thực hiện Push Chạy lệnh push để tải các layer của image lên AWS.\ndocker push [Account-ID].dkr.ecr.ap-southeast-1.amazonaws.com/band-up-frontend:v1.0.0 7. Kiểm tra kết quả cuối cùng Quay lại Amazon ECR Console và mở repository band-up-frontend. Bạn sẽ thấy image với tag v1.0.0 đã xuất hiện trong danh sách.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Hệ Thống Web Tự Học IELTS Nền Tảng Thông Minh Cho Việc Chuẩn Bị IELTS Độc Lập 1. Tóm Tắt Điều Hành Hệ Thống Web Tự Học IELTS là một nền tảng trực tuyến toàn diện được thiết kế để hỗ trợ sinh viên trong hành trình chuẩn bị IELTS độc lập. Nền tảng cung cấp giải pháp tất-trong-một bao gồm quản lý người dùng, blog giáo dục, phòng học tương tác, bài kiểm tra thực hành và hệ thống flashcard được hỗ trợ bởi AI. Tận dụng các công nghệ web hiện đại và tích hợp AI, hệ thống cung cấp trải nghiệm học tập được cá nhân hóa, tính năng cộng tác thời gian thực và công cụ đánh giá tự động để giúp sinh viên đạt được mục tiêu IELTS một cách hiệu quả.\n2. Phát Biểu Vấn Đề Vấn Đề Là Gì? Nhiều người học IELTS gặp khó khăn trong việc tìm kiếm các nền tảng tự học giá cả phải chăng, toàn diện và tương tác. Các phương pháp học truyền thống thiếu khả năng cộng tác thời gian thực, phản hồi cá nhân hóa và công cụ thực hành tích hợp. Sinh viên thường gặp khó khăn với:\nQuyền truy cập hạn chế vào tài liệu thực hành chất lượng và bài kiểm tra mô phỏng Thiếu phản hồi ngay lập tức về các bài thi Speaking và Writing Khó khăn trong việc tìm bạn học và duy trì kỷ luật học tập Tài nguyên phân mảnh trên nhiều nền tảng khác nhau Chi phí cao của các khóa học chuẩn bị IELTS truyền thống Giải Pháp Hệ Thống Web Tự Học IELTS cung cấp một nền tảng thống nhất với năm tính năng cốt lõi:\nHệ Thống Quản Lý Người Dùng: Thành viên nhiều cấp (Khách, Thành viên, Premium, Quản trị viên) với xác thực mạng xã hội (Google, Facebook), hồ sơ cá nhân và khả năng nhắn tin.\nNền Tảng Blog Giáo Dục: Nội dung do cộng đồng tạo ra với các thao tác CRUD, phân loại theo thể loại/thẻ, lọc nâng cao, bình luận, báo cáo và tính năng yêu thích.\nPhòng Học Tương Tác: Không gian học ảo với lên lịch, cuộc gọi thoại/video, bộ đếm thời gian Pomodoro, nhạc nền, tích hợp từ điển và hỗ trợ dịch thuật để nâng cao việc học.\nBài Kiểm Tra Thực Hành IELTS: Các bài kiểm tra mô phỏng toàn diện cho Reading và Listening với tính năng tự động trích xuất từ vựng vào flashcard, cộng với đánh giá được hỗ trợ bởi AI cho các bài Speaking và Writing, và bài tập chính tả.\nHệ Thống Flashcard Quizlet: Tạo flashcard thông minh với nhiều chế độ học, tự động trích xuất từ vựng từ văn bản, tạo bài quiz bằng AI từ tài liệu được tải lên và khả năng chia sẻ.\nLợi Ích và Lợi Tức Đầu Tư Cho Sinh Viên: Thay thế tiết kiệm chi phí cho các khóa học đắt đỏ, lộ trình học tập cá nhân hóa, truy cập tài liệu học 24/7, phản hồi được hỗ trợ bởi AI và môi trường học tập hợp tác. Giá Trị Giáo Dục: Phát triển kỷ luật tự giác, cung cấp chuẩn bị IELTS toàn diện, cho phép học tập ngang hàng và cung cấp tiến độ có thể theo dõi. Lợi Ích Kỹ Thuật: Kiến trúc có thể mở rộng, công nghệ hiện đại, tích hợp AI cho đánh giá tự động và tiềm năng mở rộng tính năng trong tương lai. Tiềm Năng Thị Trường: Nhu cầu ngày càng tăng về chuẩn bị IELTS trực tuyến, mô hình doanh thu dựa trên đăng ký (Khách → Thành viên → Premium) và tiềm năng hợp tác với các tổ chức giáo dục. 3. Kiến Trúc Giải Pháp Nền tảng sử dụng kiến trúc web full-stack hiện đại được thiết kế để có khả năng mở rộng, cộng tác thời gian thực và tích hợp AI. Hệ thống bao gồm năm module chính hoạt động cùng nhau để cung cấp trải nghiệm học IELTS toàn diện. Hạ tầng sử dụng triển khai active-passive Multi-AZ trên AWS ECS để đảm bảo tính sẵn sàng cao, trong đó AZ-1 xử lý toàn bộ lưu lượng hoạt động và AZ-2 đóng vai trò dự phòng để chuyển đổi dự phòng tự động.\nTổng Quan Kiến Trúc Hệ Thống: Công Nghệ Sử Dụng Frontend:\nNext.js 14+: Framework React hiện đại cho ứng dụng web đáp ứng TypeScript: Phát triển an toàn kiểu dữ liệu TailwindCSS: Styling tiện ích ưu tiên WebRTC: Giao tiếp video/thoại thời gian thực Socket.io Client: Nhắn tin và cộng tác thời gian thực Backend:\nSpring Boot 3.x: Kiến trúc API RESTful nguyên khối Java 17+: Ngôn ngữ lập trình backend Spring Security: Xác thực và phân quyền Spring WebSocket: Giao tiếp thời gian thực JWT: Xác thực dựa trên token an toàn OAuth 2.0: Tích hợp đăng nhập mạng xã hội (Google, Facebook) Cơ Sở Dữ Liệu:\nPostgreSQL 14+: Cơ sở dữ liệu quan hệ chính cho tất cả dữ liệu (người dùng, bài kiểm tra, blog, flashcard, phiên học) Amazon ElastiCache (Redis): Bộ nhớ đệm và quản lý phiên Hạ Tầng Đám Mây (AWS):\nAmazon ECS (Elastic Container Service): Điều phối container với triển khai active-passive Multi-AZ Application Load Balancer: Định tuyến lưu lượng đến AZ hoạt động với chuyển đổi dự phòng tự động Amazon RDS for PostgreSQL: Triển khai Multi-AZ (primary hoạt động ở AZ-1, standby thụ động ở AZ-2) Amazon S3: Lưu trữ tệp và phương tiện Amazon CloudFront: CDN cho tài nguyên tĩnh Amazon CloudWatch: Giám sát và ghi log Dịch Vụ Bên Thứ Ba:\nGoogle Gemini Flash API (Free Tier): Đánh giá Speaking/Writing được hỗ trợ bởi AI và tạo nội dung API Từ Điển Miễn Phí: Định nghĩa và ví dụ từ Thư viện dịch mã nguồn mở: Dịch thuật nhận biết ngữ cảnh (thay thế cho API trả phí) Thiết Kế Thành Phần 1. Module Quản Lý Người Dùng:\nHệ thống xác thực nhiều cấp (Khách, Thành viên, Premium, Quản trị viên) Tích hợp OAuth mạng xã hội (Google, Facebook) Quản lý hồ sơ người dùng với thống kê học tập Hệ thống nhắn tin thời gian thực Khôi phục mật khẩu và xác minh email 2. Module Nền Tảng Blog:\nCác thao tác CRUD cho bài đăng blog Hệ thống quản lý thể loại và thẻ Tìm kiếm và lọc nâng cao (theo thẻ, thể loại, ngày, mức độ phổ biến) Hệ thống bình luận với phản hồi lồng nhau Báo cáo và kiểm duyệt nội dung Tính năng yêu thích/đánh dấu Phân phối nội dung được tối ưu hóa SEO 3. Module Phòng Học:\nTạo và quản lý phòng học ảo Lên lịch phiên học với tích hợp lịch Cuộc gọi thoại và video dựa trên WebRTC Bộ đếm thời gian Pomodoro với khoảng thời gian tùy chỉnh Thư viện nhạc nền với danh sách phát tập trung Từ điển tích hợp với API từ điển miễn phí Hỗ trợ dịch thuật sử dụng thư viện mã nguồn mở Chia sẻ màn hình cho học tập cộng tác Quản lý người tham gia thời gian thực 4. Module Bài Kiểm Tra Thực Hành IELTS:\nQuản lý ngân hàng bài kiểm tra (Reading, Listening, Speaking, Writing) Mô phỏng bài kiểm tra có giới hạn thời gian với tự động nộp bài Tự động trích xuất từ vựng từ đoạn văn Reading vào flashcard Đánh giá Speaking được hỗ trợ bởi AI sử dụng Gemini Flash (phát âm, độ trôi chảy, mạch lạc) Đánh giá Writing được hỗ trợ bởi AI sử dụng Gemini Flash (ngữ pháp, từ vựng, hoàn thành nhiệm vụ) Bài tập chính tả cho thực hành Listening Báo cáo điểm chi tiết và phân tích Theo dõi tiến độ qua các loại bài kiểm tra 5. Module Flashcard Quizlet:\nCác thao tác CRUD cho bộ flashcard Nhiều chế độ học (flashcard, học, kiểm tra, ghép cặp, viết) Thuật toán lặp lại ngắt quãng (SRS) Tự động trích xuất từ vựng từ đoạn văn bản Tạo bài quiz bằng AI từ tài liệu/văn bản được tải lên sử dụng Gemini Flash Bộ flashcard cộng tác với khả năng chia sẻ Thống kê học tập và theo dõi mức độ thành thạo Chức năng nhập/xuất 4. Triển Khai Kỹ Thuật Các Giai Đoạn Triển Khai\nGiai Đoạn 1: Lập Kế Hoạch và Thiết Kế (Tuần 1-2)\nThu thập yêu cầu và định nghĩa user story Thiết kế kiến trúc hệ thống và lập kế hoạch hạ tầng AWS Thiết kế schema cơ sở dữ liệu cho PostgreSQL Wireframe và mockup UI/UX Thiết kế endpoint API cho Spring Boot Đánh giá và lập kế hoạch tích hợp dịch vụ bên thứ ba Thiết lập kiến trúc Multi-AZ trên AWS ECS Giai Đoạn 2: Phát Triển Cốt Lõi (Tuần 3-6)\nThiết lập ứng dụng Spring Boot với kiến trúc nguyên khối Xác thực và phân quyền người dùng với Spring Security Thiết lập cơ sở dữ liệu PostgreSQL trên Amazon RDS (Multi-AZ: active-passive) Tích hợp JWT và OAuth 2.0 (Google, Facebook) Thiết lập frontend Next.js với TypeScript Tạo thư viện component frontend Các thao tác CRUD cơ bản cho tất cả module Cấu hình AWS ECS cluster với chuyển đổi dự phòng active-passive Giai Đoạn 3: Phát Triển Tính Năng (Tuần 7-10)\nNền tảng blog với lọc và tìm kiếm nâng cao Tạo phòng học với tích hợp WebRTC Module bài kiểm tra thực hành với logic chấm điểm tự động Hệ thống flashcard với thuật toán lặp lại ngắt quãng Nhắn tin thời gian thực với Spring WebSocket Tích hợp API từ điển và Google Translate Tích hợp Amazon S3 cho tải tệp lên ElastiCache Redis cho quản lý phiên và bộ nhớ đệm Giai Đoạn 4: Tích Hợp AI \u0026amp; Triển Khai (Tuần 11-12)\nTích hợp Google Gemini Flash API cho đánh giá Speaking Tích hợp Google Gemini Flash API cho đánh giá Writing Thuật toán trích xuất từ vựng tự động Tạo bài quiz bằng AI từ nội dung được tải lên Kiểm thử toàn diện (đơn vị, tích hợp, end-to-end) Tối ưu hóa hiệu suất và kiểm tra tải Kiểm tra bảo mật và sửa lỗi Triển khai production lên AWS ECS với Multi-AZ Thiết lập giám sát với CloudWatch Yêu Cầu Kỹ Thuật\nMôi Trường Phát Triển:\nJava 17+ cho backend Spring Boot Node.js 18+ cho frontend Next.js PostgreSQL 14+ cho cơ sở dữ liệu Docker cho containerization cục bộ Git cho quản lý phiên bản Maven cho quản lý dependency Java Yêu Cầu Frontend:\nNext.js 14+ với App Router và TypeScript WebRTC cho giao tiếp video/thoại thời gian thực Socket.io client cho tính năng thời gian thực Xác thực biểu mẫu (React Hook Form + Zod) Yêu Cầu Backend:\nSpring Boot 3.x với Java 17+ Spring Data JPA cho các thao tác cơ sở dữ liệu Spring Security cho xác thực/phân quyền Spring WebSocket cho tính năng thời gian thực Spring Web cho API RESTful JWT cho xác thực dựa trên token OAuth 2.0 cho đăng nhập mạng xã hội Xử lý tải tệp lên multipart Hạ Tầng AWS:\nAmazon ECS: Loại khởi chạy Fargate cho ứng dụng container Application Load Balancer: Định tuyến lưu lượng đến AZ hoạt động với kiểm tra sức khỏe Amazon RDS PostgreSQL: Triển khai Multi-AZ active-passive cho tính sẵn sàng cao Amazon ElastiCache (Redis): Quản lý phiên và bộ nhớ đệm Amazon S3: Lưu trữ tệp phương tiện Amazon CloudFront: CDN cho tài nguyên tĩnh Amazon CloudWatch: Ghi log và giám sát Amazon VPC: Cô lập mạng với subnet công khai/riêng tư qua 2 AZ AWS Certificate Manager: Chứng chỉ SSL/TLS Tích Hợp AI/ML:\nGoogle Gemini Flash API (Free Tier) cho đánh giá Speaking/Writing 5. Lộ Trình \u0026amp; Mốc Triển Khai Lộ Trình Dự Án: 3 Tháng (12 Tuần)\nTuần 1-2: Lập Kế Hoạch \u0026amp; Thiết Kế\n✓ Phân tích và lập tài liệu yêu cầu ✓ Thiết kế kiến trúc AWS Multi-AZ ✓ Thiết kế schema cơ sở dữ liệu PostgreSQL ✓ Hoàn thành mockup UI/UX ✓ Thiết lập cấu trúc dự án Spring Boot Kết quả: Tài liệu đặc tả kỹ thuật hoàn chỉnh và kế hoạch hạ tầng AWS Tuần 3-6: Phát Triển Cốt Lõi\n✓ Thiết lập backend nguyên khối Spring Boot ✓ Triển khai Spring Security (JWT, OAuth 2.0) ✓ Quản lý người dùng và kiểm soát truy cập dựa trên vai trò ✓ Triển khai Amazon RDS PostgreSQL Multi-AZ ✓ Framework frontend Next.js và thư viện component ✓ Thiết lập AWS ECS cluster với Application Load Balancer ✓ Cấu hình ElastiCache Redis Kết quả: Hệ thống xác thực hoạt động và hạ tầng AWS Tuần 7-10: Phát Triển Tính Năng\n✓ Nền tảng blog với chức năng CRUD đầy đủ ✓ Tạo và quản lý phòng học ✓ Tích hợp WebRTC cho cuộc gọi video/thoại Module bài kiểm tra thực hành (Reading \u0026amp; Listening) Hệ thống flashcard với các chế độ học Tích hợp Amazon S3 cho lưu trữ phương tiện Tích hợp API từ điển miễn phí và thư viện dịch mã nguồn mở Spring WebSocket cho tính năng thời gian thực Kết quả: Tất cả năm tính năng cốt lõi hoạt động (không có AI) Tuần 11-12: Tích Hợp AI \u0026amp; Triển Khai\n✓ Tích hợp Google Gemini Flash API (Free Tier) cho đánh giá Writing ✓ Tích hợp Google Gemini Flash API (Free Tier) cho đánh giá Speaking ✓ Thuật toán trích xuất từ vựng ✓ Chức năng tạo bài quiz bằng AI ✓ Kiểm thử toàn diện (đơn vị, tích hợp, E2E) ✓ Tối ưu hóa hiệu suất và kiểm tra bảo mật ✓ Triển khai production lên AWS ECS Multi-AZ ✓ Thiết lập giám sát và cảnh báo CloudWatch ✓ Sửa lỗi cuối cùng và lập tài liệu Kết quả: Ứng dụng sẵn sàng production được triển khai trên AWS Các Mốc Quan Trọng:\nTuần 2: Đặc tả kỹ thuật và kiến trúc AWS được phê duyệt Tuần 6: Backend cốt lõi và hạ tầng được triển khai Tuần 10: Tất cả tính năng hoàn thành (phiên bản beta) Tuần 12: Ra mắt production với tích hợp AI Mục Tiêu Sprint Hàng Tuần:\nSprint 1-2: Kiến trúc và thiết lập Sprint 3-4: Xác thực và cơ sở dữ liệu Sprint 5-6: API cốt lõi và triển khai AWS Sprint 7-8: Tính năng blog và phòng học Sprint 9-10: Bài kiểm tra thực hành và flashcard Sprint 11: Tích hợp AI và kiểm thử Sprint 12: Triển khai production và ra mắt 6. Ước Tính Ngân Sách Chi Phí Phát Triển (Một lần)\nPhần Mềm \u0026amp; Công Cụ:\nCông cụ và giấy phép phát triển: $0 (sử dụng công cụ miễn phí/mã nguồn mở) Công cụ thiết kế (Figma Free): $0 Công cụ quản lý dự án: $0 (sử dụng gói miễn phí) Tổng Phần Mềm: $0 Thiết Lập Ban Đầu:\nĐăng ký tên miền: $1/năm Chứng chỉ SSL: $0 (AWS Certificate Manager - Miễn phí) Máy chủ phát triển: $0 (phát triển cục bộ) Tổng Thiết Lập Ban Đầu: $1 Chi Phí Vận Hành (Hàng Tháng)\nHạ Tầng \u0026amp; Hosting (AWS):\nHạ Tầng AWS \u0026amp; Hosting Dịch Vụ Bên Thứ Ba:\nGoogle Gemini Flash API: Gói miễn phí Tổng Phụ Dịch Vụ: $0/tháng Chi Phí Vận Hành Khác:\nGiám sát \u0026amp; phân tích: $10/tháng (tích hợp với CloudWatch) Lưu trữ sao lưu (RDS automated backups): $5/tháng Gia hạn tên miền \u0026amp; SSL: $0.08/tháng (phân bổ từ $1/năm, SSL qua AWS Certificate Manager - Miễn phí) Tổng Phụ Khác: $15.08/tháng Tổng Chi Phí Vận Hành Hàng Tháng: $103.66/tháng\nTóm Tắt Ngân Sách Hàng Năm\nGiai Đoạn Phát Triển (3 Tháng):\nChi phí phát triển: $1 (một lần, chỉ tên miền) Chi phí vận hành (3 tháng): $310.98 ($103.66 × 3 tháng) Tổng Giai Đoạn Phát Triển: $311.98 Năm 1 (Sau Ra Mắt):\nChi phí phát triển: $1 (một lần, chỉ tên miền) Chi phí vận hành: $1,243.92 ($103.66 × 12 tháng) Tổng Năm 1: $1,244.92 Năm 2+ (Định Kỳ Hàng Năm):\nChi phí vận hành: $1,243.92/năm Gia hạn tên miền: $1/năm Tổng Hàng Năm: $2,845.96 Dự Báo Doanh Thu (Mô Hình Đăng Ký)\nCác Cấp Thành Viên:\nKhách: Miễn phí (tính năng hạn chế) Thành viên: $5/tháng (tính năng cơ bản) Premium: $15/tháng (tất cả tính năng + đánh giá AI) Ước Tính Doanh Thu Thận Trọng (Năm 1):\nTháng 6-12: Trung bình 100 Premium + 200 Thành viên Doanh thu: (100 × $15 + 200 × $5) × 7 tháng = $17,500 Chi phí vận hành (Năm 1): $1,243.92 Lợi Nhuận Ròng Năm 1: $16,256.08 Hòa vốn: Tháng 1 sau khi ra mắt Ước Tính Doanh Thu Lạc Quan (Năm 2):\n500 Premium + 1,000 Thành viên Doanh thu hàng tháng: $12,500 Doanh thu hàng năm: $150,000 Chi phí vận hành: $1,243.92 Lợi Nhuận Ròng Năm 2: $147,154.04 Tỷ suất lợi nhuận: ~98% sau chi phí vận hành Chiến Lược Tối Ưu Chi Phí:\nChi phí nhân sự bằng không (dự án tự phát triển) Triển khai Multi-AZ active-passive giảm chi phí (tài nguyên dự phòng chỉ sử dụng khi chuyển đổi dự phòng) Sử dụng AWS ECS Fargate Spot cho môi trường phát triển (tiết kiệm 70% chi phí) Triển khai bộ nhớ đệm với ElastiCache để giảm truy vấn cơ sở dữ liệu Sử dụng CloudFront CDN để giảm thiểu chi phí truyền dữ liệu Tận dụng gói miễn phí của Google Gemini Flash API cho tính năng AI Sử dụng API từ điển miễn phí và thư viện dịch mã nguồn mở Công cụ phát triển và phần mềm thiết kế miễn phí (VS Code, Figma Free, v.v.) Tận dụng AWS Free Tier trong giai đoạn phát triển ban đầu RDS automated backups được bao gồm (lưu trữ 7 ngày) Sử dụng AWS Certificate Manager cho chứng chỉ SSL miễn phí Triển khai chính sách lifecycle S3 để chuyển dữ liệu cũ sang tầng lưu trữ rẻ hơn Không có chi phí dịch vụ email bằng cách hoãn tính năng email cho giai đoạn sau Task ECS dự phòng ở AZ-2 được giữ ở mức tối thiểu cho đến khi cần chuyển đổi dự phòng 7. Đánh Giá Rủi Ro Ma Trận Rủi Ro Rủi Ro Ưu Tiên Cao:\nVượt Chi Phí API AI\nẢnh hưởng: Thấp | Xác suất: Thấp Mô tả: Gói miễn phí Google Gemini Flash API có giới hạn sử dụng có thể bị vượt quá Giảm thiểu: Triển khai hạn ngạch sử dụng và giới hạn tốc độ; giám sát việc sử dụng API qua bảng điều khiển Dự phòng: Nâng cấp lên gói trả phí nếu giới hạn miễn phí bị vượt quá liên tục, hoặc triển khai hệ thống xếp hàng Vi Phạm Bảo Mật \u0026amp; Quyền Riêng Tư Dữ Liệu\nẢnh hưởng: Nghiêm trọng | Xác suất: Thấp Mô tả: Lộ dữ liệu người dùng hoặc truy cập trái phép Giảm thiểu: Triển khai mã hóa, kiểm tra bảo mật định kỳ, tuân thủ GDPR Dự phòng: Kế hoạch ứng phó sự cố, bảo hiểm, tư vấn pháp lý Vấn Đề Khả Năng Mở Rộng\nẢnh hưởng: Cao | Xác suất: Trung bình Mô tả: Hiệu suất hệ thống suy giảm khi người dùng tăng Giảm thiểu: AWS ECS Auto Scaling ở AZ hoạt động, RDS Multi-AZ active-passive cho tính sẵn sàng cao, ElastiCache cho hiệu suất Dự phòng: Mở rộng task ECS ở AZ hoạt động, kích hoạt thêm task ở AZ thụ động nếu cần, nâng cấp class instance RDS Rủi Ro Ưu Tiên Trung Bình:\nNgừng Hoạt Động Dịch Vụ Bên Thứ Ba\nẢnh hưởng: Trung bình | Xác suất: Thấp Mô tả: Phụ thuộc vào API bên ngoài (gói miễn phí Gemini Flash, API từ điển miễn phí) Giảm thiểu: Suy giảm nhẹ nhàng, thông báo người dùng khi tính năng AI không khả dụng Dự phòng: Phản hồi được lưu trong bộ nhớ đệm cho tra cứu từ điển, tùy chọn chấm điểm thủ công cho bài kiểm tra khi gặp sự cố Thách Thức Thu Hút Người Dùng\nẢnh hưởng: Cao | Xác suất: Trung bình Mô tả: Khó khăn trong việc thu hút và giữ chân người dùng Giảm thiểu: Chiến lược marketing, tối ưu hóa SEO, chương trình giới thiệu Dự phòng: Điều chỉnh tính năng dựa trên phản hồi, hợp tác với trường học Vấn Đề Kiểm Duyệt Nội Dung\nẢnh hưởng: Trung bình | Xác suất: Cao Mô tả: Nội dung không phù hợp trong blog, bình luận hoặc phòng học Giảm thiểu: Lọc nội dung tự động, hệ thống báo cáo, đội ngũ kiểm duyệt Dự phòng: Hướng dẫn cộng đồng, cấm người dùng, tuyên bố miễn trừ pháp lý Rủi Ro Ưu Tiên Thấp:\nCông Nghệ Lỗi Thời\nẢnh hưởng: Thấp | Xác suất: Trung bình Mô tả: Các công nghệ được chọn trở nên lỗi thời Giảm thiểu: Cập nhật dependency định kỳ, kiến trúc module hóa Dự phòng: Kế hoạch di chuyển dần dần, ngân sách tái cấu trúc Cạnh Tranh Từ Các Nền Tảng Đã Thành Lập\nẢnh hưởng: Trung bình | Xác suất: Cao Mô tả: Cạnh tranh với Duolingo, IELTS.org, v.v. Giảm thiểu: Tính năng độc đáo (phòng học, đánh giá AI), nhắm mục tiêu thị trường ngách Dự phòng: Chiến lược khác biệt hóa, đổi mới tính năng Chiến Lược Giảm Thiểu Giảm Thiểu Kỹ Thuật:\nTriển khai xử lý lỗi toàn diện và ghi log với CloudWatch Thiết lập cảnh báo CloudWatch cho việc sử dụng tài nguyên và lỗi Sao lưu tự động định kỳ với RDS Multi-AZ và khôi phục theo thời điểm Sử dụng CloudFront CDN cho tài nguyên tĩnh để giảm tải ECS Triển khai giới hạn tốc độ API để ngăn chặn lạm dụng Đánh giá mã và kiểm thử tự động trong pipeline CI/CD (AWS CodePipeline/GitHub Actions) AWS WAF cho bảo mật ứng dụng và bảo vệ DDoS Giảm Thiểu Kinh Doanh:\nBắt đầu với mô hình freemium để xây dựng cơ sở người dùng Giai đoạn thử nghiệm beta để xác định vấn đề nghiêm trọng Triển khai tính năng dần dần để quản lý chi phí Xây dựng cộng đồng qua mạng xã hội và marketing nội dung Thiết lập quan hệ đối tác với giáo viên và tổ chức IELTS Giảm Thiểu Pháp Lý \u0026amp; Tuân Thủ:\nĐiều khoản dịch vụ và Chính sách quyền riêng tư Tuân thủ GDPR và bảo vệ dữ liệu Thỏa thuận cấp phép nội dung Sự đồng ý của người dùng cho xử lý dữ liệu Kiểm tra tuân thủ định kỳ Kế Hoạch Dự Phòng Lỗi Kỹ Thuật:\nLỗi cơ sở dữ liệu: Chuyển đổi dự phòng tự động sang instance standby RDS Multi-AZ ở AZ-2 (thụ động) Lỗi task ECS ở AZ-1: Auto Scaling thay thế task không khỏe mạnh; lỗi nghiêm trọng kích hoạt AZ-2 Ngừng hoạt động API: Phục vụ nội dung được lưu trong bộ nhớ đệm từ ElastiCache và xếp hàng yêu cầu Vi phạm bảo mật: Cảnh báo ngay lập tức từ AWS Security Hub, khóa và điều tra Multi-AZ active-passive đảm bảo tính sẵn sàng cao với chuyển đổi dự phòng tự động sang AZ-2 thụ động Lỗi Kinh Doanh:\nTỷ lệ chấp nhận người dùng thấp: Chuyển sang mô hình B2B (trường học, gia sư) Tỷ lệ rời bỏ cao: Phỏng vấn người dùng, cải thiện tính năng Thiếu hụt doanh thu: Tối ưu hóa chi phí, tìm kiếm đầu tư Vấn Đề Pháp Lý:\nKhiếu nại bản quyền: Quy trình gỡ bỏ nội dung Khiếu nại quyền riêng tư: Xóa dữ liệu và đánh giá tuân thủ Vi phạm điều khoản: Tạm ngừng người dùng và điều tra 8. Kết Quả Kỳ Vọng Cải Tiến Kỹ Thuật Khả Năng Nền Tảng:\nỨng dụng web hoạt động đầy đủ với 5 module tích hợp Tính năng cộng tác thời gian thực (cuộc gọi video/thoại, nhắn tin) Đánh giá được hỗ trợ bởi AI cho Speaking và Writing sử dụng Google Gemini Flash Kiến trúc Multi-AZ có thể mở rộng trên AWS ECS hỗ trợ 10,000+ người dùng đồng thời Thiết kế đáp ứng trên mobile để học mọi lúc mọi nơi API RESTful mạnh mẽ được xây dựng với Spring Boot nguyên khối Tính sẵn sàng cao với thời gian hoạt động 99.9% thông qua triển khai Multi-AZ active-passive Thành Tựu Kỹ Thuật:\nPhát triển web full-stack hiện đại với Next.js và Spring Boot Triển khai giao tiếp thời gian thực (WebRTC, Spring WebSocket) Tích hợp AI/ML Google Gemini Flash và quản lý API Hạ tầng đám mây AWS và triển khai kiến trúc Multi-AZ active-passive Thiết kế và tối ưu hóa cơ sở dữ liệu PostgreSQL Điều phối container với Amazon ECS Fargate Thực hành bảo mật tốt nhất với Spring Security và dịch vụ AWS Thực hành DevOps với giám sát CloudWatch và triển khai tự động Tác Động Giáo Dục Cho Sinh Viên:\nNền tảng chuẩn bị IELTS dễ tiếp cận, giá cả phải chăng Lộ trình học tập cá nhân hóa và theo dõi tiến độ Phản hồi ngay lập tức về bài kiểm tra thực hành Môi trường học tập do cộng đồng thúc đẩy Truy cập tài liệu học tập và bài kiểm tra thực hành 24/7 Ước tính giảm 30-40% chi phí so với các khóa học truyền thống Kết Quả Học Tập:\nCải thiện điểm IELTS thông qua thực hành nhất quán Quản lý thời gian tốt hơn với tích hợp Pomodoro Nâng cao từ vựng thông qua hệ thống flashcard Tự tin Speaking thông qua phản hồi AI Cải thiện kỹ năng Writing với phân tích chi tiết Giá Trị Kinh Doanh Vị Thế Thị Trường:\nGiải pháp thay thế cạnh tranh cho các khóa học chuẩn bị IELTS đắt đỏ Kết hợp độc đáo các tính năng (phòng học + AI + cộng đồng) Mô hình kinh doanh SaaS có thể mở rộng Tiềm năng cho thị trường B2C và B2B (trường học, trung tâm gia sư) Mục Tiêu Tăng Trưởng Người Dùng:\nTuần 12 (Ra mắt): 100 người dùng đăng ký (người thử nghiệm beta) Tháng 6: 500 người dùng đăng ký Tháng 12: 2,000 người dùng đăng ký Năm 2: 10,000 người dùng đăng ký Tỷ lệ chuyển đổi Premium: 10-15% Tiềm Năng Doanh Thu:\nNăm 1: $17,500 (sau khi ra mắt vào Tháng 6) Năm 2: $150,000+ (với 500 premium, 1,000 thành viên thường) Năm 3: $500,000+ (với mở rộng thị trường và quan hệ đối tác) Giá Trị Dài Hạn Phát Triển Nền Tảng:\nNền tảng cho các module học ngôn ngữ khác (TOEFL, SAT, v.v.) Thu thập dữ liệu để cải thiện mô hình AI Thư viện nội dung do cộng đồng tạo ra Tiềm năng cho hệ thống gamification và thành tích Phát triển ứng dụng mobile dựa trên thành công của nền tảng web Tác Động Xã Hội:\nDân chủ hóa việc chuẩn bị IELTS cho sinh viên trên toàn thế giới Giảm rào cản học ngôn ngữ Xây dựng cộng đồng học tập hỗ trợ Cho phép chia sẻ kiến thức ngang hàng Tạo cơ hội cho những người sáng tạo nội dung giáo dục Lợi Ích Portfolio \u0026amp; Nghề Nghiệp:\nDự án full-stack toàn diện với Spring Boot và Next.js cho portfolio của nhà phát triển Kinh nghiệm thực tế với dịch vụ đám mây AWS (ECS, RDS, S3, CloudFront, v.v.) Kinh nghiệm kiến trúc Multi-AZ active-passive và thiết kế hệ thống có tính sẵn sàng cao Kinh nghiệm tích hợp AI với Google Gemini Flash Hiểu biết về công nghệ giáo dục (EdTech) Điều phối container và chiến lược chuyển đổi dự phòng Cơ hội khởi nghiệp tiềm năng hoặc mục tiêu mua lại Chỉ Số Thành Công:\nMức độ tương tác người dùng: Trung bình 3+ phiên mỗi tuần Tỷ lệ hoàn thành bài kiểm tra: 70%+ bài kiểm tra đã bắt đầu Giữ chân người dùng: 60%+ người dùng hoạt động hàng tháng Điểm NPS: 50+ (cho thấy sự hài lòng mạnh mẽ của người dùng) Cải thiện điểm IELTS trung bình: Tăng 0.5-1.0 band Bản kế hoạch dự án "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.6-ai-service/5.6.2-sqs-queues/","title":"SQS Queues","tags":[],"description":"","content":"Tổng Quan Tạo Amazon SQS queues cho asynchronous AI processing với Dead Letter Queues cho failed messages.\nTạo Writing Assessment Queue Setting Value Name ielts-ai-dev-writing-evaluation Type Standard Visibility timeout 5 minutes Message retention 14 days Dead-letter queue ielts-ai-dev-writing-evaluation-dlq Max receives 3 Create Speaking Assessment Queue Setting Value Name ielts-ai-dev-speaking-evaluation Visibility timeout 15 minutes Dead-letter queue ielts-ai-dev-speaking-evaluation-dlq Create Flashcard Generation Queue Setting Value Name ielts-ai-dev-flashcard-generation Visibility timeout 15 minutes Dead-letter queue ielts-ai-dev-flashcard-generation-dlq AWS CLI Commands # Tạo Dead Letter Queue aws sqs create-queue --queue-name ielts-writing-dlq # Tạo main queue với DLQ aws sqs create-queue \\ --queue-name ielts-writing-queue \\ --attributes \u0026#39;{ \u0026#34;VisibilityTimeout\u0026#34;: \u0026#34;300\u0026#34;, \u0026#34;MessageRetentionPeriod\u0026#34;: \u0026#34;1209600\u0026#34;, \u0026#34;RedrivePolicy\u0026#34;: \u0026#34;{\\\u0026#34;deadLetterTargetArn\\\u0026#34;:\\\u0026#34;arn:aws:sqs:ap-southeast-1:{account}:ielts-writing-dlq\\\u0026#34;,\\\u0026#34;maxReceiveCount\\\u0026#34;:\\\u0026#34;3\\\u0026#34;}\u0026#34; }\u0026#39; # Lặp lại cho speaking và flashcard queues aws sqs create-queue --queue-name ielts-speaking-dlq aws sqs create-queue --queue-name ielts-speaking-queue \\ --attributes \u0026#39;{\u0026#34;VisibilityTimeout\u0026#34;: \u0026#34;900\u0026#34;}\u0026#39; aws sqs create-queue --queue-name ielts-flashcard-dlq aws sqs create-queue --queue-name ielts-flashcard-queue \\ --attributes \u0026#39;{\u0026#34;VisibilityTimeout\u0026#34;: \u0026#34;900\u0026#34;}\u0026#39; Tóm Tắt Queue Queue Visibility Timeout DLQ Max Receives ielts-writing-queue 5 min ielts-writing-dlq 3 ielts-speaking-queue 15 min ielts-speaking-dlq 3 ielts-flashcard-queue 15 min ielts-flashcard-dlq 3 Bước Tiếp Theo Tiến hành đến Lambda Functions.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.7-cicd-pipeline/5.7.2-test-gwe/","title":"Tạo CodePipeline với trigger theo tag GitLab","tags":[],"description":"","content":"Thiết kế CodePipeline (Source → Build → Deploy) Build (CodeBuild) Project: dự án CodeBuild của dự án này (Source = CodePipeline) Environment variables: theo nhu cầu build của dự án Buildspec: dùng buildspec.yml có sẵn trong repository Hướng dẫn tạo CodePipeline Ở phần chọn tùy chọn tạo pipeline, chọn Build custom pipeline. Trong tab pipeline settings, đặt tên pipeline và dùng các thiết lập mặc định. Bật webhook events và thêm bộ lọc theo tag. Đặt mẫu tag là \u0026ldquo;v*\u0026rdquo;. Thêm dự án frontend/backend bằng AWS CodeBuild ở bước Build. Ở bước Deploy, chọn Amazon ECS làm nhà cung cấp triển khai. Chỉ định cluster và service để deploy. Điền file image definition như minh họa. Gửi tạo và hoàn tất, pipeline sẽ được tạo. "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3 Khắc phục vấn đề tài khoản AWS và tạo tài khoản mới nếu cần. Thành thạo cấu hình Hybrid DNS với Route 53 Resolver. Triển khai và hiểu VPC Peering cho giao tiếp giữa các VPC. Thảo luận kế hoạch dự án và chọn ngôn ngữ lập trình với team. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Quản trị quyền truy cập với AWS Identity and Access Management (IAM) 21/09/2025 23/09/2025 Quản trị quyền truy cập với AWS Identity and Access Management (IAM) 3 - Hoàn thành Lab 10: Route 53 và cấu hình Hybrid DNS.\n- Khởi chạy máy chủ ảo để triển khai và kiểm tra DNS.\n- Hoàn thành: Hybrid DNS Management with Amazon Route 53. 24/09/2025 25/09/2025 FCJ Playlist 4 - Triển khai VPC Peering cho giao tiếp private giữa các VPC.\n- Tạo các tài nguyên cần thiết cho cấu hình VPC Peering.\n- Dọn dẹp tài nguyên sau khi hoàn thành.\n- Hoàn thành: Network Integration with VPC Peering. 25/09/2025 26/09/2025 AWS VPC Peering 5 - Tham gia họp nhóm để thảo luận kế hoạch dự án và chọn ngôn ngữ lập trình.\n- Đặt deadline cho các thành viên nghiên cứu công nghệ đã chọn. 28/09/2025 28/09/2025 Họp nhóm Khóa học AWS Skill Builder đã hoàn thành Khóa học Danh mục Trạng thái Hybrid DNS Management with Amazon Route 53 Mạng ✅ Network Integration with VPC Peering Mạng ✅ Networking on AWS Workshop Mạng ✅ Infrastructure as Code with AWS CloudFormation DevOps ✅ Cloud Development with AWS Cloud9 Phát triển ✅ Static Website Hosting with Amazon S3 Lưu trữ ✅ Kết quả đạt được tuần 3 Kỹ năng kỹ thuật đã tiếp thu:\nRoute 53 và Hybrid DNS:\nCấu hình thành công hạ tầng Hybrid DNS với Route 53 Resolver Tạo và cấu hình Outbound Endpoints để chuyển tiếp DNS queries Thiết lập Route 53 Resolver rules cho conditional DNS resolution Triển khai Inbound Endpoints cho DNS queries từ on-premises đến AWS Kết nối thành công với RD Gateway Server trong các bài thực hành VPC Peering:\nNắm vững khái niệm VPC Peering cho giao tiếp private giữa các VPC mà không qua internet công cộng Kích hoạt Cross-Zone and Cross-Region DNS Resolution trong VPC Peering: EC2 instances có thể phân giải DNS của instances trong VPCs được peering ra địa chỉ IP private Hiểu rằng nếu không có tính năng này, DNS queries trả về public IPs, định tuyến traffic qua internet Học quy trình dọn dẹp tài nguyên để tránh chi phí không cần thiết Infrastructure as Code:\nHọc cách provision tài nguyên AWS sử dụng CloudFormation templates Hiểu nguyên tắc quản lý hạ tầng declarative Khám phá AWS Cloud9 như môi trường phát triển trên cloud Hợp tác nhóm:\nTham gia họp nhóm để xác định hướng đi dự án Chọn ngôn ngữ lập trình cho dự án Thiết lập deadline cho các thành viên nghiên cứu công nghệ đã chọn Tiếp tục hành trình học tập với sự hỗ trợ của FCJ team Bài học chính:\nHybrid DNS cho phép phân giải DNS liền mạch giữa on-premises và AWS VPC Peering hiệu quả về chi phí để kết nối VPCs nhưng có giới hạn (không có transitive peering) CloudFormation templates đảm bảo triển khai hạ tầng nhất quán, có thể lặp lại AWS Cloud9 loại bỏ sự phức tạp của việc thiết lập môi trường phát triển local "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.4-setup-fe/5.4.3-sg/","title":"Cấu hình Security Group","tags":[],"description":"","content":"Các container Frontend của chúng ta hoạt động trong Private Subnet. Để cho phép chúng nhận lưu lượng truy cập, ta cần cấu hình Security Group đóng vai trò như một bức tường lửa ảo.\nTuân thủ nguyên tắc bảo mật (best practices), chúng ta sẽ chỉ cho phép truy cập từ Application Load Balancer (ALB) vào cổng 3000. Mọi truy cập trực tiếp từ Internet hoặc các nguồn khác đều sẽ bị chặn.\n1. Tạo Security Group Truy cập EC2 Dashboard \u0026gt; Security Groups \u0026gt; Create security group. Basic details (Thông tin cơ bản): Security group name: ecs-private-sg. Description: security group for ecs. VPC: Chọn band-up-vpc. 2. Cấu hình Inbound Rules (Quy tắc chiều vào) Đây là bước quan trọng nhất. Chúng ta cần cho phép ALB giao tiếp với ứng dụng Next.js.\nInbound rules: Nhấn Add rule. Type: Custom TCP. Port range: 3000 (Cổng mà ứng dụng Next.js đang lắng nghe). Source: Chọn Custom và tìm chọn Security Group ID của ALB (ví dụ: alb-sg). Lưu ý: Bằng cách chọn ID của Security Group thay vì dải IP, chúng ta đảm bảo rằng chỉ có lưu lượng xuất phát từ Load Balancer mới được chấp nhận. Outbound rules (Quy tắc chiều ra): Giữ nguyên mặc định (Allow all traffic) để container có thể tải các gói tin hoặc gọi API bên ngoài. Nhấn Create security group. Security Group hiện đã sẵn sàng để được gắn vào ECS Task trong bước tiếp theo.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.3-network/","title":"Hạ tầng Mạng &amp; Bảo mật","tags":[],"description":"","content":"Tổng quan Trong phần này, chúng ta sẽ xây dựng lớp mạng nền tảng và các thiết lập bảo mật cốt lõi cho IELTS BandUp.\nMột kiến trúc mạng vững chắc là yếu tố then chốt để bảo vệ dữ liệu người dùng và đảm bảo tính sẵn sàng cao của hệ thống. Thay vì sử dụng các cài đặt mạng mặc định, chúng ta sẽ xây dựng một Virtual Private Cloud (VPC) tùy chỉnh, được thiết kế chuyên biệt cho môi trường production. Thiết lập này cho phép kiểm soát chặt chẽ luồng truy cập giữa các thành phần ứng dụng (Frontend, Backend, Database) và Internet.\nNgoài ra, chúng ta sẽ cấu hình các VPC Endpoints để cho phép các container trong mạng nội bộ giao tiếp an toàn với các dịch vụ AWS (như ECR và S3) mà không cần đi qua Internet công cộng, giúp tối ưu hóa cả về bảo mật lẫn hiệu năng mạng.\nCác bước thực hiện Chúng ta sẽ chia quy trình thiết lập hạ tầng thành các nhiệm vụ chính sau:\nVPC \u0026amp; Kết nối: Khởi tạo môi trường mạng cô lập, phân chia thành các Subnet Public/Private và cấu hình Internet Gateway (IGW) cho kết nối ra bên ngoài. Cân bằng tải (ALB): Thiết lập Application Load Balancer và các Target Group để phân phối lưu lượng truy cập đến các ECS task sau này. Bảo mật IAM: Cấp phát ecsTaskExecutionRole để ủy quyền cho Fargate container thực hiện các tác vụ như tải image và ghi log. Cấu hình VPC Endpoints: Thiết lập kết nối riêng tư đến các dịch vụ AWS (ECR, CloudWatch, S3) để bảo mật lưu lượng nội bộ. Nội dung Cấu hình VPC, Subnets \u0026amp; Routing Cài đặt Application Load Balancer (ALB) IAM Roles cho ECS Thiết lập VPC Endpoints "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.3-network/5.3.3-iam/","title":"IAM Roles cho ECS","tags":[],"description":"","content":"Để Amazon ECS có thể quản lý các container, dịch vụ này cần được cấp một số quyền hạn nhất định. Chúng ta phải tạo một IAM Role để ủy quyền cho ECS agent thực hiện các tác vụ như kéo (pull) container image từ Amazon ECR và gửi log đến Amazon CloudWatch thay mặt cho bạn.\nTạo ecsTaskExecutionRole Truy cập IAM Dashboard. Ở thanh điều hướng bên trái, chọn Roles. Nhấn Create role. Bước 1: Thực thể tin cậy (Trusted Entity)\nTrusted entity type: Chọn AWS service. Service or use case: Chọn Elastic Container Service. Chọn Elastic Container Service Task trong các tùy chọn hiện ra. Nhấn Next. Bước 2: Thêm quyền (Permissions)\nTrong thanh tìm kiếm, gõ AmazonECSTaskExecutionRolePolicy. Tích vào ô vuông cạnh tên chính sách AmazonECSTaskExecutionRolePolicy. Lưu ý: Đây là chính sách được AWS quản lý, cung cấp đủ quyền để kéo image từ ECR và tải log lên CloudWatch. Nhấn Next. Bước 3: Đặt tên và Xem lại\nRole name: Nhập ecsTaskExecutionRole. Kiểm tra lại cấu hình và nhấn Create role. Sau khi tạo xong, Role này đã sẵn sàng để gán cho các ECS Task Definition trong các phần tiếp theo của workshop.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.5-setup-be/5.5.3-redis/","title":"Tạo ElastiCache (Redis/Valkey)","tags":[],"description":"","content":"Trong bước này, chúng ta sẽ khởi tạo một kho dữ liệu in-memory để xử lý việc quản lý session và caching cho backend. Chúng ta sẽ sử dụng Amazon ElastiCache với engine Valkey (một nhánh mã nguồn mở hiệu năng cao của Redis được AWS hỗ trợ).\n1. Cấu hình Security Group Đầu tiên, tạo Security Group để cho phép backend giao tiếp với cache cluster.\nTruy cập EC2 \u0026gt; Security Groups \u0026gt; Create security group. Name: redis-sg. Inbound rules: Cho phép lưu lượng Custom TCP tại cổng 6379 từ nguồn là ecs-backend-sg. (Lưu ý: Hãy đảm bảo tạo SG này trước khi vào giao diện ElastiCache).\n2. Tạo Subnet Group Chúng ta cần xác định các subnet mà cache node sẽ hoạt động.\nTruy cập Amazon ElastiCache \u0026gt; Subnet groups \u0026gt; Create subnet group. Name: bandup-cached-subnet-group. VPC: Chọn band-up-vpc. Subnets: Chọn private-database-subnet-1 và private-database-subnet-2 (Availability Zones ap-southeast-1a và 1b). 3. Tạo ElastiCache Cluster Bây giờ chúng ta tiến hành khởi tạo cluster.\nTruy cập ElastiCache \u0026gt; Caches \u0026gt; Create cache. Engine: Chọn Valkey - recommended (Tương thích với Redis OSS). Deployment option: Chọn Node-based cluster (Cho phép kiểm soát loại instance). Creation method: Cluster cache. Cấu hình Cluster: Cluster mode: Disabled (Cấu trúc primary-replica đơn giản là đủ). Name: bandup-redis. Description: in memory db for bandup. Cấu hình Node: Node type: cache.t3.micro (Tiết kiệm chi phí cho workshop). Number of replicas: 0 (Chạy node đơn lẻ). Kết nối (Connectivity): Network type: IPv4. Subnet groups: Chọn bandup-cached-subnet-group. Bảo mật \u0026amp; Mã hóa: Encryption at rest: Enabled (Default key). Encryption in transit: Enabled. Access control: No access control (Chúng ta dựa vào Security Group để bảo mật). Security groups: Chọn redis-sg đã tạo trước đó. Sao lưu: Bật sao lưu tự động (Retention: 1 ngày). Nhấn Create. Trạng thái của cluster sẽ chuyển sang Creating. Sau khi chuyển sang Available, hãy ghi lại Primary Endpoint (có dạng ...cache.amazonaws.com:6379) để sử dụng cấu hình cho backend.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Blog 1 - Accelerate benefits claims processing with Amazon Bedrock Data Automation Bài blog giới thiệu cách các công ty quản lý quyền lợi nhân sự có thể nâng cao hiệu quả vận hành bằng cách tự động hóa quá trình xử lý yêu cầu bồi hoàn, vốn đang gặp thách thức bởi sự phụ thuộc vào hệ thống kế thừa, quy trình thủ công và vấn đề gian lận. Giải pháp được đề xuất sử dụng Amazon Bedrock Data Automation để tự động trích xuất và phân loại dữ liệu từ các tài liệu phi cấu trúc như hình ảnh séc và biên lai, giảm thiểu lỗi và tăng tốc thời gian xử lý. Đồng thời, giải pháp còn tích hợp mô hình ngôn ngữ lớn Amazon Nova Lite và Knowledge Bases để tự động xác thực và ra quyết định phê duyệt/từ chối dựa trên các quy tắc nghiệp vụ linh hoạt, giúp thích ứng nhanh chóng với các yêu cầu tuân thủ như HIPAA và ERISA, qua đó giảm chi phí vận hành và nâng cao sự hài lòng của nhân viên.\nBlog 2 - Enabling AI adoption at scale through enterprise risk management framework – Part 2 Blog này giới thiệu về các chiến lược thực tiễn để điều chỉnh Khung quản lý rủi ro doanh nghiệp (ERMF) nhằm thúc đẩy việc ứng dụng Generative AI ở quy mô lớn một cách an toàn và có trách nhiệm. Bài viết khám phá cách tích hợp các yếu tố quản trị Generative AI vào ERMF, xây dựng trên các quy trình quản lý rủi ro hiện có, đồng thời xử lý các đặc thù của Generative AI. Các lĩnh vực kiểm soát trọng yếu được trình bày chi tiết bao gồm Công bằng, Giải thích, Bảo mật và quyền riêng tư, An toàn, Khả năng kiểm soát, Tính xác thực và độ vững chắc, Quản trị, và Tính minh bạch. Kết thúc bài viết, người đọc sẽ có một lộ trình để cân bằng giữa đổi mới và các biện pháp kiểm soát chặt chẽ, giúp tổ chức bảo vệ trước các rủi ro như rò rỉ dữ liệu hay hiện tượng \u0026ldquo;ảo giác\u0026rdquo; của mô hình, đặc biệt quan trọng đối với các tổ chức trong lĩnh vực dịch vụ tài chính.\nBlog 3 - How PropHero built an intelligent property investment advisor with continuous evaluation using Amazon Bedrock Bài viết giới thiệu cách PropHero, một dịch vụ quản lý tài sản bất động sản hàng đầu tại Tây Ban Nha và Úc, đã hợp tác với AWS Generative AI Innovation Center để xây dựng một cố vấn đầu tư bất động sản thông minh. Giải pháp này sử dụng hệ thống AI hội thoại đa tác nhân (multi-agent) dựa trên Amazon Bedrock để cung cấp lời khuyên cá nhân hóa, đồng thời tích hợp cơ chế đánh giá liên tục nhằm đo lường các chỉ số chất lượng như Context Relevance, Response Groundedness, và Agent Goal Accuracy. Về hiệu quả kinh doanh, cố vấn AI đã đạt tỷ lệ goal accuracy 90%, giúp giảm 30% khối lượng công việc của bộ phận hỗ trợ khách hàng và tối ưu 60% chi phí AI so với việc chỉ sử dụng các mô hình cao cấp.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.6-ai-service/5.6.3-lambda-functions/","title":"Lambda Functions","tags":[],"description":"","content":"Tổng Quan Tầng AI Service bao gồm bốn Lambda functions cung cấp sức mạnh cho nền tảng học IELTS. Các functions này xử lý yêu cầu bất đồng bộ qua SQS queues và tích hợp với Google Gemini API và Amazon Bedrock để đánh giá bằng AI.\nLambda Function 1: Writing Evaluator Đánh giá bài luận IELTS Writing Task 1 và Task 2 sử dụng Gemini API với điểm band chi tiết.\nCài Đặt Giá Trị Function name bandup-writing-evaluator Runtime Python 3.11 Memory 1024 MB Timeout 5 phút Trigger SQS (bandup-writing-queue) AI Model Google Gemini 2.0 Flash Triển Khai Chính:\nimport json import os import boto3 import logging from typing import Dict, Any logger = logging.getLogger() logger.setLevel(logging.INFO) # Import từ Lambda layer from lambda_shared.gemini_client import GeminiClient from secrets_helper import get_gemini_api_key def lambda_handler(event: Dict[str, Any], context: Any) -\u0026gt; Dict[str, Any]: \u0026#34;\u0026#34;\u0026#34;Đánh giá bài luận IELTS Writing sử dụng Gemini API.\u0026#34;\u0026#34;\u0026#34; # Parse SQS message hoặc API Gateway request if is_sqs_event(event): request_data, job_id = parse_sqs_message(event) update_job_status(job_id, \u0026#39;processing\u0026#39;, \u0026#39;writing\u0026#39;) else: request_data = json.loads(event.get(\u0026#39;body\u0026#39;, \u0026#39;{}\u0026#39;)) # Lấy API key an toàn từ Secrets Manager gemini_api_key = get_gemini_api_key() # Lấy từ AWS Secrets Manager gemini_client = GeminiClient(api_key=gemini_api_key) # Trích xuất parameters từ request user_id = request_data.get(\u0026#39;user_id\u0026#39;) essay_content = request_data.get(\u0026#39;essay_content\u0026#39;) task_type = request_data.get(\u0026#39;task_type\u0026#39;, \u0026#39;TASK_2\u0026#39;) # Xây dựng prompt đánh giá prompt = build_writing_prompt(essay_content, task_type) # Gọi Gemini API để đánh giá response = gemini_client.generate_evaluation( prompt=prompt, feature=\u0026#39;writing_task2\u0026#39;, max_retries=3, timeout=60 ) # Parse và validate band scores evaluation = parse_gemini_response(response[\u0026#39;content\u0026#39;]) # Xây dựng kết quả với tiêu chí IELTS result = { \u0026#39;session_id\u0026#39;: request_data.get(\u0026#39;session_id\u0026#39;), \u0026#39;overall_band\u0026#39;: evaluation.get(\u0026#39;overall_band\u0026#39;), \u0026#39;task_achievement_band\u0026#39;: evaluation[\u0026#39;task_achievement\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;coherence_band\u0026#39;: evaluation[\u0026#39;coherence_cohesion\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;lexical_band\u0026#39;: evaluation[\u0026#39;lexical_resource\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;grammar_band\u0026#39;: evaluation[\u0026#39;grammatical_range_accuracy\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;feedback\u0026#39;: evaluation } # Lưu vào DynamoDB dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;) table = dynamodb.Table(os.environ.get(\u0026#39;DYNAMODB_EVALUATIONS\u0026#39;)) table.put_item(Item={ \u0026#39;evaluation_id\u0026#39;: result[\u0026#39;session_id\u0026#39;], \u0026#39;user_id\u0026#39;: user_id, \u0026#39;evaluation_type\u0026#39;: \u0026#39;writing\u0026#39;, \u0026#39;status\u0026#39;: \u0026#39;completed\u0026#39;, **result }) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(result)} Mẫu Prompt Gemini:\ndef build_writing_prompt(essay_content: str, task_type: str) -\u0026gt; str: return f\u0026#34;\u0026#34;\u0026#34;You are an experienced IELTS examiner. Evaluate this essay: Task Type: {task_type} ESSAY: {essay_content} Evaluate using IELTS band descriptors (1-9, 0.5 increments): 1. Task Achievement - Addresses all parts of task 2. Coherence and Cohesion - Logical organization 3. Lexical Resource - Vocabulary range and accuracy 4. Grammatical Range and Accuracy - Sentence structures RESPOND IN JSON FORMAT: {{ \u0026#34;overall_band\u0026#34;: \u0026lt;float\u0026gt;, \u0026#34;task_achievement\u0026#34;: {{\u0026#34;band\u0026#34;: \u0026lt;float\u0026gt;, \u0026#34;feedback\u0026#34;: \u0026#34;...\u0026#34;}}, \u0026#34;coherence_cohesion\u0026#34;: {{\u0026#34;band\u0026#34;: \u0026lt;float\u0026gt;, \u0026#34;feedback\u0026#34;: \u0026#34;...\u0026#34;}}, \u0026#34;lexical_resource\u0026#34;: {{\u0026#34;band\u0026#34;: \u0026lt;float\u0026gt;, \u0026#34;feedback\u0026#34;: \u0026#34;...\u0026#34;}}, \u0026#34;grammatical_range_accuracy\u0026#34;: {{\u0026#34;band\u0026#34;: \u0026lt;float\u0026gt;, \u0026#34;feedback\u0026#34;: \u0026#34;...\u0026#34;}}, \u0026#34;quoted_examples\u0026#34;: [{{\u0026#34;quote\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;issue\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;suggestion\u0026#34;: \u0026#34;...\u0026#34;}}] }}\u0026#34;\u0026#34;\u0026#34; Lambda Function 2: Speaking Evaluator Đánh giá IELTS Speaking sử dụng Gemini native audio processing - rẻ hơn 72% và nhanh gấp 2 lần so với AWS Transcribe.\nCài Đặt Giá Trị Function name bandup-speaking-evaluator Runtime Python 3.11 Memory 2048 MB Timeout 5 phút Trigger SQS (bandup-speaking-queue) AI Model Gemini 2.5 Flash (Native Audio) Triển Khai Chính:\nimport json import os import boto3 import logging from typing import Dict, Any, Tuple logger = logging.getLogger() # Import từ Lambda layer from lambda_shared.gemini_client import GeminiClient from secrets_helper import get_gemini_api_key def download_audio_from_s3(audio_url: str) -\u0026gt; Tuple[bytes, str]: \u0026#34;\u0026#34;\u0026#34;Tải file audio từ S3 và xác định MIME type.\u0026#34;\u0026#34;\u0026#34; s3_client = boto3.client(\u0026#39;s3\u0026#39;) # Parse S3 URL: s3://bucket-name/path/to/file.mp3 parts = audio_url.replace(\u0026#39;s3://\u0026#39;, \u0026#39;\u0026#39;).split(\u0026#39;/\u0026#39;, 1) bucket, key = parts[0], parts[1] response = s3_client.get_object(Bucket=bucket, Key=key) audio_bytes = response[\u0026#39;Body\u0026#39;].read() # Xác định MIME type từ extension mime_types = {\u0026#39;.mp3\u0026#39;: \u0026#39;audio/mp3\u0026#39;, \u0026#39;.wav\u0026#39;: \u0026#39;audio/wav\u0026#39;, \u0026#39;.m4a\u0026#39;: \u0026#39;audio/m4a\u0026#39;} ext = \u0026#39;.\u0026#39; + key.split(\u0026#39;.\u0026#39;)[-1].lower() mime_type = mime_types.get(ext, \u0026#39;audio/mp3\u0026#39;) return audio_bytes, mime_type def lambda_handler(event: Dict[str, Any], context: Any) -\u0026gt; Dict[str, Any]: \u0026#34;\u0026#34;\u0026#34;Đánh giá IELTS Speaking sử dụng Gemini native audio.\u0026#34;\u0026#34;\u0026#34; # Parse request request_data = parse_request(event) # Lấy API key từ Secrets Manager gemini_api_key = get_gemini_api_key() gemini_client = GeminiClient(api_key=gemini_api_key) # Trích xuất parameters audio_url = request_data.get(\u0026#39;audio_url\u0026#39;) part = request_data.get(\u0026#39;part\u0026#39;, \u0026#39;PART_1\u0026#39;) questions = request_data.get(\u0026#39;questions\u0026#39;, []) # Bước 1: Tải audio từ S3 audio_bytes, mime_type = download_audio_from_s3(audio_url) logger.info(f\u0026#34;Đã tải {len(audio_bytes)} bytes, MIME: {mime_type}\u0026#34;) # Bước 2: Gửi audio trực tiếp đến Gemini (MỘT lần gọi API) # Không cần AWS Transcribe - Gemini xử lý audio trực tiếp evaluation = gemini_client.evaluate_audio( audio_bytes=audio_bytes, part=part, questions=questions, mime_type=mime_type, max_retries=3, timeout=120 ) # Bước 3: Xây dựng response với tiêu chí IELTS Speaking result = { \u0026#39;session_id\u0026#39;: request_data.get(\u0026#39;session_id\u0026#39;), \u0026#39;transcript\u0026#39;: evaluation.get(\u0026#39;transcript\u0026#39;), \u0026#39;duration\u0026#39;: evaluation.get(\u0026#39;duration_seconds\u0026#39;), \u0026#39;overall_band\u0026#39;: evaluation.get(\u0026#39;overall_band\u0026#39;), \u0026#39;fluency_band\u0026#39;: evaluation[\u0026#39;fluency_coherence\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;lexical_band\u0026#39;: evaluation[\u0026#39;lexical_resource\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;grammar_band\u0026#39;: evaluation[\u0026#39;grammatical_range_accuracy\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;pronunciation_band\u0026#39;: evaluation[\u0026#39;pronunciation\u0026#39;][\u0026#39;band\u0026#39;], \u0026#39;model_used\u0026#39;: \u0026#39;gemini-2.5-flash-audio\u0026#39;, \u0026#39;estimated_cost\u0026#39;: evaluation[\u0026#39;usage\u0026#39;][\u0026#39;cost\u0026#39;] } # Lưu vào DynamoDB save_evaluation(result, request_data.get(\u0026#39;user_id\u0026#39;)) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(result)} So Sánh Chi Phí:\nPhương Pháp Chi Phí / 3-phút Audio Độ Trễ Gemini Native Audio ~$0.021 30-45s AWS Transcribe + LLM ~$0.076 60-90s Tiết Kiệm 72% Nhanh gấp 2x Lambda Function 3: Flashcard Generator (RAG) Tạo flashcards từ tài liệu PDF sử dụng RAG pipeline nhẹ với Titan Embeddings (in-memory vector store, tối ưu cho Lambda package \u0026lt;50MB).\nCài Đặt Giá Trị Function name bandup-flashcard-generator Runtime Python 3.11 Memory 1024 MB Timeout 10 phút Trigger SQS (bandup-flashcard-queue) AI Model Gemini + Amazon Titan Embeddings V2 Luồng RAG Pipeline:\n┌─────────────┐ ┌──────────────┐ ┌─────────────────┐ │ PDF Upload │ ──▶ │ Chunking │ ──▶ │ Titan Embeddings│ │ (S3) │ │ (3000 chars) │ │ (Bedrock) │ └─────────────┘ └──────────────┘ └────────┬────────┘ │ ▼ ┌─────────────┐ ┌──────────────┐ ┌─────────────────┐ │ Flashcards │ ◀── │ Gemini │ ◀── │ In-Memory Store │ │ (JSON) │ │ Generation │ │ (Cosine Sim) │ └─────────────┘ └──────────────┘ └─────────────────┘ Triển Khai Chính:\nimport json import os import boto3 import time import google.generativeai as genai from typing import Dict, Any, List from concurrent.futures import ThreadPoolExecutor, as_completed logger = logging.getLogger() # Global instance cho warm starts (tối ưu Lambda) _rag_instance = None _s3_client = None def get_s3_client(): \u0026#34;\u0026#34;\u0026#34;Lấy cached S3 client.\u0026#34;\u0026#34;\u0026#34; global _s3_client if _s3_client is None: _s3_client = boto3.client(\u0026#39;s3\u0026#39;) return _s3_client def get_rag_instance(api_key: str): \u0026#34;\u0026#34;\u0026#34;Lấy cached RAG instance cho warm starts.\u0026#34;\u0026#34;\u0026#34; global _rag_instance if _rag_instance is None: _rag_instance = RAG( api_key=api_key, chunk_size=int(os.environ.get(\u0026#39;RAG_CHUNK_SIZE\u0026#39;, \u0026#39;500\u0026#39;)), chunk_overlap=int(os.environ.get(\u0026#39;RAG_CHUNK_OVERLAP\u0026#39;, \u0026#39;100\u0026#39;)) ) logger.info(\u0026#34;Cold start: RAG instance created\u0026#34;) else: logger.info(\u0026#34;Warm start: Reusing RAG instance\u0026#34;) return _rag_instance def download_pdf_from_s3(bucket: str, key: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Tải PDF từ S3 về /tmp.\u0026#34;\u0026#34;\u0026#34; s3 = get_s3_client() local_path = f\u0026#34;/tmp/{key.split(\u0026#39;/\u0026#39;)[-1]}\u0026#34; s3.download_file(bucket, key, local_path) return local_path def lambda_handler(event: Dict[str, Any], context: Any) -\u0026gt; Dict[str, Any]: \u0026#34;\u0026#34;\u0026#34;Tạo flashcard dựa trên RAG (nhẹ).\u0026#34;\u0026#34;\u0026#34; start_time = time.time() is_async = is_sqs_event(event) # Parse request if is_async: request, job_id = parse_sqs_message(event) update_job_status(job_id, \u0026#39;processing\u0026#39;) else: request = json.loads(event.get(\u0026#39;body\u0026#39;, \u0026#39;{}\u0026#39;)) if isinstance(event.get(\u0026#39;body\u0026#39;), str) else event # Lấy S3 location pdf_url = request.get(\u0026#39;pdf_url\u0026#39;) s3_bucket, s3_key = parse_s3_url(pdf_url) # Lấy API key từ Secrets Manager secret_arn = os.environ.get(\u0026#39;GEMINI_API_KEY_SECRET_ARN\u0026#39;) secrets_client = boto3.client(\u0026#39;secretsmanager\u0026#39;) api_key = secrets_client.get_secret_value(SecretId=secret_arn)[\u0026#39;SecretString\u0026#39;] # Lấy parameters num_cards = int(request.get(\u0026#39;num_cards\u0026#39;, 10)) difficulty = request.get(\u0026#39;difficulty\u0026#39;, \u0026#39;MEDIUM\u0026#39;) question_types = request.get(\u0026#39;question_types\u0026#39;, [\u0026#39;DEFINITION\u0026#39;, \u0026#39;VOCABULARY\u0026#39;, \u0026#39;COMPREHENSION\u0026#39;]) # Bước 1: Tải PDF từ S3 local_pdf = download_pdf_from_s3(s3_bucket, s3_key) # Bước 2: Index document với RAG (Titan Embeddings + in-memory store) rag = get_rag_instance(api_key) rag._vector_store = None # Reset cho document mới rag._chunks = [] index_result = rag.index_document(local_pdf, document_id=s3_key) logger.info(f\u0026#34;Đã index {index_result[\u0026#39;chunk_count\u0026#39;]} chunks từ {index_result[\u0026#39;page_count\u0026#39;]} trang\u0026#34;) # Bước 3: Truy xuất chunks liên quan (hybrid approach) if index_result[\u0026#39;chunk_count\u0026#39;] \u0026lt;= 15: # Document nhỏ: dùng representative chunks chunks = rag.get_representative_chunks(num_chunks=min(10, index_result[\u0026#39;chunk_count\u0026#39;])) retrieval_method = \u0026#34;representative\u0026#34; else: # Document lớn: dùng smart keyword-based queries chunks = rag.retrieve_with_smart_queries(top_k_per_query=3) retrieval_method = \u0026#34;smart_queries\u0026#34; # Bước 4: Tạo flashcards với Gemini prompt = generate_flashcards_prompt(chunks, num_cards, difficulty, question_types) flashcard_result = call_gemini(prompt, api_key) # Dọn dẹp os.remove(local_pdf) # Xây dựng response total_time = time.time() - start_time response_body = { \u0026#39;status\u0026#39;: \u0026#39;success\u0026#39;, \u0026#39;set_id\u0026#39;: request.get(\u0026#39;set_id\u0026#39;), \u0026#39;user_id\u0026#39;: request.get(\u0026#39;user_id\u0026#39;), \u0026#39;document\u0026#39;: { \u0026#39;s3_bucket\u0026#39;: s3_bucket, \u0026#39;s3_key\u0026#39;: s3_key, \u0026#39;page_count\u0026#39;: index_result[\u0026#39;page_count\u0026#39;], \u0026#39;chunk_count\u0026#39;: index_result[\u0026#39;chunk_count\u0026#39;] }, \u0026#39;retrieval\u0026#39;: { \u0026#39;method\u0026#39;: retrieval_method, \u0026#39;chunks_used\u0026#39;: len(chunks), \u0026#39;keywords\u0026#39;: index_result.get(\u0026#39;keywords\u0026#39;, [])[:5] }, \u0026#39;flashcards\u0026#39;: flashcard_result.get(\u0026#39;flashcards\u0026#39;, []), \u0026#39;total_cards\u0026#39;: len(flashcard_result.get(\u0026#39;flashcards\u0026#39;, [])), \u0026#39;metrics\u0026#39;: { \u0026#39;total_time_ms\u0026#39;: round(total_time * 1000) } } # Lưu vào DynamoDB (bảng bandup-flashcard-sets) dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;) table = dynamodb.Table(os.environ.get(\u0026#39;DYNAMODB_FLASHCARD_SETS\u0026#39;)) table.put_item(Item={ \u0026#39;set_id\u0026#39;: request.get(\u0026#39;set_id\u0026#39;), \u0026#39;user_id\u0026#39;: request.get(\u0026#39;user_id\u0026#39;), \u0026#39;document_id\u0026#39;: s3_key, \u0026#39;status\u0026#39;: \u0026#39;completed\u0026#39;, \u0026#39;flashcards\u0026#39;: json.dumps(response_body[\u0026#39;flashcards\u0026#39;]), \u0026#39;total_cards\u0026#39;: response_body[\u0026#39;total_cards\u0026#39;], \u0026#39;page_count\u0026#39;: index_result[\u0026#39;page_count\u0026#39;], \u0026#39;chunk_count\u0026#39;: index_result[\u0026#39;chunk_count\u0026#39;], \u0026#39;created_at\u0026#39;: int(time.time()) }) if is_async: return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: \u0026#39;OK\u0026#39;} return create_response(200, response_body) Titan Embeddings với Xử Lý Song Song:\nclass TitanEmbeddings: \u0026#34;\u0026#34;\u0026#34;Amazon Titan Text Embeddings V2 qua Bedrock với xử lý song song.\u0026#34;\u0026#34;\u0026#34; MODEL_ID = \u0026#34;amazon.titan-embed-text-v2:0\u0026#34; def __init__(self, region: str = None): self.region = region or os.environ.get(\u0026#39;BEDROCK_REGION\u0026#39;, \u0026#39;us-east-1\u0026#39;) self._client = None @property def client(self): if self._client is None: self._client = boto3.client(\u0026#39;bedrock-runtime\u0026#39;, region_name=self.region) return self._client def embed(self, text: str) -\u0026gt; List[float]: \u0026#34;\u0026#34;\u0026#34;Lấy embedding cho single text sử dụng Titan V2.\u0026#34;\u0026#34;\u0026#34; response = self.client.invoke_model( modelId=self.MODEL_ID, body=json.dumps({ \u0026#34;inputText\u0026#34;: text[:8000], # Độ dài input tối đa \u0026#34;dimensions\u0026#34;: 512, \u0026#34;normalize\u0026#34;: True }), contentType=\u0026#34;application/json\u0026#34;, accept=\u0026#34;application/json\u0026#34; ) result = json.loads(response[\u0026#39;body\u0026#39;].read()) return result[\u0026#39;embedding\u0026#39;] def embed_batch_parallel(self, texts: List[str], max_workers: int = 10) -\u0026gt; List[List[float]]: \u0026#34;\u0026#34;\u0026#34;Embed nhiều texts SONG SONG sử dụng ThreadPoolExecutor.\u0026#34;\u0026#34;\u0026#34; embeddings = [None] * len(texts) with ThreadPoolExecutor(max_workers=max_workers) as executor: futures = {executor.submit(self.embed, t): i for i, t in enumerate(texts)} for future in as_completed(futures): idx = futures[future] embeddings[idx] = future.result() return embeddings RAG Pipeline (In-Memory):\nimport math import fitz # PyMuPDF class RAG: \u0026#34;\u0026#34;\u0026#34;RAG nhẹ sử dụng Titan Embeddings + in-memory cosine similarity.\u0026#34;\u0026#34;\u0026#34; def __init__(self, api_key: str, chunk_size: int = 3000, chunk_overlap: int = 300): self.api_key = api_key self.chunk_size = chunk_size self.chunk_overlap = chunk_overlap self._chunks = [] self._embeddings = [] self._titan = TitanEmbeddings() self._keywords = [] def index_document(self, pdf_path: str, document_id: str = None) -\u0026gt; Dict: \u0026#34;\u0026#34;\u0026#34;Index PDF với Titan V2 embeddings (xử lý song song).\u0026#34;\u0026#34;\u0026#34; # Tải các trang PDF pages = [] with fitz.open(pdf_path) as doc: for page_num, page in enumerate(doc): text = page.get_text() if text.strip(): pages.append({\u0026#39;content\u0026#39;: text, \u0026#39;page\u0026#39;: page_num + 1}) # Chunk text với overlap self._chunks = [] for page in pages: chunks = self._chunk_text(page[\u0026#39;content\u0026#39;]) for chunk in chunks: self._chunks.append({ \u0026#39;text\u0026#39;: chunk, \u0026#39;page\u0026#39;: page[\u0026#39;page\u0026#39;] }) # Trích xuất keywords cho smart query generation all_text = \u0026#34; \u0026#34;.join([c[\u0026#39;text\u0026#39;] for c in self._chunks]) self._keywords = self._extract_keywords(all_text, top_n=20) # Tạo embeddings song song (10 Bedrock calls đồng thời) texts = [c[\u0026#39;text\u0026#39;] for c in self._chunks] self._embeddings = self._titan.embed_batch_parallel(texts, max_workers=10) return { \u0026#39;page_count\u0026#39;: len(pages), \u0026#39;chunk_count\u0026#39;: len(self._chunks), \u0026#39;keywords\u0026#39;: self._keywords[:10] } def _cosine_similarity(self, a: List[float], b: List[float]) -\u0026gt; float: \u0026#34;\u0026#34;\u0026#34;Tính cosine similarity giữa hai vectors.\u0026#34;\u0026#34;\u0026#34; dot_product = sum(x * y for x, y in zip(a, b)) norm_a = math.sqrt(sum(x * x for x in a)) norm_b = math.sqrt(sum(x * x for x in b)) if norm_a == 0 or norm_b == 0: return 0.0 return dot_product / (norm_a * norm_b) def similarity_search(self, query: str, top_k: int = 5) -\u0026gt; List[Dict]: \u0026#34;\u0026#34;\u0026#34;Tìm kiếm chunks tương tự sử dụng in-memory cosine similarity.\u0026#34;\u0026#34;\u0026#34; query_embedding = self._titan.embed(query) # Tính similarities similarities = [] for i, embedding in enumerate(self._embeddings): score = self._cosine_similarity(query_embedding, embedding) similarities.append((i, score)) # Sắp xếp theo similarity (giảm dần) và trả về top-k similarities.sort(key=lambda x: x[1], reverse=True) results = [] for rank, (idx, score) in enumerate(similarities[:top_k]): chunk = self._chunks[idx] results.append({ \u0026#39;text\u0026#39;: chunk[\u0026#39;text\u0026#39;], \u0026#39;page\u0026#39;: chunk[\u0026#39;page\u0026#39;], \u0026#39;score\u0026#39;: score, \u0026#39;rank\u0026#39;: rank + 1 }) return results def generate_smart_queries(self, num_queries: int = 5) -\u0026gt; List[str]: \u0026#34;\u0026#34;\u0026#34;Tạo queries theo document sử dụng keywords đã trích xuất.\u0026#34;\u0026#34;\u0026#34; kw = self._keywords queries = [] if len(kw) \u0026gt;= 2: queries.append(f\u0026#34;definition and explanation of {kw[0]} and {kw[1]}\u0026#34;) if len(kw) \u0026gt;= 4: queries.append(f\u0026#34;key concepts about {kw[2]} {kw[3]}\u0026#34;) if len(kw) \u0026gt;= 6: queries.append(f\u0026#34;important information regarding {kw[4]} {kw[5]}\u0026#34;) return queries[:num_queries] def retrieve_with_smart_queries(self, top_k_per_query: int = 3) -\u0026gt; List[Dict]: \u0026#34;\u0026#34;\u0026#34;Truy xuất chunks sử dụng nhiều smart queries cho coverage tốt hơn.\u0026#34;\u0026#34;\u0026#34; queries = self.generate_smart_queries() seen_texts = set() all_results = [] for query in queries: results = self.similarity_search(query, top_k=top_k_per_query) for r in results: if r[\u0026#39;text\u0026#39;] not in seen_texts: seen_texts.add(r[\u0026#39;text\u0026#39;]) all_results.append(r) return sorted(all_results, key=lambda x: x[\u0026#39;score\u0026#39;], reverse=True) def get_representative_chunks(self, num_chunks: int = 10) -\u0026gt; List[Dict]: \u0026#34;\u0026#34;\u0026#34;Lấy chunks phân bố đều trong document.\u0026#34;\u0026#34;\u0026#34; if len(self._chunks) \u0026lt;= num_chunks: return [{\u0026#39;text\u0026#39;: c[\u0026#39;text\u0026#39;], \u0026#39;page\u0026#39;: c[\u0026#39;page\u0026#39;], \u0026#39;score\u0026#39;: 1.0} for c in self._chunks] step = len(self._chunks) // num_chunks return [{\u0026#39;text\u0026#39;: self._chunks[i * step][\u0026#39;text\u0026#39;], \u0026#39;page\u0026#39;: self._chunks[i * step][\u0026#39;page\u0026#39;], \u0026#39;score\u0026#39;: 1.0} for i in range(num_chunks)] Prompt Tạo Flashcard:\ndef generate_flashcards_prompt(chunks: List[Dict], num_cards: int, difficulty: str, question_types: List[str]) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Xây dựng prompt cho Gemini tạo flashcard.\u0026#34;\u0026#34;\u0026#34; context = \u0026#34;\\n\\n\u0026#34;.join([ f\u0026#34;[Chunk {i+1}] (Page {c.get(\u0026#39;page\u0026#39;, \u0026#39;?\u0026#39;)}):\\n{c[\u0026#39;text\u0026#39;]}\u0026#34; for i, c in enumerate(chunks) ]) return f\u0026#34;\u0026#34;\u0026#34;Based on the following document excerpts, generate {num_cards} flashcards. CONTEXT: {context} REQUIREMENTS: - Difficulty: {difficulty} - Generate exactly {num_cards} flashcards - Each flashcard should have a clear question and concise answer - Focus on key concepts, definitions, and important facts - Use these question types: {\u0026#34;, \u0026#34;.join(question_types)} OUTPUT FORMAT (JSON): {{ \u0026#34;flashcards\u0026#34;: [ {{ \u0026#34;question\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;answer\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;DEFINITION\u0026#34;, \u0026#34;difficulty\u0026#34;: \u0026#34;{difficulty}\u0026#34;, \u0026#34;source_chunk\u0026#34;: 1 }} ] }} Return ONLY valid JSON.\u0026#34;\u0026#34;\u0026#34; def call_gemini(prompt: str, api_key: str) -\u0026gt; Dict: \u0026#34;\u0026#34;\u0026#34;Gọi Gemini API để tạo flashcard.\u0026#34;\u0026#34;\u0026#34; import google.generativeai as genai genai.configure(api_key=api_key) model = genai.GenerativeModel( model_name=os.environ.get(\u0026#39;GEMINI_MODEL\u0026#39;, \u0026#39;gemini-2.0-flash\u0026#39;), generation_config={ \u0026#39;temperature\u0026#39;: 0.3, \u0026#39;max_output_tokens\u0026#39;: 4096 } ) response = model.generate_content(prompt) text = response.text # Trích xuất JSON nếu được wrap trong markdown if \u0026#39;```json\u0026#39; in text: text = text.split(\u0026#39;```json\u0026#39;)[1].split(\u0026#39;```\u0026#39;)[0] return json.loads(text.strip()) Lambda Function 4: S3 Upload Handler Tạo presigned URLs để upload file an toàn lên S3.\nCài Đặt Giá Trị Function name bandup-s3-upload Runtime Python 3.11 Memory 256 MB Timeout 30 giây Trigger API Gateway (sync) Triển Khai Chính:\nimport json import os import boto3 from datetime import datetime from typing import Dict, Any s3_client = boto3.client(\u0026#39;s3\u0026#39;) def lambda_handler(event: Dict[str, Any], context: Any) -\u0026gt; Dict: \u0026#34;\u0026#34;\u0026#34;Tạo presigned URL cho S3 upload.\u0026#34;\u0026#34;\u0026#34; request = json.loads(event.get(\u0026#39;body\u0026#39;, \u0026#39;{}\u0026#39;)) user_id = request.get(\u0026#39;user_id\u0026#39;) filename = request.get(\u0026#39;filename\u0026#39;) content_type = request.get(\u0026#39;content_type\u0026#39;, \u0026#39;application/octet-stream\u0026#39;) upload_type = request.get(\u0026#39;upload_type\u0026#39;, \u0026#39;general\u0026#39;) # Xác định bucket dựa trên upload type bucket_map = { \u0026#39;speaking_audio\u0026#39;: os.environ.get(\u0026#39;S3_BUCKET_AUDIO\u0026#39;), \u0026#39;flashcard_pdf\u0026#39;: os.environ.get(\u0026#39;S3_BUCKET_DOCUMENTS\u0026#39;), \u0026#39;writing_essay\u0026#39;: os.environ.get(\u0026#39;S3_BUCKET_DOCUMENTS\u0026#39;), } bucket = bucket_map.get(upload_type) # Tạo S3 key có tổ chức timestamp = datetime.now().strftime(\u0026#39;%Y%m%d_%H%M%S\u0026#39;) key = f\u0026#34;uploads/{upload_type}/{user_id}/{timestamp}_{filename}\u0026#34; # Tạo presigned PUT URL (hết hạn sau 15 phút) upload_url = s3_client.generate_presigned_url( \u0026#39;put_object\u0026#39;, Params={\u0026#39;Bucket\u0026#39;: bucket, \u0026#39;Key\u0026#39;: key, \u0026#39;ContentType\u0026#39;: content_type}, ExpiresIn=900 ) # Tạo presigned GET URL (hết hạn sau 1 giờ) get_url = s3_client.generate_presigned_url( \u0026#39;get_object\u0026#39;, Params={\u0026#39;Bucket\u0026#39;: bucket, \u0026#39;Key\u0026#39;: key}, ExpiresIn=3600 ) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;headers\u0026#39;: {\u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;}, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;upload_url\u0026#39;: upload_url, \u0026#39;get_url\u0026#39;: get_url, \u0026#39;file_url\u0026#39;: f\u0026#34;s3://{bucket}/{key}\u0026#34;, \u0026#39;expires_in\u0026#39;: 900 }) } Quản Lý Secrets An Toàn Tất cả Lambda functions sử dụng AWS Secrets Manager để lấy API keys:\n# secrets_helper.py (trong Lambda Layer) import boto3 import os from functools import lru_cache @lru_cache(maxsize=1) def get_gemini_api_key() -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34;Lấy Gemini API key từ Secrets Manager (có cache).\u0026#34;\u0026#34;\u0026#34; client = boto3.client(\u0026#39;secretsmanager\u0026#39;) secret_arn = os.environ.get(\u0026#39;GEMINI_API_KEY_SECRET_ARN\u0026#39;) response = client.get_secret_value(SecretId=secret_arn) return response[\u0026#39;SecretString\u0026#39;] Best Practices Bảo Mật:\nKhông bao giờ hardcode API keys trong Lambda code Sử dụng AWS Secrets Manager cho tất cả credentials nhạy cảm Rotate secrets định kỳ sử dụng automatic rotation Sử dụng IAM roles với least-privilege permissions IAM Role cho Lambda Functions { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;BedrockAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;bedrock:InvokeModel\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:bedrock:*:*:foundation-model/amazon.titan-embed-text-v2*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;DynamoDBAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;dynamodb:PutItem\u0026#34;, \u0026#34;dynamodb:GetItem\u0026#34;, \u0026#34;dynamodb:Query\u0026#34;], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:dynamodb:*:*:table/bandup-evaluations\u0026#34;, \u0026#34;arn:aws:dynamodb:*:*:table/bandup-flashcard-sets\u0026#34; ] }, { \u0026#34;Sid\u0026#34;: \u0026#34;S3Access\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::bandup-*/*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;SQSAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;sqs:ReceiveMessage\u0026#34;, \u0026#34;sqs:DeleteMessage\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sqs:*:*:bandup-*-queue\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;SecretsAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;secretsmanager:GetSecretValue\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:secretsmanager:*:*:secret:bandup/*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;CloudWatchLogs\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:log-group:/aws/lambda/bandup-*\u0026#34; } ] } Bảng DynamoDB Các Lambda functions lưu kết quả vào hai bảng DynamoDB:\nBảng Sử Dụng Bởi Mục Đích bandup-evaluations Writing + Speaking Evaluators Lưu điểm band IELTS, feedback, transcripts bandup-flashcard-sets Flashcard Generator Lưu flashcards và document metadata Schema Bảng Evaluations (Writing \u0026amp; Speaking):\n# Sử dụng bởi Writing Evaluator table.put_item(Item={ \u0026#39;evaluation_id\u0026#39;: session_id, # Partition Key \u0026#39;user_id\u0026#39;: user_id, # Sort Key \u0026#39;evaluation_type\u0026#39;: \u0026#39;writing\u0026#39;, # \u0026#39;writing\u0026#39; hoặc \u0026#39;speaking\u0026#39; \u0026#39;status\u0026#39;: \u0026#39;completed\u0026#39;, \u0026#39;overall_band\u0026#39;: \u0026#39;7.0\u0026#39;, \u0026#39;task_achievement_band\u0026#39;: \u0026#39;7.0\u0026#39;, # Chỉ Writing \u0026#39;fluency_band\u0026#39;: \u0026#39;6.5\u0026#39;, # Chỉ Speaking \u0026#39;pronunciation_band\u0026#39;: \u0026#39;7.0\u0026#39;, # Chỉ Speaking \u0026#39;transcript\u0026#39;: \u0026#39;...\u0026#39;, # Chỉ Speaking \u0026#39;feedback\u0026#39;: json.dumps(feedback), \u0026#39;created_at\u0026#39;: timestamp }) Schema Bảng Flashcard Sets:\n# Sử dụng bởi Flashcard Generator table.put_item(Item={ \u0026#39;set_id\u0026#39;: set_id, # Partition Key \u0026#39;user_id\u0026#39;: user_id, # Sort Key \u0026#39;document_id\u0026#39;: document_id, \u0026#39;status\u0026#39;: \u0026#39;completed\u0026#39;, \u0026#39;flashcards\u0026#39;: json.dumps(flashcards), \u0026#39;total_cards\u0026#39;: 10, \u0026#39;page_count\u0026#39;: 5, \u0026#39;chunk_count\u0026#39;: 12, \u0026#39;created_at\u0026#39;: timestamp }) Biến Môi Trường Biến Mô Tả Ví Dụ GEMINI_API_KEY_SECRET_ARN Secrets Manager ARN arn:aws:secretsmanager:...:secret:bandup/gemini-api-key DYNAMODB_EVALUATIONS Bảng evaluations (Writing + Speaking) bandup-evaluations DYNAMODB_FLASHCARD_SETS Bảng flashcard sets bandup-flashcard-sets S3_BUCKET_AUDIO Audio bucket bandup-audio-bucket S3_BUCKET_DOCUMENTS Documents bucket bandup-documents-bucket BEDROCK_REGION Bedrock region cho Titan us-east-1 RAG_CHUNK_SIZE Chunk size cho RAG 3000 RAG_CHUNK_OVERLAP Chunk overlap 300 GEMINI_MODEL Tên Gemini model gemini-2.0-flash Deploy Lambda Functions # Đóng gói với dependencies cd rag_flashcard pip install -r requirements.txt -t package/ cp lambda_handler.py rag_pipeline.py package/ cd package \u0026amp;\u0026amp; zip -r ../function.zip . \u0026amp;\u0026amp; cd .. # Tạo Lambda function aws lambda create-function \\ --function-name bandup-flashcard-generator \\ --runtime python3.11 \\ --handler lambda_handler.lambda_handler \\ --role arn:aws:iam::${AWS_ACCOUNT_ID}:role/bandup-lambda-role \\ --timeout 600 \\ --memory-size 1024 \\ --zip-file fileb://function.zip \\ --environment Variables=\u0026#34;{ GEMINI_API_KEY_SECRET_ARN=arn:aws:secretsmanager:${AWS_REGION}:${AWS_ACCOUNT_ID}:secret:bandup/gemini-api-key, BEDROCK_REGION=us-east-1, RAG_CHUNK_SIZE=3000 }\u0026#34; # Thêm SQS trigger aws lambda create-event-source-mapping \\ --function-name bandup-flashcard-generator \\ --event-source-arn arn:aws:sqs:${AWS_REGION}:${AWS_ACCOUNT_ID}:bandup-flashcard-queue \\ --batch-size 1 Bước Tiếp Theo Tiến hành đến DynamoDB để cấu hình các bảng database.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/4-eventparticipated/","title":"Các sự kiện đã tham gia","tags":[],"description":"","content":"Event 1 Tên sự kiện: AWS Cloud Day Vietnam - AI Edition 2025 Ngày: 18 tháng 9 năm 2025 Địa điểm: Số 2 đường Hải Triều, Phường Bến Nghé, Quận 1, TP. Hồ Chí Minh Vai trò tham dự: Người tham dự Tổng quan sự kiện và Hoạt động chính Sự kiện AWS Cloud Day Vietnam - AI Edition 2025 đóng vai trò là diễn đàn then chốt nhằm thúc đẩy quá trình chuyển đổi số tại Việt Nam, khai thác sức mạnh của Điện toán đám mây và Trí tuệ nhân tạo. Sự kiện tập trung khai thác bốn chủ đề cốt lõi: Phổ cập AI Tạo sinh cho Doanh nghiệp Thu hẹp khoảng cách giữa Kinh doanh và CNTT trong Tài chính Thúc đẩy hiện đại hóa ngành công nghiệp Tăng cường các khuôn khổ bảo mật Các hoạt động trong ngày bao gồm các phiên họp toàn thể cấp cao với sự tham gia của các quan chức chính phủ và lãnh đạo ngành, tiếp theo là các chuyên đề kỹ thuật chuyên sâu tập trung vào Chiến lược dữ liệu, DevOps và Lộ trình di chuyển lên đám mây.\nBài học chính và Kết quả đạt được Thông tin chiến lược: Hiểu sâu hơn về mối tương tác quan trọng giữa AI Tạo sinh và chiến lược dữ liệu vững chắc, được xác định là động lực chính dẫn đến thành công trong các doanh nghiệp hiện đại. Tư duy \u0026ldquo;Di chuyển để Vận hành\u0026rdquo;: Nắm bắt được khung tư duy \u0026ldquo;Migrate to Operate\u0026rdquo;, nhấn mạnh việc sử dụng AI để tinh giản quy trình vận hành và tối ưu hóa chi phí sau khi chuyển đổi lên đám mây. Kiến thức kỹ thuật: Tiếp thu kiến thức về việc tích hợp AI Tạo sinh vào vòng đời DevOps, đặc biệt là trong việc tự động hóa tạo mã và kiểm thử. Đổi mới về bảo mật: Tìm hiểu về phương pháp \u0026ldquo;Bảo mật ngay từ thiết kế\u0026rdquo; (Security by Design), tập trung vào việc nhúng các biện pháp bảo mật trong suốt vòng đời ứng dụng thay vì chỉ dựa vào các biện pháp phòng thủ lớp ngoài. Sự kiện này đã cung cấp những kiến thức vô giá và bài học thực tế, nâng cao hơn nữa sự hiểu biết của tôi về sự giao thoa giữa AI, điện toán đám mây và bảo mật trong bối cảnh các giải pháp doanh nghiệp hiện đại.\nEvent 2 Tên sự kiện: Discover Agentic AI – Amazon QuickSuite Workshop\nNgày: 07/11/2025\nĐịa điểm: Văn phòng AWS Việt Nam, Tháp Tài chính Bitexco, Quận 1, TP. Hồ Chí Minh\nVai trò: Người tham dự\nTổng quan Sự kiện và Các Hoạt động Chính Workshop \u0026ldquo;Discover Agentic AI – Amazon QuickSuite\u0026rdquo;, được tổ chức với sự hợp tác của Cloud Kinetics, đóng vai trò là một phiên kỹ thuật chiến lược đánh dấu sự chuyển mình từ AI Tạo sinh (Generative AI) thụ động sang AI Tác tử (Agentic AI) tự chủ. Sự kiện nổi bật với buổi trình diễn trực tiếp (live demo) đầu tiên của Amazon QuickSuite tại Việt Nam. Nội dung workshop tập trung vào bốn trụ cột chính: Định nghĩa mô hình \u0026ldquo;Agentic\u0026rdquo;: Tự chủ (Autonomy), Suy luận (Reasoning) và Thực thi (Execution). Tích hợp Dữ liệu và AI thông qua hệ sinh thái Amazon QuickSuite. Thực hành xây dựng các khái niệm AI trực tiếp cùng các chuyên gia kỹ thuật AWS. Hỗ trợ tài chính cho đổi mới sáng tạo thông qua Chương trình AWS LIFT. Chương trình kết hợp giữa các phiên lý thuyết kiến trúc và các bài thực hành thực tế sử dụng Amazon QuickSight và Quick Suite Q, cho phép người tham dự xây dựng các mô hình AI chức năng ngay tại sự kiện.\nBài học Chính và Kết quả - Chuyển đổi Mô hình (Paradigm Shift): Hiểu rõ sự chuyển dịch từ Generative AI (tạo nội dung) sang Agentic AI (thực thi tác vụ tự chủ), nơi các hệ thống có thể nhận thức môi trường và hành động độc lập để giải quyết vấn đề kinh doanh. Hệ sinh thái Hợp nhất: Có được cái nhìn thực tế về Amazon QuickSuite, học cách tích hợp trí tuệ doanh nghiệp (QuickSight) với năng lực tạo sinh để tạo ra các \u0026ldquo;Tác tử Phân tích\u0026rdquo; (Analyst Agents) giúp tinh gọn quy trình vận hành. Linh hoạt trong Vận hành: Nhận ra giá trị chiến lược của khung làm việc \u0026ldquo;Quick\u0026rdquo;, nhấn mạnh vào việc triển khai nhanh và \u0026ldquo;Thời gian tạo ra Giá trị\u0026rdquo; (Time-to-Value), cho phép doanh nghiệp triển khai các giải pháp AI phức tạp với tốc độ cao. Hỗ trợ Chiến lược: Tìm hiểu về Chương trình AWS LIFT (cung cấp khoản tín dụng lên tới $80,000 USD), xác định đây là cơ chế quan trọng để giảm thiểu rủi ro cho R\u0026amp;D và tăng tốc việc áp dụng tính toán hiệu năng cao. Workshop này đã cung cấp một lộ trình cụ thể để xây dựng các hệ thống doanh nghiệp tự chủ, kết hợp kiến thức lý thuyết với kỹ năng kỹ thuật thực hành và thông tin tài chính chiến lược để thúc đẩy chuyển đổi số.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4 Theo kịp tiến độ học tập của nhóm về các dịch vụ AWS. Thành thạo thiết lập và cấu hình AWS Transit Gateway. Hiểu sâu về Amazon EC2 và các dịch vụ compute liên quan. Học Git cơ bản để hợp tác nhóm hiệu quả. Workshop: Bắt đầu VPC \u0026amp; Network Setup cho hạ tầng Bandup IELTS. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Khám phá AWS Transit Gateway: khái niệm, quy trình thiết lập và tài nguyên cần thiết.\n- So sánh sự khác biệt giữa VPC Peering và Transit Gateway.\n- Hoàn thành: Centralized Network Management with AWS Transit Gateway. 29/09/2025 30/09/2025 AWS Transit Gateway 3 - Nghiên cứu sâu về Amazon EC2 qua các bài giảng Module 3.\n- Học EC2 Auto Scaling cho quản lý tài nguyên tự động.\n- Hoàn thành: Scaling Applications with EC2 Auto Scaling. 01/10/2025 02/10/2025 FCJ Playlist 4 - Học và thực hành các lệnh Git (commit, push, pull) cho hợp tác nhóm.\n- Khám phá Amazon Lightsail cho các giải pháp compute đơn giản.\n- Hoàn thành: Simplified Computing with Amazon Lightsail. 03/10/2025 04/10/2025 Git Tutorial 5 - Đề xuất ý tưởng và phân công nhiệm vụ cho team để chuẩn bị proposal.\n- Nghiên cứu các chiến lược migration cho AWS.\n- Hoàn thành: VM Migration with AWS VM Import/Export.\n- Hoạt động Workshop: Tạo VPC với CIDR 10.0.0.0/16 và cấu hình DNS support. 05/10/2025 06/10/2025 Họp nhóm, Workshop 5.3 Khóa học AWS Skill Builder đã hoàn thành Khóa học Danh mục Trạng thái Centralized Network Management with AWS Transit Gateway Mạng ✅ Scaling Applications with EC2 Auto Scaling Compute ✅ Simplified Computing with Amazon Lightsail Compute ✅ Container Deployment with Amazon Lightsail Containers Containers ✅ VM Migration with AWS VM Import/Export Migration ✅ Database Migration with AWS DMS and SCT Migration ✅ Disaster Recovery with AWS Elastic Disaster Recovery Reliability ✅ Monitoring with Amazon CloudWatch Operations ✅ Kết quả đạt được tuần 4 Kỹ năng kỹ thuật đã tiếp thu:\nAWS Transit Gateway:\nThành thạo thiết lập và cấu hình Transit Gateway Hiểu các ưu điểm chính so với VPC Peering: Hỗ trợ topology multi-VPC phức tạp (mô hình hub-and-spoke) Cho phép transitive routing giữa các mạng được kết nối Đơn giản hóa quản lý mạng ở quy mô lớn Hỗ trợ VPN và Direct Connect attachments Học quản lý route table của Transit Gateway Amazon EC2 Deep Dive:\nHiểu toàn diện các tính năng chính của EC2: Elasticity: Scale tài nguyên lên/xuống theo nhu cầu Cấu hình linh hoạt: Nhiều instance types cho các workloads khác nhau Tối ưu chi phí: Mô hình On-Demand, Reserved, Spot instances Thành thạo EC2 Auto Scaling cho điều chỉnh tài nguyên tự động Hiểu Instance Store như block storage tạm thời cho EC2 Khám phá Amazon Lightsail như giải pháp đơn giản cho ứng dụng quy mô nhỏ Học về Lightsail Containers để triển khai container dễ dàng Dịch vụ Migration:\nHiểu AWS Application Migration Service (MGN) cho migration server Học VM Import/Export để migration máy ảo lên AWS Khám phá Database Migration Service (DMS) và Schema Conversion Tool (SCT) Nghiên cứu chiến lược disaster recovery với AWS Elastic Disaster Recovery DevOps và Monitoring:\nThành thạo các lệnh Git (commit, push, pull) và workflows nhóm Học CloudWatch cơ bản để monitor tài nguyên AWS Hợp tác nhóm:\nĐề xuất thành công ý tưởng và phân công nhiệm vụ cho proposal Team sẵn sàng bắt đầu giai đoạn implementation Thiết lập vai trò và trách nhiệm rõ ràng cho từng thành viên Tiến độ Workshop - VPC \u0026amp; Network Setup:\nTạo VPC với CIDR 10.0.0.0/16 trong region ap-southeast-1 Thiết kế kiến trúc subnet: Public subnets (10.0.1.0/24, 10.0.2.0/24) và Private subnets cho App (10.0.11.0/24, 10.0.12.0/24) và DB (10.0.21.0/24, 10.0.22.0/24) across hai AZs Cấu hình Internet Gateway cho public subnet internet access Thiết lập route tables cho proper traffic routing Bắt đầu cấu hình security groups cho multi-tier architecture Bài học chính:\nTransit Gateway thiết yếu cho quản lý kiến trúc multi-VPC phức tạp EC2 Auto Scaling đảm bảo ứng dụng xử lý được tải biến động hiệu quả Lightsail hoàn hảo cho workloads đơn giản mà không cần sự phức tạp của AWS Dịch vụ migration cung cấp nhiều đường dẫn để di chuyển workloads lên AWS Thiết kế VPC với public/private subnets riêng biệt cung cấp security isolation Triển khai Multi-AZ đảm bảo high availability từ network layer "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.5-setup-be/5.5.4-task/","title":"Tạo Service &amp; Task","tags":[],"description":"","content":"Trong bước cuối cùng của quá trình triển khai backend, chúng ta sẽ định nghĩa cấu hình chạy cho ứng dụng Spring Boot và khởi tạo nó dưới dạng một ECS Service ổn định.\n1. Tạo Task Definition Truy cập Amazon ECS \u0026gt; Task definitions \u0026gt; Create new task definition. Cấu hình Task definition: Family: bandup-backend. Launch type: AWS Fargate. OS/Architecture: Linux/X86_64. Task size: 1 vCPU và 2 GB Memory. Lưu ý: Ứng dụng Java (Spring Boot) thường yêu cầu nhiều bộ nhớ hơn Node.js để quản lý JVM heap hiệu quả. Task Role \u0026amp; Execution Role: Chọn ecsTaskExecutionRole. Chi tiết Container:\nName: bandup-be-container. Image URI: Nhập ECR URI (.../band-up-backend:v1.0.0). Container Port: 8080 (Cổng mặc định của Spring Boot). Cấu hình Biến môi trường (Thực hành tốt): Thay vì nhập thủ công các biến nhạy cảm (Database URL, Username, Password) dưới dạng văn bản thuần, chúng ta sẽ tải chúng từ một file bảo mật được lưu trữ trên S3.\nEnvironment files: Nhập S3 ARN của file .env (ví dụ: arn:aws:s3:::bandup2025-fcj/.env). Yêu cầu: Đảm bảo ecsTaskExecutionRole của bạn đã có quyền đọc (GetObjects) đối với file S3 này. 2. Tạo ECS Service Triển khai task definition vào cluster.\nTruy cập bandup-cluster \u0026gt; Services \u0026gt; Create. Cấu hình Deployment: Compute options: FARGATE. Family: bandup-backend (Chọn Revision mới nhất). Service name: bandup-backend-service. Desired tasks: 1. Mạng (Networking): VPC: band-up-vpc. Subnets: Chọn Private Subnets (private-subnet-1, private-subnet-2). Security group: Chọn ecs-backend-sg (Đã tạo ở bước 5.5.2). Cân bằng tải (Load Balancing): Load balancer: Chọn bandup-public-alb. Listener: Sử dụng listener có sẵn 80:HTTP. Target group: Tạo target group mới tên là target-bandup-be. Thông tin Container: Đảm bảo lưu lượng được chuyển đến cổng 8080. Nhấn Create. Dịch vụ sẽ tiến hành cấp phát tài nguyên Fargate, kéo image về, tải biến môi trường từ S3 và đăng ký container vào ALB. "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.4-setup-fe/5.4.4-task/","title":"Tạo Task Definition &amp; Service","tags":[],"description":"","content":"Trong bước cuối cùng của phần triển khai Frontend, chúng ta sẽ định nghĩa cách ứng dụng chạy (Task Definition) và triển khai nó dưới dạng một dịch vụ (ECS Service) có khả năng mở rộng, được kết nối trực tiếp với Load Balancer.\n1. Tạo Task Definition Task Definition đóng vai trò như một bản thiết kế (blueprint) cho ứng dụng.\nTruy cập Amazon ECS \u0026gt; Task definitions \u0026gt; Create new task definition. Cấu hình Task definition: Task definition family: bandup-frontend. Launch type: AWS Fargate. OS/Architecture: Linux/X86_64. Task size: .5 vCPU và 1 GB Memory (Đủ cho ứng dụng Next.js). Task Role \u0026amp; Task Execution Role: Chọn ecsTaskExecutionRole (Đã tạo ở phần 5.3.3). Chi tiết Container: Name: bandup-fe-container. Image URI: Nhập ECR URI chúng ta đã push trước đó (ví dụ: .../band-up-frontend:v1.0.0). Container port: 3000. Nhấn Create. 2. Tạo ECS Service Bây giờ chúng ta sẽ triển khai bản thiết kế này vào Cluster.\nTruy cập Clusters \u0026gt; Chọn bandup-cluster. Tại tab Services, nhấn Create. Bước 1: Môi trường (Environment)\nCompute options: Launch type -\u0026gt; FARGATE. Task definition: bandup-frontend (Revision 1). Service name: bandup-frontend-service. Desired tasks: 1 (Số lượng container muốn chạy). Bước 2: Mạng (Networking)\nVPC: band-up-vpc. Subnets: Chọn các Private Subnets (private-subnet-1, private-subnet-2). Security group: Chọn ecs-private-sg (Cho phép traffic từ ALB). Bước 3: Cân bằng tải (Load Balancing)\nLoad balancer type: Application Load Balancer. Load balancer: Chọn bandup-public-alb. Container to load balance: bandup-fe-container 3000:3000. Listener: Chọn Create new listener tại Port 80 (HTTP). Target group: Chọn Use an existing target group -\u0026gt; target-bandup-fe. Nhấn Create. Dịch vụ sẽ bắt đầu triển khai container của bạn. Hãy đợi đến khi trạng thái chuyển sang Active và Task status là Running. 3. Kiểm tra kết quả Khi dịch vụ đã ổn định, hãy mở trình duyệt web và truy cập vào DNS name của Application Load Balancer.\nBạn sẽ thấy trang chủ của IELTS BandUp tải thành công, được phục vụ từ container nằm an toàn trong private subnet.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.3-network/5.3.4-endpoints/","title":"Thiết lập VPC Endpoints","tags":[],"description":"","content":"Để đảm bảo an toàn bảo mật, các dịch vụ backend chạy trong Private Subnet không nên truy cập các dịch vụ AWS quan trọng thông qua Internet công cộng. Thay vào đó, chúng ta sử dụng AWS PrivateLink (VPC Endpoints) để giữ lưu lượng này hoàn toàn bên trong mạng lưới của AWS.\nChúng ta sẽ tạo 4 Endpoints:\nInterface Endpoints: Cho ECR (Docker \u0026amp; API) và CloudWatch Logs. Gateway Endpoint: Cho Amazon S3. 1. Tạo Interface Endpoints (ECR \u0026amp; CloudWatch) Chúng ta sẽ bắt đầu tạo endpoint cho ECR Docker (ecr.dkr). Quy trình này hoàn toàn tương tự cho ECR API (ecr.api) và CloudWatch (logs).\nBước 1: Chọn dịch vụ\nTruy cập VPC Dashboard \u0026gt; Endpoints \u0026gt; Create endpoint. Name tag: ecr-endpoint (cho Docker). Service category: Chọn AWS services. Services: Tìm kiếm ecr.dkr và chọn com.amazonaws.ap-southeast-1.ecr.dkr. Bước 2: Cấu hình VPC \u0026amp; Subnets\nVPC: Chọn band-up-vpc. Subnets: Chọn các Availability Zone và tích chọn các Private Subnets (private-app-subnet-1 và private-app-subnet-2). Lưu ý: Bước này sẽ tạo các Network Interface (ENI) trong private subnet đóng vai trò là cổng kết nối. Bước 3: Chọn Security Group\nSecurity groups: Chọn Security Group cho phép lưu lượng HTTPS (Port 443) từ VPC của bạn. Trong workshop này, bạn có thể chọn default security group nếu nó cho phép inbound traffic từ nội bộ VPC. Nhấn Create endpoint. Bước 4: Lặp lại cho ECR API và CloudWatch Lặp lại các bước trên để tạo thêm 2 Interface Endpoints:\nECR API: Tìm kiếm ecr.api -\u0026gt; Đặt tên: ecr-api-endpoint. CloudWatch Logs: Tìm kiếm logs -\u0026gt; Đặt tên: cloudwatch-endpoint. 2. Tạo Gateway Endpoint (S3) Đối với Amazon S3, chúng ta sử dụng Gateway Endpoint. Loại này tiết kiệm chi phí hơn và sử dụng bảng định tuyến (Route Table) thay vì card mạng ảo.\nNhấn Create endpoint. Name tag: s3-endpoint. Services: Tìm kiếm s3 và chọn com.amazonaws.ap-southeast-1.s3 (Loại: Gateway). VPC: Chọn band-up-vpc. Route tables: Tích chọn các Route Table được liên kết với Private Subnets. Nhấn Create endpoint. 3. Kiểm tra kết quả Sau khi hoàn tất, quay lại danh sách Endpoints. Bạn sẽ thấy 4 endpoint đang hoạt động, đảm bảo kết nối bảo mật cho hạ tầng hệ thống.\necr-endpoint (Interface) ecr-api-endpoint (Interface) cloudwatch-endpoint (Interface) s3-endpoint (Gateway) "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.4-setup-fe/","title":"Triển khai Frontend (ECS Fargate)","tags":[],"description":"","content":"Tổng quan Trong phần này, chúng ta sẽ tiến hành triển khai Frontend của IELTS BandUp (ứng dụng Next.js) lên hạ tầng AWS Cloud.\nChúng ta sẽ sử dụng Amazon Elastic Container Service (ECS) với loại hình khởi chạy Fargate. Cách tiếp cận serverless này cho phép vận hành các container mà không cần quản lý các máy chủ EC2 vật lý bên dưới. Dịch vụ Frontend sẽ được đặt trong các Private Subnet để đảm bảo bảo mật, nhưng vẫn cho phép người dùng truy cập thông qua Application Load Balancer (ALB) đã cấu hình ở phần trước.\nCác bước thực hiện Để triển khai thành công Frontend, chúng ta sẽ tuân theo quy trình sau:\nContainer Registry (ECR): Tạo kho lưu trữ (repository) để chứa các Docker image và đẩy mã nguồn từ máy local lên AWS. Cấu hình Bảo mật (Security Group): Thiết lập các quy tắc tường lửa, đảm bảo Frontend container chỉ nhận lưu lượng truy cập từ ALB. ECS Task \u0026amp; Service: Thiết lập bản thiết kế (Task Definition) cho container (CPU, RAM, Biến môi trường) và khởi chạy nó dưới dạng một Service ổn định. Nội dung Đóng gói ứng dụng với Docker Thiết lập ECR \u0026amp; Đẩy Image Cấu hình Security Group Tạo Task Definition \u0026amp; Service "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.6-ai-service/5.6.4-dynamodb/","title":"DynamoDB","tags":[],"description":"","content":"Tổng Quan Tạo hai bảng DynamoDB để lưu kết quả Lambda function:\nBảng Sử Dụng Bởi Mục Đích bandup-evaluations Writing + Speaking Evaluators Lưu điểm band IELTS, feedback, transcripts bandup-flashcard-sets Flashcard Generator Lưu flashcards và document metadata Bảng 1: Evaluations Table Lưu kết quả từ cả hai Lambda functions Writing Evaluator và Speaking Evaluator.\nCài Đặt Giá Trị Table name bandup-evaluations Partition key evaluation_id (String) Sort key user_id (String) Billing mode On-demand (PAY_PER_REQUEST) Schema Bảng:\nAttribute Type Mô Tả evaluation_id String Session ID duy nhất (PK) user_id String User identifier (SK) evaluation_type String writing hoặc speaking status String processing, completed, failed overall_band String Điểm band IELTS tổng (ví dụ: \u0026ldquo;7.0\u0026rdquo;) task_achievement_band String Chỉ Writing coherence_band String Chỉ Writing lexical_band String Cả Writing và Speaking grammar_band String Cả Writing và Speaking fluency_band String Chỉ Speaking pronunciation_band String Chỉ Speaking transcript String Chỉ Speaking - audio đã transcribe feedback String JSON-encoded detailed feedback model_used String AI model sử dụng để đánh giá created_at Number Unix timestamp Ví Dụ Item (Writing):\n{ \u0026#34;evaluation_id\u0026#34;: \u0026#34;eval-abc123\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;user-456\u0026#34;, \u0026#34;evaluation_type\u0026#34;: \u0026#34;writing\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;completed\u0026#34;, \u0026#34;overall_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;task_achievement_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;coherence_band\u0026#34;: \u0026#34;6.5\u0026#34;, \u0026#34;lexical_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;grammar_band\u0026#34;: \u0026#34;6.5\u0026#34;, \u0026#34;feedback\u0026#34;: \u0026#34;{\\\u0026#34;strengths\\\u0026#34;:[...],\\\u0026#34;weaknesses\\\u0026#34;:[...]}\u0026#34;, \u0026#34;model_used\u0026#34;: \u0026#34;gemini-writing_task2\u0026#34;, \u0026#34;created_at\u0026#34;: 1733644800 } Ví Dụ Item (Speaking):\n{ \u0026#34;evaluation_id\u0026#34;: \u0026#34;speak-xyz789\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;user-456\u0026#34;, \u0026#34;evaluation_type\u0026#34;: \u0026#34;speaking\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;completed\u0026#34;, \u0026#34;overall_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;fluency_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;lexical_band\u0026#34;: \u0026#34;6.5\u0026#34;, \u0026#34;grammar_band\u0026#34;: \u0026#34;7.0\u0026#34;, \u0026#34;pronunciation_band\u0026#34;: \u0026#34;6.5\u0026#34;, \u0026#34;transcript\u0026#34;: \u0026#34;Well, I\u0026#39;d like to talk about...\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;120.5\u0026#34;, \u0026#34;word_count\u0026#34;: 185, \u0026#34;feedback\u0026#34;: \u0026#34;{\\\u0026#34;fluency\\\u0026#34;:{...},\\\u0026#34;pronunciation\\\u0026#34;:{...}}\u0026#34;, \u0026#34;model_used\u0026#34;: \u0026#34;gemini-2.5-flash-audio\u0026#34;, \u0026#34;created_at\u0026#34;: 1733644800 } Bảng 2: Flashcard Sets Table Lưu kết quả từ Lambda function Flashcard Generator.\nCài Đặt Giá Trị Table name bandup-flashcard-sets Partition key set_id (String) Sort key user_id (String) Billing mode On-demand (PAY_PER_REQUEST) Schema Bảng:\nAttribute Type Mô Tả set_id String ID bộ flashcard duy nhất (PK) user_id String User identifier (SK) document_id String S3 key của tài liệu nguồn status String processing, completed, failed flashcards String JSON-encoded array của flashcards total_cards Number Số lượng flashcards được tạo page_count Number Số trang trong PDF nguồn chunk_count Number Số text chunks đã index created_at Number Unix timestamp Ví Dụ Item:\n{ \u0026#34;set_id\u0026#34;: \u0026#34;flashcard-set-123\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;user-456\u0026#34;, \u0026#34;document_id\u0026#34;: \u0026#34;uploads/documents/user-456/vocab-guide.pdf\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;completed\u0026#34;, \u0026#34;flashcards\u0026#34;: \u0026#34;[{\\\u0026#34;question\\\u0026#34;:\\\u0026#34;What is...\\\u0026#34;,\\\u0026#34;answer\\\u0026#34;:\\\u0026#34;...\\\u0026#34;}]\u0026#34;, \u0026#34;total_cards\u0026#34;: 15, \u0026#34;page_count\u0026#34;: 8, \u0026#34;chunk_count\u0026#34;: 24, \u0026#34;created_at\u0026#34;: 1733644800 } Tạo Tables với AWS CLI # Tạo bảng evaluations (Writing + Speaking) aws dynamodb create-table \\ --table-name bandup-evaluations \\ --attribute-definitions \\ AttributeName=evaluation_id,AttributeType=S \\ AttributeName=user_id,AttributeType=S \\ --key-schema \\ AttributeName=evaluation_id,KeyType=HASH \\ AttributeName=user_id,KeyType=RANGE \\ --billing-mode PAY_PER_REQUEST \\ --tags Key=Project,Value=bandup Key=Environment,Value=production # Tạo bảng flashcard sets aws dynamodb create-table \\ --table-name bandup-flashcard-sets \\ --attribute-definitions \\ AttributeName=set_id,AttributeType=S \\ AttributeName=user_id,AttributeType=S \\ --key-schema \\ AttributeName=set_id,KeyType=HASH \\ AttributeName=user_id,KeyType=RANGE \\ --billing-mode PAY_PER_REQUEST \\ --tags Key=Project,Value=bandup Key=Environment,Value=production Bật Point-in-Time Recovery Bật PITR để bảo vệ dữ liệu:\n# Bật PITR cho bảng evaluations aws dynamodb update-continuous-backups \\ --table-name bandup-evaluations \\ --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true # Bật PITR cho bảng flashcard sets aws dynamodb update-continuous-backups \\ --table-name bandup-flashcard-sets \\ --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true Query Patterns Lấy lịch sử đánh giá của user:\nresponse = table.query( IndexName=\u0026#39;user_id-created_at-index\u0026#39;, # Nếu có GSI KeyConditionExpression=Key(\u0026#39;user_id\u0026#39;).eq(\u0026#39;user-456\u0026#39;), ScanIndexForward=False, # Mới nhất trước Limit=10 ) Lấy đánh giá cụ thể theo ID:\nresponse = table.get_item( Key={ \u0026#39;evaluation_id\u0026#39;: \u0026#39;eval-abc123\u0026#39;, \u0026#39;user_id\u0026#39;: \u0026#39;user-456\u0026#39; } ) Lấy flashcard sets của user:\nresponse = table.query( KeyConditionExpression=Key(\u0026#39;user_id\u0026#39;).eq(\u0026#39;user-456\u0026#39;), FilterExpression=Attr(\u0026#39;status\u0026#39;).eq(\u0026#39;completed\u0026#39;) ) Biến Môi Trường Lambda Cấu hình Lambda functions để sử dụng các bảng này:\nLambda Function Biến Môi Trường Giá Trị Writing Evaluator DYNAMODB_EVALUATIONS bandup-evaluations Speaking Evaluator DYNAMODB_EVALUATIONS bandup-evaluations Flashcard Generator DYNAMODB_FLASHCARD_SETS bandup-flashcard-sets IAM Policy cho Lambda Access { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;DynamoDBAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:PutItem\u0026#34;, \u0026#34;dynamodb:GetItem\u0026#34;, \u0026#34;dynamodb:UpdateItem\u0026#34;, \u0026#34;dynamodb:Query\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:dynamodb:${AWS_REGION}:${AWS_ACCOUNT_ID}:table/bandup-evaluations\u0026#34;, \u0026#34;arn:aws:dynamodb:${AWS_REGION}:${AWS_ACCOUNT_ID}:table/bandup-flashcard-sets\u0026#34; ] } ] } Bước Tiếp Theo Tiến hành đến Bedrock Integration để cấu hình Amazon Titan Embeddings.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5 Xác định và giải quyết chi phí AWS bất thường trên tài khoản. Thiết kế và phân chia kiến trúc hạ tầng cho dự án. Bắt đầu cấu hình dự án ban đầu và phân bổ vai trò team. Khám phá AWS Skill Builder và nâng cao học tập về các chủ đề tối ưu hóa. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Phân tích và xác định nguyên nhân chi phí bất thường trên tài khoản AWS.\n- Hoàn thành: Cost and Usage Management và Managing Quotas with Service Quotas. 07/10/2025 08/10/2025 AWS Cost Explorer 3 - Thiết kế và phân chia kiến trúc hạ tầng dự án.\n- Đề xuất các template kiến trúc cơ bản cho team tham khảo.\n- Hoàn thành: Building Highly Available Web Applications. 09/10/2025 10/10/2025 FCJ Community 4 - Xây dựng code skeleton và cấu hình các file dự án ban đầu.\n- Thiết lập môi trường phát triển.\n- Hoàn thành: Development Environment with AWS Toolkit for VS Code. 11/10/2025 13/10/2025 VS Code + AWS Toolkit 5 - Đăng ký AWS Skill Builder và khám phá các khóa học.\n- Nghiên cứu kỹ thuật tối ưu EC2.\n- Hoàn thành: Right-Sizing with EC2 Resource Optimization. 11/10/2025 12/10/2025 AWS Skill Builder Khóa học AWS Skill Builder đã hoàn thành Khóa học Danh mục Trạng thái Cost and Usage Management Tối ưu chi phí ✅ Managing Quotas with Service Quotas Operations ✅ Billing Console Delegation Quản lý chi phí ✅ Right-Sizing with EC2 Resource Optimization Tối ưu chi phí ✅ Development Environment with AWS Toolkit for VS Code Phát triển ✅ Building Highly Available Web Applications Kiến trúc ✅ Database Essentials with Amazon RDS Database ✅ NoSQL Database Essentials with Amazon DynamoDB Database ✅ In-Memory Caching with Amazon ElastiCache Database ✅ Command Line Operations with AWS CLI Operations ✅ Kết quả đạt được tuần 5 Kỹ năng kỹ thuật đã tiếp thu:\nTối ưu chi phí:\nXác định nguyên nhân chi phí AWS bất thường: Xóa không hoàn toàn tài nguyên EC2 (EBS volumes, Elastic IPs) Thiếu kiểm soát tài khoản người dùng và IAM permissions Tài nguyên chạy ở các regions không sử dụng Học các best practices quản lý chi phí AWS: AWS Budgets để cảnh báo chi phí chủ động Cost Explorer để phân tích patterns chi tiêu Service Quotas để quản lý giới hạn tài khoản Billing Console Delegation cho visibility chi phí team Đề xuất các biện pháp tối ưu chi phí cho team Thiết kế kiến trúc:\nThiết kế thành công kiến trúc hạ tầng dự án Tạo các template kiến trúc tham khảo cho team áp dụng Áp dụng nguyên tắc High Availability: Triển khai Multi-AZ Chiến lược load balancing Patterns replication database Design patterns fault-tolerant Môi trường phát triển:\nThiết lập AWS Toolkit cho VS Code để phát triển streamlined Thành thạo AWS CLI cho command-line operations Xây dựng code skeleton vững chắc với các file cấu hình ban đầu Thiết lập nền tảng dự án cho hợp tác team Dịch vụ Database:\nHiểu Amazon RDS cho nhu cầu relational database Học DynamoDB cho NoSQL workloads Khám phá ElastiCache cho in-memory caching (Redis/Memcached) Áp dụng tiêu chí chọn database dựa trên use cases Tiến độ dự án:\nĐăng ký và kích hoạt tài khoản AWS Skill Builder Bắt đầu khám phá các khóa học nâng cao và learning paths Kiến trúc hạ tầng đã hoàn thiện và documented Môi trường phát triển đã cấu hình và sẵn sàng coding Bài học chính:\nTối ưu chi phí bắt đầu từ visibility - sử dụng Cost Explorer hàng ngày Right-sizing EC2 instances có thể giảm chi phí 30-50% High availability yêu cầu planning across multiple AZs AWS Toolkit cho VS Code cải thiện đáng kể developer productivity Chọn database phụ thuộc vào data model, scale, và access patterns Service Quotas ngăn ngừa các giới hạn capacity không mong muốn "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.5-setup-be/","title":"Triển khai Backend (ECS Fargate)","tags":[],"description":"","content":"Tổng quan Trong phần này, chúng ta sẽ triển khai IELTS BandUp Backend, một ứng dụng Spring Boot đóng vai trò là lớp xử lý logic cốt lõi của nền tảng.\nKhác với Frontend, Backend yêu cầu các cơ chế lưu trữ và bộ nhớ đệm (caching) để hoạt động hiệu quả. Do đó, trước khi khởi chạy các container trên ECS Fargate, chúng ta bắt buộc phải thiết lập hạ tầng dữ liệu (PostgreSQL và Redis). Dịch vụ Backend sẽ được đặt trong các Private Subnet, được bảo vệ nghiêm ngặt bởi Security Group và sẽ giao tiếp với các dịch vụ AI thông qua AWS SDK.\nCác bước thực hiện Để triển khai hệ thống backend hoàn chỉnh, chúng ta sẽ tuân theo trình tự sau:\nContainer Registry (ECR): Đóng gói ứng dụng Spring Boot và đẩy Docker image lên kho lưu trữ ECR riêng tư. Cơ sở dữ liệu quan hệ (RDS): Khởi tạo Amazon RDS for PostgreSQL để lưu trữ dữ liệu người dùng, kết quả bài thi và nội dung học tập. Bộ nhớ đệm (ElastiCache): Thiết lập cụm Amazon ElastiCache (Redis) để quản lý phiên đăng nhập (session) và tăng tốc độ truy xuất dữ liệu. ECS Task \u0026amp; Service: Định nghĩa cấu hình task (bao gồm các biến môi trường kết nối Database) và khởi chạy dịch vụ. Nội dung Thiết lập ECR \u0026amp; Đẩy Image Tạo PostgreSQL RDS Tạo ElastiCache (Redis) Tạo Service \u0026amp; Task "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Hệ Thống Tự Học IELTS - Workshop Hạ Tầng AWS Tổng Quan Workshop toàn diện này hướng dẫn bạn xây dựng hạ tầng AWS sẵn sàng cho production cho Hệ Thống Tự Học IELTS. Bạn sẽ học cách triển khai ứng dụng web có tính sẵn sàng cao, khả năng mở rộng và bảo mật sử dụng các dịch vụ AWS hiện đại và các phương pháp tốt nhất.\nKiến trúc triển khai theo mô hình active-passive Multi-AZ trên Amazon ECS, với lớp dịch vụ AI serverless cho việc đánh giá thông minh và tạo nội dung.\nNhững Gì Bạn Sẽ Xây Dựng Sau khi hoàn thành workshop này, bạn sẽ triển khai được:\nThành Phần Dịch Vụ AWS Mục Đích Lớp Mạng VPC, Subnets, NAT Gateway Hạ tầng mạng cô lập, bảo mật Nền Tảng Container ECS Fargate, ECR Điều phối container serverless Cân Bằng Tải ALB, Route 53, ACM Phân phối lưu lượng và SSL termination Lớp Dữ Liệu RDS PostgreSQL, ElastiCache, S3 CSDL quan hệ, caching, lưu trữ object Dịch Vụ AI API Gateway, SQS, Lambda, DynamoDB Pipeline xử lý AI serverless CI/CD CodePipeline, CodeBuild Pipeline triển khai tự động Bảo Mật IAM, Secrets Manager, WAF Quản lý danh tính và bảo vệ Giám Sát CloudWatch Logs, Alarms Quan sát và cảnh báo Điểm Nổi Bật Kiến Trúc Thiết Kế Tính Sẵn Sàng Cao:\nTriển khai Multi-AZ trên hai Availability Zones Failover active-passive cho ECS services RDS Multi-AZ với failover tự động Application Load Balancer với health checks Kiến Trúc AI Serverless:\nAPI Gateway cho các RESTful AI endpoints SQS cho xử lý message bất đồng bộ Lambda functions cho Writing Assessment, Speaking Assessment, và RAG-based Flashcard Generation DynamoDB để lưu trữ kết quả AI Tích hợp Amazon Bedrock cho các AI models (Gemma 3 12B, Titan Embeddings) Google Gemini API cho smart query generation Phương Pháp Bảo Mật Tốt Nhất:\nPrivate subnets cho application và database tiers Security groups với least-privilege access AWS WAF cho application-level protection Secrets Manager cho quản lý credentials IAM roles với quyền tối thiểu cần thiết Điều Kiện Tiên Quyết Trước khi bắt đầu workshop này, hãy đảm bảo bạn có:\nTài khoản AWS với quyền phù hợp AWS CLI đã cài đặt và cấu hình Hiểu biết cơ bản về các dịch vụ AWS (VPC, EC2, ECS) Docker đã cài đặt locally cho container builds Git cho version control Thời Gian Hoàn Thành Phần Thời Gian Ước Tính Điều kiện tiên quyết 15 phút VPC \u0026amp; Network Setup 30 phút ECS \u0026amp; Container Setup 45 phút Load Balancer Configuration 30 phút Database \u0026amp; Storage Setup 45 phút AI Service Architecture 60 phút CI/CD Pipeline 30 phút Security \u0026amp; IAM 30 phút Monitoring Setup 20 phút Tổng ~5 giờ Nội Dung Tổng Quan Workshop Điều Kiện Tiên Quyết VPC \u0026amp; Network Setup ECS \u0026amp; Container Setup Load Balancer Configuration Database \u0026amp; Storage Setup AI Service Architecture CI/CD Pipeline Security \u0026amp; IAM Monitoring \u0026amp; Logging Clean Up "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.6-ai-service/5.6.5-bedrock-integration/","title":"Bedrock Integration","tags":[],"description":"","content":"Tổng Quan Cấu hình Amazon Bedrock cho AI model access bao gồm Gemma 3 12B và Titan Embeddings.\nEnable Model Access Điều hướng đến Amazon Bedrock → Model access Request access đến: Amazon Titan Text Express (cho assessments) Amazon Titan Embeddings V2 (cho RAG) Meta Llama 3 hoặc Anthropic Claude (optional) Test Bedrock API import boto3 import json bedrock = boto3.client(\u0026#39;bedrock-runtime\u0026#39;, region_name=\u0026#39;ap-southeast-1\u0026#39;) # Test Titan Text response = bedrock.invoke_model( modelId=\u0026#39;amazon.titan-text-express-v1\u0026#39;, body=json.dumps({ \u0026#39;inputText\u0026#39;: \u0026#39;Hello, how are you?\u0026#39;, \u0026#39;textGenerationConfig\u0026#39;: { \u0026#39;maxTokenCount\u0026#39;: 100, \u0026#39;temperature\u0026#39;: 0.7 } }) ) print(json.loads(response[\u0026#39;body\u0026#39;].read())) Titan Embeddings cho RAG # Generate embeddings response = bedrock.invoke_model( modelId=\u0026#39;amazon.titan-embed-text-v2:0\u0026#39;, body=json.dumps({ \u0026#39;inputText\u0026#39;: \u0026#39;Document chunk text here\u0026#39; }) ) embedding = json.loads(response[\u0026#39;body\u0026#39;].read())[\u0026#39;embedding\u0026#39;] # Lưu trong OpenSearch hoặc dùng cho similarity search Google Gemini Integration Cho smart query generation:\nimport google.generativeai as genai genai.configure(api_key=os.environ[\u0026#39;GEMINI_API_KEY\u0026#39;]) model = genai.GenerativeModel(\u0026#39;gemini-2.5-flash\u0026#39;) response = model.generate_content( f\u0026#34;\u0026#34;\u0026#34;Analyze this document and generate 10 intelligent questions: {document_text} \u0026#34;\u0026#34;\u0026#34; ) Tối Ưu Chi Phí Sử dụng Titan Text Express cho assessments (lower cost) Batch embeddings generation khi có thể Implement caching cho repeated queries Sử dụng Google Gemini free tier cho query generation Bước Tiếp Theo Tiến hành đến CI/CD Pipeline.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6 Nắm vững các dịch vụ lưu trữ AWS cơ bản và use cases của chúng. Nâng cao kỹ năng lập trình Python thông qua các bài tập thực hành. Thiết kế và hoàn thiện kiến trúc hạ tầng dự án. Tham gia webinar \u0026ldquo;Reinventing DevSecOps with AWS Generative AI\u0026rdquo; để khám phá thực hành DevSecOps và Amazon Q Developer. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Nghiên cứu Amazon S3 cơ bản: Kiến trúc Bucket, đảm bảo độ bền, và khả năng host static website.\n- Khám phá S3 Storage Classes (Standard, Standard-IA) và Amazon Glacier cho giải pháp cold storage.\n- Hoàn thành: Static Website Hosting with Amazon S3. 14/10/2025 15/10/2025 AWS S3 Documentation 3 - Học các loại AWS Storage Gateway (File, Volume, Tape Gateway) và patterns tích hợp.\n- Hiểu Object Lifecycle Management policies để tối ưu chi phí.\n- Thực hành Python cơ bản: data structures, functions, và error handling.\n- Tham gia webinar: \u0026ldquo;Reinventing DevSecOps with AWS Generative AI\u0026rdquo; với sự góp mặt của anh Hoàng Kha. 16/10/2025 17/10/2025 AWS Storage Gateway\nAWS Events 4 - Nghiên cứu khái niệm disaster recovery: RTO, RPO, và các chiến lược Backup \u0026amp; Restore.\n- Khám phá dịch vụ AWS Backup cho quản lý backup tập trung.\n- Thực hành: Tạo S3 buckets, upload files, cấu hình static website hosting, và test lifecycle policies.\n- Nghiên cứu phương pháp DevSecOps: CI/CD pipelines, SAST/DAST tools, Infrastructure as Code. 18/10/2025 19/10/2025 AWS Backup 5 - Hoàn thiện sơ đồ kiến trúc hạ tầng dự án với các mối quan hệ component chi tiết.\n- Tái cấu trúc code skeleton để phù hợp với thiết kế kiến trúc đã cập nhật.\n- Chuẩn hóa lựa chọn ngôn ngữ lập trình và framework cho tính nhất quán của team.\n- Khám phá khả năng Amazon Q Developer: AI-powered code generation, testing, và vulnerability scanning. 20/10/2025 21/10/2025 Amazon Q Developer Khóa học AWS Skill Builder đã hoàn thành Khóa học Danh mục Trạng thái Static Website Hosting with Amazon S3 Lưu trữ ✅ Data Protection with AWS Backup Reliability ✅ Content Delivery with Amazon CloudFront Mạng ✅ Kết quả đạt được tuần 6 Thành thạo Dịch vụ Lưu trữ:\nHiểu toàn diện về kiến trúc Amazon S3: Buckets, độ bền (99.999999999%), và static website hosting Nắm vững S3 Storage Classes: Standard, Standard-IA, Glacier cho các access patterns khác nhau Học patterns tích hợp AWS Storage Gateway cho hybrid cloud storage Hiểu Object Lifecycle Management cho automated data tiering và tối ưu chi phí Disaster Recovery \u0026amp; Backup:\nNắm bắt fundamentals disaster recovery: RTO (Recovery Time Objective) và RPO (Recovery Point Objective) Học dịch vụ AWS Backup cho quản lý backup tập trung across services Hiểu các chiến lược Backup \u0026amp; Restore cho business continuity Kỹ năng Phát triển:\nNâng cao lập trình Python thông qua các bài tập thực hành Tạo thành công S3 buckets, cấu hình static websites, và test lifecycle policies Cải thiện hiểu biết về data structures và error handling Lập kế hoạch Dự án:\nHoàn thiện sơ đồ kiến trúc hạ tầng toàn diện Tái cấu trúc code skeleton với cấu trúc thư mục phù hợp Chuẩn hóa technology stack cho hợp tác team Insights DevSecOps:\nTham gia webinar \u0026ldquo;Reinventing DevSecOps with AWS Generative AI\u0026rdquo; (16/10/2025) Học tích hợp DevSecOps: Security trong SDLC sử dụng Jenkins (CI/CD), SonarQube (SAST), OWASP ZAP (DAST), Terraform (IaC) Khám phá Amazon Q Developer: AI assistant cho code generation, testing, vulnerability scanning, và AWS optimization Bài học chính:\nS3 là nền tảng cho object storage trên AWS - hiểu storage classes là cực kỳ quan trọng cho tối ưu chi phí Lifecycle policies tự động hóa quản lý dữ liệu và giảm chi phí lưu trữ đáng kể AWS Backup cung cấp quản lý backup thống nhất across multiple AWS services DevSecOps tích hợp security xuyên suốt development lifecycle, không phải là afterthought "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong thời gian thực tập tại Amazon Web Services từ 08/09/2025 đến 28/11/2025, tôi tham gia phát triển \u0026ldquo;Hệ thống Tự học IELTS\u0026rdquo; — một nền tảng web full-stack hỗ trợ người học tự ôn luyện IELTS.\nCông việc của tôi bao gồm thiết kế kiến trúc trên AWS (ECS Fargate active–passive Multi-AZ, RDS PostgreSQL, S3, CloudFront), xây dựng backend API với Spring Boot 3 (Java 17, JWT/OAuth2, WebSocket) và frontend Next.js 14 TypeScript. Tôi cũng tích hợp AI hỗ trợ chấm Speaking/Writing bằng Google Gemini Flash (free tier) và thiết lập CI/CD với AWS CodeBuild/CodePipeline.\nDự án giúp tôi nâng cao kỹ năng lập trình full-stack, thiết kế/tối ưu cơ sở dữ liệu, triển khai hạ tầng cloud, thực hành DevOps và giao tiếp/kỹ năng viết tài liệu kỹ thuật. Tôi tuân thủ quy trình nhóm và chủ động phối hợp để tháo gỡ vướng mắc, cải thiện chất lượng bàn giao.\nĐể phản ánh khách quan quá trình thực tập, tôi tự đánh giá theo các tiêu chí sau:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao quản lý thời gian và đảm bảo hoàn thành mốc/kế hoạch nội bộ đúng hạn. Củng cố tư duy giải quyết vấn đề theo hướng hệ thống (phân rã yêu cầu, kiểm thử giả thuyết, tối ưu hiệu năng Spring Boot/SQL). Cải thiện độ rõ ràng khi giao tiếp tiếng Anh/Việt trong tài liệu kỹ thuật, bàn giao công việc và cập nhật cho các bên liên quan. "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.6-ai-service/","title":"AI Service Architecture","tags":[],"description":"","content":"Tổng Quan Phần này bao gồm kiến trúc serverless AI service sử dụng API Gateway, SQS, Lambda, DynamoDB, và Amazon Bedrock cho intelligent assessment và content generation.\nKiến Trúc AI Service AI service triển khai theo mô hình fully serverless:\nUser → API Gateway → SQS Queue → Lambda → AI Model → DynamoDB → Response Ba Lambda Functions:\nFunction Mục Đích AI Model Writing Evaluate IELTS writing assessment Gemma 3 12B / Gemini Speaking Evaluate Audio transcription + assessment Transcribe + Gemma 3 12B Flashcard Generate RAG-based flashcard creation Titan Embeddings + Gemini Nội Dung API Gateway SQS Queues Lambda Functions DynamoDB Bedrock Integration Request Flow User submits request (writing sample, audio, document) API Gateway validates và enqueues message đến SQS SQS triggers appropriate Lambda function Lambda processes với AI model (Bedrock/Gemini) Results stored trong DynamoDB User retrieves results qua API Thời Gian Ước Tính: ~60 phút Ước Tính Chi Phí Tóm Tắt Chi Phí Hàng Tháng:\nChi Phí Ban Đầu Chi Phí Hàng Tháng Tổng Chi Phí 12 Tháng Tiền Tệ $0.00 $23.61 $283.32 USD Lưu ý: Bao gồm chi phí ban đầu\nChi Tiết Phân Tích Chi Phí:\nDịch Vụ Mô Tả Khu Vực Chi Phí Hàng Tháng (USD) Chi Phí Hàng Năm (USD) AWS Lambda Writing Evaluator Asia Pacific (Singapore) $0.00 $0.00 AWS Lambda Speaking Evaluator Asia Pacific (Singapore) $0.00 $0.00 AWS Lambda Evaluation Status Asia Pacific (Singapore) $0.00 $0.00 AWS Lambda S3 Upload Asia Pacific (Singapore) $0.00 $0.00 Amazon API Gateway HTTP API Asia Pacific (Singapore) $0.42 $5.04 S3 Standard Audio bucket Asia Pacific (Singapore) $0.51 $6.12 S3 Standard Documents Bucket Asia Pacific (Singapore) $0.53 $6.36 DynamoDB Evaluations Table Asia Pacific (Singapore) $0.37 $4.44 DynamoDB Flashcard Sets Table Asia Pacific (Singapore) $0.52 $6.24 Amazon SQS Writing/Speaking/Flashcard queues Asia Pacific (Singapore) $0.00 $0.00 AWS Secrets Manager Secrets management Asia Pacific (Singapore) $0.45 $5.40 Amazon CloudWatch RAG Lambda logs Asia Pacific (Singapore) $0.01 $0.08 Amazon Bedrock Bedrock inference US East (N. Virginia) $0.50 $6.00 OpenAI GPT inference US East (N. Virginia) $20.30 $243.65 Tổng Cộng $23.61 $283.32 AWS Pricing Calculator chỉ cung cấp ước tính về phí AWS của bạn và không bao gồm bất kỳ loại thuế nào có thể áp dụng. Phí thực tế của bạn phụ thuộc vào nhiều yếu tố, bao gồm việc sử dụng thực tế các dịch vụ AWS của bạn.\nXem chi tiết phân tích chi phí: AWS Pricing Calculator\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7 Tập trung ôn tập toàn diện và củng cố kiến thức chuẩn bị cho kỳ thi giữa kỳ. Luyện tập các bài lab và câu hỏi trắc nghiệm trên các nền tảng AWS Builders và AWSboy để làm quen với format đề thi. Hệ thống hóa các dịch vụ AWS cơ bản đã học: EC2, S3, VPC, IAM, RDS, Lambda, DynamoDB. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Hệ thống hóa kiến thức dịch vụ Compute (EC2, Lambda). - Thực hành: Hoàn thành bài tập/lab về tạo, cấu hình, quản lý vòng đời của EC2 Instances. - Ôn tập tạo Lambda function, triggers, và execution models. 22/10/2024 22/10/2024 AWS Builders, AWSboy 3 - Ôn tập kiến thức dịch vụ Storage (S3, EBS, EFS). - Thực hành: Hoàn thành bài tập về S3 storage classes (Standard, IA, Glacier), EBS volume types, và EFS use cases. - Thực hành S3 bucket policies và access control. 23/10/2024 23/10/2024 AWS Builders, AWSboy 4 - Củng cố kiến thức về Networking (VPC, Subnets, Route Tables, Internet Gateway, Security Groups, NACLs). - Thực hành: Luyện tập câu hỏi về cấu hình VPC, Security Group rules vs NACL rules, và routing principles. - Ôn tập VPC Peering và Transit Gateway concepts. 24/10/2024 24/10/2024 AWS Builders, AWSboy 5 - Ôn tập Database services (RDS, DynamoDB) và Security/Identity (IAM). - Thực hành: Tập trung vào các khái niệm IAM Policies, IAM Roles, và IAM Users cơ bản. - Thực hành thiết kế DynamoDB table và cấu hình RDS instance. 25/10/2024 25/10/2024 AWS Builders, AWSboy 6 - Tổng kết và Luyện đề: Làm các bài thi thử toàn diện trên nền tảng AWS Builders và AWSboy. - Rà soát các lĩnh vực yếu được xác định trong bài thi thử để nghiên cứu thêm. - Tạo ghi chú tóm tắt để tham khảo nhanh trước kỳ thi. 26/10/2024 26/10/2024 AWS Builders, AWSboy Kết quả đạt được tuần 7 Hoàn thành ôn tập toàn diện các nhóm dịch vụ AWS cơ bản: Compute, Storage, Networking, Database, Security (IAM). Luyện tập thành công nhiều labs và câu hỏi trắc nghiệm trên các nền tảng AWS Builders và AWSboy. Nắm vững các thông số cơ bản của EC2 (Instance Types, AMI, EBS volumes) và hoạt động của S3 (Storage Classes, Object/Bucket management). Hiểu rõ mối quan hệ và cấu hình của các thành phần trong VPC (Public/Private Subnets, Routing, Security Groups vs NACLs). Tự tin hơn với kiến thức đã học, sẵn sàng cho kỳ thi giữa kỳ sắp tới. Tạo ghi chú học tập toàn diện bao gồm tất cả các danh mục dịch vụ AWS chính. Xác định và giải quyết các khoảng trống kiến thức thông qua các phiên thực hành có mục tiêu. Bài học chính:\nSecurity Groups là stateful (return traffic tự động được phép), NACLs là stateless (cần rules hai chiều) EC2 instance types được tối ưu cho các workloads khác nhau (compute, memory, storage, GPU) S3 storage classes cân bằng chi phí vs. tần suất truy cập IAM policies tuân theo nguyên tắc explicit deny - policy hạn chế nhất thắng VPC routing tuân theo nguyên tắc most specific route match "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.7-cicd-pipeline/","title":"CI/CD với CodeBuild &amp; CodePipeline","tags":[],"description":"","content":"Quy trình CI/CD với AWS CodeBuild \u0026amp; CodePipeline Tài liệu này hướng dẫn triển khai quy trình CI/CD dùng AWS CodePipeline và CodeBuild với GitLab làm SCM. Khi tạo một Release mới trong repository GitLab, CodePipeline sẽ được kích hoạt, CodeBuild chạy hai dự án frontend và backend dựa trên frontend-buildspec.yml và backend-buildspec.yml hiện có, sau đó CodePipeline deploy lên ECS.\nBạn sẽ làm gì 5.3.1 – Cấu hình dự án CodeBuild (frontend/backend) và trigger theo Release GitLab 5.3.2 – Thiết kế CodePipeline để deploy ECS và tích hợp artifact sau build Điều kiện tiên quyết Quyền IAM cho CodeBuild, CodePipeline, S3, Secrets Manager (nếu dùng token GitLab) và IAM pass role. Ứng dụng mẫu có buildspec.yml (chúng tôi sẽ cung cấp mẫu tối thiểu trong bước). S3 bucket cho artifact của pipeline (trình hướng dẫn CodePipeline sẽ tạo/chọn giúp bạn). Sơ đồ tổng quan Luồng chính: Tag push từ GitLab -\u0026gt; API Gateway/Lambda -\u0026gt; upload archive lên S3 -\u0026gt; CodePipeline (S3 Source) kích hoạt -\u0026gt; CodeBuild build -\u0026gt; (Tùy chọn) Deploy.\nĐặt sơ đồ tại: static/images/5-Workshop/5.3-S3-vpc/ci-overview.png.\nMẹo: Dùng đường dẫn ảnh tuyệt đối /images/... và lưu screenshot trong static/images/5-Workshop/5.3-S3-vpc/.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8 Hoàn thành kỳ thi giữa kỳ (Ngày 31/10) với kết quả tốt. Bắt đầu triển khai các chức năng CRUD (Create, Read, Update, Delete) nền tảng cho dự án Bandup IELTS. Nghiên cứu và lập kế hoạch tích hợp dịch vụ AWS Serverless (Lambda, API Gateway, DynamoDB) cho kiến trúc dự án. Thiết lập môi trường phát triển và xây dựng cấu trúc dự án. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Ôn tập tổng hợp lần cuối kiến thức chuẩn bị cho kỳ thi giữa kỳ. - Rà soát các câu hỏi khó và các khái niệm thường bị nhầm lẫn (IAM Policies vs Roles, Security Groups vs NACLs, VPC routing). - Thực hành quản lý thời gian cho việc hoàn thành bài thi. 28/10/2024 28/10/2024 Ghi chú cá nhân, AWS Builders 3 - Chuẩn bị tâm lý và thiết lập công cụ cho kỳ thi. - Thực hành: Bắt đầu thiết lập môi trường phát triển cho dự án Bandup IELTS. - Cài đặt và cấu hình Python development tools, AWS CLI, và IDE setup. 29/10/2024 30/10/2024 AWS CLI Documentation 4 - Thi giữa kỳ (Ngày 31/10) - Hoàn thành mục tiêu quan trọng nhất. - Phản ánh sau kỳ thi về hiệu suất và các lĩnh vực cần cải thiện. 31/10/2024 31/10/2024 Địa điểm thi 5 - Bắt đầu triển khai chức năng CRUD cơ bản đầu tiên (Create operation: tạo flashcard sets). - Nghiên cứu và triển khai thử nghiệm AWS Lambda functions cho serverless compute. - Nghiên cứu thiết kế DynamoDB table để lưu trữ dữ liệu flashcard. 01/11/2024 01/11/2024 Tài liệu AWS Lambda \u0026amp; DynamoDB 6 - Lập kế hoạch tích hợp kiến trúc Serverless: + Nghiên cứu API Gateway cho RESTful API endpoints. + Thiết kế luồng dữ liệu: Frontend → API Gateway → Lambda → DynamoDB. + Định nghĩa cấu trúc Lambda function và event handling patterns. - Triển khai chức năng Read cơ bản để truy xuất flashcard sets từ DynamoDB. 02/11/2024 02/11/2024 Tài liệu API Gateway, Serverless patterns Kết quả đạt được tuần 8 Hoàn thành kỳ thi giữa kỳ (Ngày 31/10) thành công. Thiết lập thành công môi trường phát triển cơ bản cho dự án với Python, AWS CLI, và cấu hình IDE. Bắt đầu xây dựng chức năng Create/Read đầu tiên cho dự án Bandup IELTS sử dụng AWS Lambda và DynamoDB. Nghiên cứu và thiết kế serverless architecture pattern: API Gateway cho HTTP endpoints Lambda functions cho business logic DynamoDB cho NoSQL data storage Củng cố kiến thức về các dịch vụ Serverless thiết yếu (Lambda, DynamoDB, API Gateway) quan trọng cho phát triển dự án. Tạo cấu trúc dự án ban đầu với tổ chức thư mục phù hợp. Triển khai Lambda function handler đầu tiên cho Create operation. Bài học chính:\nKiến trúc Serverless loại bỏ overhead quản lý server Lambda functions là event-driven và scale tự động DynamoDB cung cấp độ trễ millisecond đơn cho NoSQL workloads API Gateway hoạt động như entry point cho serverless APIs Cấu trúc dự án phù hợp ngay từ đầu đơn giản hóa phát triển tương lai "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/5-workshop/5.8-cleanup/","title":"Dọn Dẹp Tài Nguyên","tags":[],"description":"","content":"Tổng Quan Phần này hướng dẫn bạn dọn dẹp tất cả tài nguyên AWS đã tạo trong workshop này để tránh các khoản phí phát sinh. Thực hiện theo thứ tự các bước vì một số tài nguyên phụ thuộc vào tài nguyên khác.\nQuan trọng: Việc xóa tài nguyên không thể hoàn tác. Hãy đảm bảo bạn đã sao lưu bất kỳ dữ liệu nào cần thiết trước khi tiếp tục.\nThời Gian Ước Tính: ~30 phút Bước 1: Xóa Tài Nguyên CI/CD Pipeline Đầu tiên, xóa CI/CD pipeline để dừng mọi deployment tự động.\nTruy cập console AWS CodePipeline Chọn pipeline của bạn (ví dụ: ielts-pipeline) Click Delete pipeline → Xác nhận xóa Truy cập console AWS CodeBuild Xóa tất cả build projects liên quan đến workshop Xóa bất kỳ S3 buckets nào được sử dụng cho pipeline artifacts Bước 2: Xóa ECS Services và Cluster Dừng và xóa tất cả ECS services trước khi xóa cluster.\nTruy cập console Amazon ECS Chọn cluster của bạn (ví dụ: ielts-cluster) Vào tab Services Với mỗi service: Chọn service Click Update → Đặt Desired tasks thành 0 → Update Chờ các running tasks dừng lại Click Delete service → Xác nhận Sau khi tất cả services đã xóa, quay lại Clusters Chọn cluster → Delete cluster → Xác nhận Bước 3: Xóa ECR Repositories Xóa container images và repositories.\nTruy cập console Amazon ECR Chọn từng repository: ielts-frontend ielts-backend Click Delete → Nhập tên repository để xác nhận Bước 4: Xóa Tài Nguyên AI Service Xóa các thành phần AI serverless theo thứ tự:\n4.1 Xóa Lambda Functions Truy cập console AWS Lambda Xóa từng function: writing-evaluator speaking-evaluator flashcard-generator evaluation-status s3-upload Chọn function → Actions → Delete → Xác nhận 4.2 Xóa API Gateway Truy cập console Amazon API Gateway Chọn API của bạn (ví dụ: ielts-ai-api) Click Actions → Delete API → Xác nhận 4.3 Xóa SQS Queues Truy cập console Amazon SQS Xóa từng queue: writing-evaluation-queue writing-evaluation-dlq speaking-evaluation-queue speaking-evaluation-dlq flashcard-generation-queue flashcard-generation-dlq Chọn queue → Delete → Xác nhận 4.4 Xóa DynamoDB Tables Truy cập console Amazon DynamoDB Xóa từng table: evaluations flashcard-sets Chọn table → Delete → Xác nhận xóa Bước 5: Xóa Tài Nguyên Load Balancer Truy cập console EC2 → Load Balancers Chọn ALB của bạn (ví dụ: ielts-alb) Click Actions → Delete → Xác nhận Vào Target Groups Xóa tất cả target groups liên quan đến workshop Vào Listeners và xóa bất kỳ listeners còn lại Bước 6: Xóa Tài Nguyên Database 6.1 Xóa RDS Instance Truy cập console Amazon RDS Chọn database instance của bạn Click Actions → Delete Bỏ chọn Create final snapshot (nếu không cần) Chọn I acknowledge\u0026hellip; → Delete Việc xóa RDS có thể mất 5-10 phút để hoàn thành.\n6.2 Xóa ElastiCache (Redis) Truy cập console Amazon ElastiCache Chọn Redis cluster của bạn Click Delete → Xác nhận 6.3 Xóa RDS Subnet Group Trong RDS console, vào Subnet groups Chọn subnet group của bạn → Delete Bước 7: Xóa S3 Buckets Truy cập console Amazon S3 Với mỗi bucket đã tạo trong workshop: ielts-audio-bucket ielts-documents-bucket Bất kỳ pipeline artifact buckets nào Chọn bucket → Empty → Xác nhận Sau khi làm trống, chọn bucket → Delete → Xác nhận S3 buckets phải được làm trống trước khi có thể xóa.\nBước 8: Xóa Secrets Manager Secrets Truy cập console AWS Secrets Manager Chọn từng secret đã tạo cho workshop Click Actions → Delete secret Đặt thời gian khôi phục thành 7 ngày (tối thiểu) hoặc chọn xóa ngay lập tức Xác nhận xóa Bước 9: Xóa Tài Nguyên CloudWatch Truy cập console Amazon CloudWatch Vào Log groups Xóa các log groups: /aws/lambda/writing-evaluator /aws/lambda/speaking-evaluator /aws/lambda/flashcard-generator /ecs/ielts-frontend /ecs/ielts-backend Vào Alarms và xóa bất kỳ alarms đã tạo Bước 10: Xóa VPC và Tài Nguyên Mạng Xóa tài nguyên mạng theo thứ tự cụ thể này:\n10.1 Xóa NAT Gateway Truy cập console VPC → NAT Gateways Chọn NAT Gateway của bạn Click Actions → Delete NAT gateway → Xác nhận Chờ trạng thái chuyển thành Deleted 10.2 Giải Phóng Elastic IPs Vào Elastic IPs Chọn bất kỳ Elastic IPs nào liên kết với NAT Gateway Click Actions → Release Elastic IP addresses → Xác nhận 10.3 Xóa VPC Endpoints Vào Endpoints Chọn tất cả VPC endpoints đã tạo cho workshop Click Actions → Delete VPC endpoints → Xác nhận 10.4 Xóa Security Groups Vào Security Groups Xóa security groups theo thứ tự này (do phụ thuộc): Application security groups trước Database security groups Load balancer security groups Không xóa default security group 10.5 Xóa Subnets Vào Subnets Chọn tất cả subnets trong workshop VPC của bạn Click Actions → Delete subnet → Xác nhận 10.6 Xóa Route Tables Vào Route Tables Xóa custom route tables (không phải main route table) Chọn route table → Actions → Delete route table 10.7 Xóa Internet Gateway Vào Internet Gateways Chọn IGW → Actions → Detach from VPC → Xác nhận Chọn lại IGW → Actions → Delete internet gateway → Xác nhận 10.8 Xóa VPC Vào Your VPCs Chọn workshop VPC của bạn Click Actions → Delete VPC → Xác nhận Bước 11: Xóa Tài Nguyên IAM Truy cập console IAM Vào Roles và xóa: ecsTaskExecutionRole (nếu được tạo cho workshop này) ielts-lambda-execution-role Bất kỳ roles cụ thể nào khác của workshop Vào Policies và xóa custom policies đã tạo cho workshop Cẩn thận không xóa tài nguyên IAM được sử dụng bởi các ứng dụng khác.\nDanh Sách Kiểm Tra Xác Minh Sau khi hoàn thành dọn dẹp, xác minh tất cả tài nguyên đã được xóa:\nTài Nguyên Console Dịch Vụ Trạng Thái CodePipeline CodePipeline ☐ Đã xóa ECS Cluster ECS ☐ Đã xóa ECR Repositories ECR ☐ Đã xóa Lambda Functions Lambda ☐ Đã xóa API Gateway API Gateway ☐ Đã xóa SQS Queues SQS ☐ Đã xóa DynamoDB Tables DynamoDB ☐ Đã xóa Load Balancer EC2 ☐ Đã xóa RDS Instance RDS ☐ Đã xóa ElastiCache ElastiCache ☐ Đã xóa S3 Buckets S3 ☐ Đã xóa Secrets Secrets Manager ☐ Đã xóa CloudWatch Logs CloudWatch ☐ Đã xóa NAT Gateway VPC ☐ Đã xóa VPC VPC ☐ Đã xóa IAM Roles IAM ☐ Đã xóa Xác Minh Chi Phí Để đảm bảo không có khoản phí bất ngờ:\nVào console AWS Billing Kiểm tra Bills cho tháng hiện tại Xem Cost Explorer để xác minh không còn tài nguyên hoạt động Thiết lập Budget alert nếu bạn có kế hoạch tiếp tục sử dụng AWS Chờ 24-48 giờ và kiểm tra lại billing dashboard để xác nhận tất cả tài nguyên đã được dọn dẹp và không có khoản phí nào đang phát sinh.\n"},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9 Hoàn tất quá trình chuyển đổi sang framework phát triển AWS SAM (Serverless Application Model). Tái cấu trúc (Refactor) và triển khai lại các chức năng CRUD theo patterns kiến trúc SAM. Giải quyết các vấn đề liên quan đến môi trường để đạt được trạng thái triển khai thành công lên AWS. Tích hợp Docker cho môi trường build chuẩn hóa và quản lý dependencies. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Nghiên cứu chuyên sâu về AWS SAM: Hiểu cấu trúc template.yaml, SAM CLI commands, và cách các tài nguyên Serverless (Lambda, API Gateway) hoạt động trong mô hình SAM. - Lập kế hoạch chiến lược migration: Chuyển đổi các Lambda functions hiện có sang cấu trúc tương thích SAM. - Nghiên cứu khả năng SAM local testing (sam local invoke, sam local start-api). 04/11/2024 04/11/2024 Tài liệu AWS SAM, AWS Study Group 3 - Tái cấu trúc mã nguồn: Viết lại các chức năng CRUD (Create/Read operations) sử dụng SAM patterns (Lambda handlers và API Gateway events). - Tích hợp Docker: Cài đặt và cấu hình Docker để đảm bảo môi trường Python runtime nhất quán cho quá trình sam build. - Tạo Dockerfile cho Lambda layer dependencies. 05/11/2024 06/11/2024 Tài liệu Docker, SAM CLI 4 - Gỡ lỗi và kiểm thử Local: Thực hiện sam local invoke để test các Lambda functions riêng lẻ. - Gặp sự cố nghiêm trọng trong môi trường Local: Dependency conflicts, Python version mismatches, vấn đề kết nối DynamoDB local. - Cố gắng giải quyết các rào cản local testing thông qua điều chỉnh cấu hình. 06/11/2024 07/11/2024 Báo cáo lỗi SAM CLI, Stack Overflow 5 - Ra quyết định chiến lược: Backend Team quyết định áp dụng chiến lược deploy-then-test trên môi trường AWS thực tế để vượt qua các hạn chế gỡ lỗi Local, chấp nhận rủi ro đã tính toán. - Tập trung khắc phục các lỗi cấu hình trong template.yaml (resource definitions, IAM permissions, environment variables). - Xác thực SAM template syntax và resource dependencies. 07/11/2024 08/11/2024 CloudFormation Template Validator 6 - Triển khai thành công: Thực hiện sam deploy --guided và triển khai thành công dự án lên môi trường AWS. - Xác thực cơ bản: Kiểm tra các API endpoints đã tạo bằng Postman/curl, xác nhận chức năng CRUD đã hoạt động. - Ghi lại quy trình triển khai và cấu hình cho team tham khảo. 08/11/2024 08/11/2024 Log triển khai AWS CloudFormation Kết quả đạt được tuần 9 Hoàn thành chuyển đổi công nghệ sang mô hình phát triển AWS SAM cho toàn bộ dự án. Tái cấu trúc thành công các chức năng CRUD vào cấu trúc Serverless của SAM với tổ chức handler phù hợp. Đã giải quyết vấn đề môi trường bằng cách sử dụng Docker để đảm bảo quá trình sam build sử dụng đúng Python version và dependencies. Đạt được cột mốc quan trọng: Triển khai thành công dự án lên môi trường AWS, vượt qua các trục trặc gỡ lỗi Local. Dự án Bandup IELTS hiện có phiên bản API hoạt động trên môi trường Cloud thực tế (mặc dù vẫn cần kiểm thử sâu hơn). Thiết lập deployment workflow và best practices cho hợp tác team. Tạo template.yaml toàn diện với resource definitions và IAM permissions phù hợp. Bài học chính:\nSAM đơn giản hóa phát triển serverless application với infrastructure as code Docker đảm bảo môi trường build nhất quán across các máy phát triển khác nhau Chiến lược deploy-then-test có thể khả thi khi local testing có vấn đề SAM templates cung cấp single source of truth cho serverless infrastructure IAM permissions phù hợp trong SAM templates là cực kỳ quan trọng cho Lambda function execution "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10 Ổn định môi trường triển khai AWS SAM/Serverless và giải quyết các vấn đề quan trọng. Tập trung gỡ lỗi các vấn đề cốt lõi: Cấu hình CORS, template validation errors, và định dạng API response. Tích hợp Frontend/Backend để cho phép kiểm thử end-to-end trên giao diện người dùng. Hoàn thiện các chức năng Read và Delete cơ bản với error handling phù hợp. Tham gia sự kiện AWS Cloud Mastery Series để nhận hướng dẫn chuyên gia và giải quyết thách thức dự án. Các công việc đã hoàn thành trong tuần Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Gỡ lỗi CORS: Phân tích cấu hình CORS trong API Gateway (CORS headers, preflight OPTIONS requests) và Lambda response headers để cho phép Frontend truy cập. - Khắc phục template validation errors: Rà soát và tối ưu file template.yaml để tránh deployment loop errors và resource dependency issues trong sam deploy. 11/11/2024 11/11/2024 Tài liệu API Gateway/CORS 3 - Củng cố chức năng Read (Truy xuất flashcard sets): Đảm bảo dữ liệu được query từ DynamoDB chính xác và trả về đúng định dạng JSON cho Frontend consumption. - Triển khai error handling cho missing records và invalid queries. - Thêm logging cho mục đích debugging. 12/11/2024 12/11/2024 Tài liệu DynamoDB Query 4 - Tích hợp Frontend: Bắt đầu kết hợp Frontend codebase với dự án và test các API endpoints đã deploy. - Thành công hiển thị danh sách flashcard sets trên giao diện người dùng. - Kiểm thử kết nối API và data rendering trong React/Vue components. 13/11/2024 13/11/2024 Tài liệu Frontend Framework 5 - Triển khai và kiểm thử chức năng Delete (Xóa flashcard sets). - Gặp lỗi: Xác định vấn đề authorization với Cognito User Sub ID khi thực hiện Delete function - Lambda không thể extract/process Sub ID từ Cognito token chính xác. - Bắt đầu troubleshooting authentication flow. 14/11/2024 14/11/2024 Tài liệu AWS Cognito 6 - Tham gia sự kiện AWS Cloud Mastery Series: + Nhận hướng dẫn chuyên gia và giải đáp các câu hỏi về Serverless architecture, Lambda best practices, và authentication patterns. - Phân tích lỗi Update/Delete: Áp dụng hướng dẫn từ Mentor để giải quyết vấn đề authorization và Cognito token parsing problems. - Ghi lại các giải pháp để tham khảo trong tương lai. 15/11/2024 15/11/2024 Mentor, AWS Cloud Mastery Series Kết quả đạt được tuần 10 Khắc phục thành công lỗi CORS và ổn định quá trình triển khai SAM (giảm thiểu template validation errors). Tham gia sự kiện AWS Cloud Mastery Series và thu thập thông tin thiết yếu để giải quyết các blockers lớn của dự án. Hoàn thành tích hợp Frontend và Backend, đạt được giao diện người dùng chức năng đầu tiên cho kiểm thử end-to-end. Đã triển khai thành công chức năng Read (Truy xuất flashcard sets) và Delete (Xóa flashcard sets), hoạt động trên giao diện web. Xác định và có hướng giải quyết cho các điểm nghẽn quan trọng: Lỗi authorization: Lambda không thể lấy/xử lý không đúng Cognito Sub ID từ JWT token, ảnh hưởng đến các thao tác cần quyền Dependency chức năng Update: Yêu cầu authentication flow phù hợp và token validation Dự án đã chuyển sang giai đoạn kiểm thử người dùng cơ bản với các thao tác CRUD hoạt động. Thiết lập debugging workflow và error handling patterns cho team. Bài học chính:\nCORS yêu cầu cấu hình phù hợp trong cả API Gateway và Lambda response headers Cognito JWT tokens phải được decode đúng cách để extract user identity (Sub ID) Tích hợp Frontend-Backend yêu cầu chú ý cẩn thận đến API contracts và data formats Error handling và logging là thiết yếu cho debugging production issues AWS Cloud Mastery Series cung cấp insights thực tế quý giá từ các practitioners giàu kinh nghiệm "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Tham gia sự kiện AWS Cloud Mastery Series #2 để tiếp tục giải đáp các vấn đề kỹ thuật chuyên sâu. Tái cấu trúc và thống nhất cấu trúc Frontend để tăng tính ổn định và dễ bảo trì. Triển khai kiến trúc Multi-Stack để tối ưu hóa tốc độ triển khai và quản lý dự án Serverless. Tích hợp các chức năng CRUD cơ bản với AI Image Processing (sử dụng Rekognition) vào trang web. Khắc phục triệt để các lỗi triển khai (đặc biệt là lỗi CORS) để ổn định hệ thống. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu CN - Tham gia sự kiện AWS Cloud Mastery Series #2 (Ngày 17/11): Tiếp tục nhận hướng dẫn và giải đáp thắc mắc chuyên sâu hơn về lỗi xác thực và luồng AI. 17/11/2024 17/11/2024 Mentor, AWS Cloud Mastery Series 2 - Thống nhất và tái cấu trúc Frontend: Tiến hành họp nhóm để thống nhất lại cấu trúc code Frontend nhằm đảm bảo tính đồng bộ và dễ bảo trì. - Nghiên cứu giải pháp Multi-Stack: Bắt đầu phân tích cách tách file template.yaml thành các Stack nhỏ hơn (Multi-Stack) để tối ưu hóa quá trình sam deploy. 18/11/2024 18/11/2024 Tài liệu Kiến trúc Serverless 3 - Triển khai kiến trúc Multi-Stack: Bắt đầu tách và cấu hình các Stack riêng biệt (như Stack cho Backend API, Stack cho Frontend Hosting). - Tiến hành tích hợp AI Image Processing: Kết hợp các chức năng CRUD cơ bản với logic xử lý ảnh (ví dụ: gọi API Rekognition/S3 trigger) để chuẩn bị cho chức năng Update. 19/11/2024 19/11/2024 Codebase Backend, AWS Rekognition 4 - Gặp lỗi sau khi tích hợp AI: Hệ thống tiếp tục gặp lỗi sau khi kết hợp chức năng AI, yêu cầu phải xóa Stack cũ và Deploy lại hoàn toàn. - Leader phát triển Stack dự phòng: Leader tạo một Stack Multi-Stack riêng biệt, đã tối ưu hóa, để dự phòng và làm tham chiếu cho việc triển khai tối ưu hóa sau này. 20/11/2024 20/11/2024 Stack dự phòng của Leader 5 - Lỗi CORS tái diễn: Sau khi deploy lại, hệ thống tiếp tục gặp lỗi CORS. - Gỡ lỗi CORS chuyên sâu: Dành thời gian phân tích triệt để nguyên nhân gốc rễ và sửa chữa dứt điểm lỗi CORS, đảm bảo các headers phản hồi được cấu hình chính xác trên cả API Gateway và Lambda. 21/11/2024 21/11/2024 Cấu hình API Gateway/Lambda 6 - Họp bàn và ổn định hóa dự án: Họp nhóm để kiểm tra cấu trúc Frontend mới, ổn định lại Stack dự án chính và đồng bộ hóa các bản sửa lỗi CORS và Template. - Tối ưu hóa bảo trì: Đưa ra giải pháp sử dụng Stack riêng (do leader phát triển) để đảm bảo tính linh hoạt và dễ tối ưu hóa trong quá trình phát triển tiếp theo. 22/11/2024 22/11/2024 Báo cáo cấu trúc mới Kết quả đạt được tuần 11: Tham gia chuỗi sự kiện AWS Cloud Mastery Series #2, thu thập thêm kiến thức sâu hơn về Serverless, Rekognition, và giải pháp cho các lỗi xác thực. Tái cấu trúc thành công Frontend và thống nhất được cấu trúc chung cho dự án, cải thiện khả năng bảo trì. Triển khai kiến trúc Multi-Stack (hoặc ít nhất là có giải pháp/Stack dự phòng) giúp đẩy nhanh quá trình deploy và dễ dàng quản lý tài nguyên. Khắc phục được triệt để lỗi CORS sau khi tìm ra nguyên nhân gốc rễ, đảm bảo đường truyền giữa Frontend và Backend ổn định. Lĩnh hội được cách khắc phục các lỗi Template cơ bản và hiểu rõ hơn về các vấn đề triển khai trên AWS SAM. Phát triển thêm Stack riêng biệt để dự phòng/tối ưu hóa, tăng tính linh hoạt và an toàn cho dự án trong các lần cập nhật lớn sau này. Dự án đã bước vào giai đoạn thử nghiệm chức năng AI, mặc dù vẫn còn lỗi, nhưng đã có hướng đi rõ ràng để gỡ rối. "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Hoàn thiện 100% các chức năng CRUD cơ bản và AI xử lý ảnh (bao gồm chức năng Update). Nâng cấp kiến trúc xử lý ảnh bằng cách tích hợp SQS để phân luồng và xử lý bất đồng bộ. Hoàn thành các tính năng thiết yếu cuối cùng của dự án: Bảo mật, Ghim Map, và SNS. Hoàn thiện các giao diện chính của Frontend, chuẩn bị mua tên miền và tham gia sự kiện AWS Cloud Mastery Series cuối cùng. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Hoàn thiện chức năng Update và AI: Khắc phục triệt để các lỗi cuối cùng (Sub ID, Rekognition) để chức năng CRUD và xử lý ảnh hoạt động trọn vẹn. 25/11/2024 25/11/2024 Hướng dẫn Mentor, Codebase Backend 3 - Nâng cấp luồng AI với SQS: Triển khai AWS SQS để tạo hàng đợi xử lý ảnh bất đồng bộ, giúp phân luồng và cải thiện hiệu suất khi lượng ảnh tải lên lớn. - Tạo luồng xử lý rõ ràng: Định nghĩa lại luồng đi của dữ liệu (Upload -\u0026gt; S3 -\u0026gt; SQS -\u0026gt; Lambda (AI) -\u0026gt; DynamoDB). 26/11/2024 26/11/2024 Tài liệu AWS SQS, Kiến trúc Lambda 4 - Frontend hoàn thiện giao diện: Hoàn tất các giao diện cho các trang chính (Homepage, Chi tiết bài viết, Trang quản lý cá nhân). - Triển khai Ghim Map: Tích hợp chức năng Ghim Map (Map Pinning) cho các bài viết, sử dụng dữ liệu định vị (geo data) trong DynamoDB hoặc một dịch vụ map phù hợp. 27/11/2024 27/11/2024 Codebase Frontend, DynamoDB Geo 5 - Hoàn thiện Bảo mật (Authorization): Tối ưu hóa việc xác thực và phân quyền (IAM Policy/Cognito), đặc biệt là việc lấy Sub chính xác cho các thao tác của người dùng. - Triển khai SNS: Tích hợp AWS SNS cho các tính năng thông báo cơ bản (ví dụ: thông báo khi bài viết được xử lý xong/tải lên thành công). 28/11/2024 28/11/2024 Tài liệu AWS SNS, Cognito/IAM 6 - Tham gia sự kiện AWS Cloud Mastery Series cuối cùng: Nhận hướng dẫn tổng thể về dự án, kiểm tra và hoàn thiện các phần còn thiếu (tên miền, bảo mật, SNS) trước khi demo. - Tên miền: Tiến hành nghiên cứu và chuẩn bị mua tên miền cho trang web, cấu hình DNS cơ bản (Route 53) nếu cần thiết (dựa trên hướng dẫn mentor). 29/11/2024 29/11/2024 Mentor, AWS Cloud Mastery Series, Route 53 Kết quả đạt được tuần 12: Hoàn thành 100% các chức năng CRUD cơ bản và AI xử lý ảnh, đảm bảo tính ổn định của hệ thống. Nâng cấp kiến trúc xử lý ảnh bằng cách tích hợp SQS và xác định các luồng xử lý bất đồng bộ rõ ràng, cải thiện hiệu suất và độ tin cậy. Hoàn thiện các tính năng thiết yếu: Đã triển khai Bảo mật, Ghim Map và thông báo bằng SNS. Giao diện Frontend cơ bản đã hoàn thiện, sẵn sàng cho việc trình bày. Tham gia thành công sự kiện AWS Cloud Mastery Series cuối cùng, nhận được hướng dẫn tổng thể để hoàn thiện dự án. Đã nghiên cứu và lên kế hoạch mua tên miền cho sản phẩm. Dự án đã đạt đến trạng thái Sẵn sàng trình bày (Demo Readiness). "},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://hoangworthy.github.io/AWS-Worklog/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]