<!doctype html><html lang=en class="js csstransforms3d"><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.134.3"><meta name=description content><meta name=author content="hoangsusp@gmail.com"><link rel=icon href=../../images/favicon.png type=image/png><title>Blog 1 :: Internship Report</title>
<link href=../../css/nucleus.css?1765297479 rel=stylesheet><link href=../../css/fontawesome-all.min.css?1765297479 rel=stylesheet><link href=../../css/hybrid.css?1765297479 rel=stylesheet><link href=../../css/featherlight.min.css?1765297479 rel=stylesheet><link href=../../css/perfect-scrollbar.min.css?1765297479 rel=stylesheet><link href=../../css/auto-complete.css?1765297479 rel=stylesheet><link href=../../css/atom-one-dark-reasonable.css?1765297479 rel=stylesheet><link href=../../css/theme.css?1765297479 rel=stylesheet><link href=../../css/hugo-theme.css?1765297479 rel=stylesheet><link href=../../css/theme-workshop.css?1765297479 rel=stylesheet><script src=../../js/jquery-3.3.1.min.js?1765297479></script><style>:root #header+#content>#left>#rlblock_left{display:none!important}</style></head><body data-url=../../3-blogstranslated/3.1-blog1/><nav id=sidebar class=showVisitedLinks><div id=header-wrapper><div id=header><a id=logo href=../../><svg id="Layer_1" data-name="Layer 1" viewBox="0 0 60 30" width="30%"><defs><style>.cls-1{fill:#fff}.cls-2{fill:#f90;fill-rule:evenodd}</style></defs><title>AWS-Logo_White-Color</title><path class="cls-1" d="M14.09 10.85a4.7 4.7.0 00.19 1.48 7.73 7.73.0 00.54 1.19.77.77.0 01.12.38.64.64.0 01-.32.49l-1 .7a.83.83.0 01-.44.15.69.69.0 01-.49-.23 3.8 3.8.0 01-.6-.77q-.25-.42-.51-1a6.14 6.14.0 01-4.89 2.3 4.54 4.54.0 01-3.32-1.19 4.27 4.27.0 01-1.22-3.2 4.28 4.28.0 011.46-3.4A6.06 6.06.0 017.69 6.46a12.47 12.47.0 011.76.13q.92.13 1.91.36V5.73a3.65 3.65.0 00-.79-2.66A3.81 3.81.0 007.86 2.3a7.71 7.71.0 00-1.79.22 12.78 12.78.0 00-1.79.57 4.55 4.55.0 01-.58.22h-.26q-.35.0-.35-.52V2a1.09 1.09.0 01.12-.58 1.2 1.2.0 01.47-.35A10.88 10.88.0 015.77.32 10.19 10.19.0 018.36.0a6 6 0 014.35 1.35 5.49 5.49.0 011.38 4.09zM7.34 13.38a5.36 5.36.0 001.72-.31A3.63 3.63.0 0010.63 12 2.62 2.62.0 0011.19 11a5.63 5.63.0 00.16-1.44v-.7a14.35 14.35.0 00-1.53-.28 12.37 12.37.0 00-1.56-.1 3.84 3.84.0 00-2.47.67A2.34 2.34.0 005 11a2.35 2.35.0 00.61 1.76A2.4 2.4.0 007.34 13.38zm13.35 1.8a1 1 0 01-.64-.16 1.3 1.3.0 01-.35-.65L15.81 1.51a3 3 0 01-.15-.67.36.36.0 01.41-.41H17.7a1 1 0 01.65.16 1.4 1.4.0 01.33.65l2.79 11 2.59-11A1.17 1.17.0 0124.39.6a1.1 1.1.0 01.67-.16H26.4a1.1 1.1.0 01.67.16 1.17 1.17.0 01.32.65L30 12.39 32.88 1.25A1.39 1.39.0 0133.22.6a1 1 0 01.65-.16h1.54a.36.36.0 01.41.41 1.36 1.36.0 010 .26 3.64 3.64.0 01-.12.41l-4 12.86a1.3 1.3.0 01-.35.65 1 1 0 01-.64.16H29.25a1 1 0 01-.67-.17 1.26 1.26.0 01-.32-.67L25.67 3.64l-2.56 10.7a1.26 1.26.0 01-.32.67 1 1 0 01-.67.17zm21.36.44a11.28 11.28.0 01-2.56-.29 7.44 7.44.0 01-1.92-.67 1 1 0 01-.61-.93v-.84q0-.52.38-.52a.9.9.0 01.31.06l.42.17a8.77 8.77.0 001.83.58 9.78 9.78.0 002 .2 4.48 4.48.0 002.43-.55 1.76 1.76.0 00.86-1.57 1.61 1.61.0 00-.45-1.16A4.29 4.29.0 0043 9.22l-2.41-.76A5.15 5.15.0 0138 6.78a3.94 3.94.0 01-.83-2.41 3.7 3.7.0 01.45-1.85 4.47 4.47.0 011.19-1.37 5.27 5.27.0 011.7-.86A7.4 7.4.0 0142.6.0a8.87 8.87.0 011.12.07q.57.07 1.08.19t.95.26a4.27 4.27.0 01.7.29 1.59 1.59.0 01.49.41.94.94.0 01.15.55v.79q0 .52-.38.52a1.76 1.76.0 01-.64-.2 7.74 7.74.0 00-3.2-.64 4.37 4.37.0 00-2.21.47 1.6 1.6.0 00-.79 1.48 1.58 1.58.0 00.49 1.18 4.94 4.94.0 001.83.92L44.55 7a5.08 5.08.0 012.57 1.6A3.76 3.76.0 0147.9 11a4.21 4.21.0 01-.44 1.93 4.4 4.4.0 01-1.21 1.47 5.43 5.43.0 01-1.85.93A8.25 8.25.0 0142.05 15.62z"/><path class="cls-2" d="M45.19 23.81C39.72 27.85 31.78 30 25 30A36.64 36.64.0 01.22 20.57c-.51-.46-.06-1.09.56-.74A49.78 49.78.0 0025.53 26.4 49.23 49.23.0 0044.4 22.53C45.32 22.14 46.1 23.14 45.19 23.81z"/><path class="cls-2" d="M47.47 21.21c-.7-.9-4.63-.42-6.39-.21-.53.06-.62-.4-.14-.74 3.13-2.2 8.27-1.57 8.86-.83s-.16 5.89-3.09 8.35c-.45.38-.88.18-.68-.32C46.69 25.8 48.17 22.11 47.47 21.21z"/></svg></a></div><div class=searchbox><label for=search-by><i class="fas fa-search"></i></label>
<input data-search-input id=search-by type=search placeholder=Search...>
<span data-search-clear><i class="fas fa-times"></i></span></div><script type=text/javascript src=../../js/lunr.min.js?1765297479></script><script type=text/javascript src=../../js/auto-complete.js?1765297479></script><script type=text/javascript>var baseurl="https://hoangworthy.github.io/AWS-Worklog/"</script><script type=text/javascript src=../../js/search.js?1765297479></script></div><div class=highlightable><ul class=topics><li data-nav-id=/1-worklog/ title=Worklog class=dd-item><a href=../../1-worklog/><b>1. </b>Worklog
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/1-worklog/1.1-week1/ title="Week 1 Worklog" class=dd-item><a href=../../1-worklog/1.1-week1/><b>1.1. </b>Week 1 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.2-week2/ title="Week 2 Worklog" class=dd-item><a href=../../1-worklog/1.2-week2/><b>1.2. </b>Week 2 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.3-week3/ title="Week 3 Worklog" class=dd-item><a href=../../1-worklog/1.3-week3/><b>1.3. </b>Week 3 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.4-week4/ title="Week 4 Worklog" class=dd-item><a href=../../1-worklog/1.4-week4/><b>1.4. </b>Week 4 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.5-week5/ title="Week 5 Worklog" class=dd-item><a href=../../1-worklog/1.5-week5/><b>1.5. </b>Week 5 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.6-week6/ title="Week 6 Worklog" class=dd-item><a href=../../1-worklog/1.6-week6/><b>1.6. </b>Week 6 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.7-week7/ title="Week 7 Worklog" class=dd-item><a href=../../1-worklog/1.7-week7/><b>1.7. </b>Week 7 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.8-week8/ title="Week 8 Worklog" class=dd-item><a href=../../1-worklog/1.8-week8/><b>1.8. </b>Week 8 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.9-week9/ title="Worklog Week 9" class=dd-item><a href=../../1-worklog/1.9-week9/><b>1.9. </b>Worklog Week 9
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.10-week10/ title="Worklog Week 10" class=dd-item><a href=../../1-worklog/1.10-week10/><b>1.10. </b>Worklog Week 10
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.11-week11/ title="Worklog Week 11" class=dd-item><a href=../../1-worklog/1.11-week11/><b>1.11. </b>Worklog Week 11
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.12-week12/ title="Worklog Week 12" class=dd-item><a href=../../1-worklog/1.12-week12/><b>1.12. </b>Worklog Week 12
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/2-proposal/ title=Proposal class=dd-item><a href=../../2-proposal/><b>2. </b>Proposal
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/ title="Translated Blogs" class="dd-item
parent"><a href=../../3-blogstranslated/><b>3. </b>Translated Blogs
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/3-blogstranslated/3.1-blog1/ title="Blog 1" class="dd-item
active"><a href=../../3-blogstranslated/3.1-blog1/><b>3.1. </b>Blog 1
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/3.2-blog2/ title="Blog 2" class=dd-item><a href=../../3-blogstranslated/3.2-blog2/><b>3.2. </b>Blog 2
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/3.3-blog3/ title="Blog 3" class=dd-item><a href=../../3-blogstranslated/3.3-blog3/><b>3.3. </b>Blog 3
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/4-eventparticipated/ title="Events Participated" class=dd-item><a href=../../4-eventparticipated/><b>4. </b>Events Participated
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/4-eventparticipated/4.2-event2/ title="Event 2" class=dd-item><a href=../../4-eventparticipated/4.2-event2/><b>4.2. </b>Event 2
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.1-event1/ title="Event 1" class=dd-item><a href=../../4-eventparticipated/4.1-event1/><b>4.1. </b>Event 1
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/5-workshop/ title=Workshop class=dd-item><a href=../../5-workshop/><b>5. </b>Workshop
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/5-workshop/5.1-workshop-overview/ title=Introduction class=dd-item><a href=../../5-workshop/5.1-workshop-overview/><b>5.1. </b>Introduction
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.2-prerequiste/ title=Prerequiste class=dd-item><a href=../../5-workshop/5.2-prerequiste/><b>5.2. </b>Prerequiste
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.3-network/ title="Network & Security Infrastructure" class=dd-item><a href=../../5-workshop/5.3-network/><b>5.3. </b>Network & Security Infrastructure
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/5-workshop/5.3-network/5.3.1-vpc/ title="VPC, Subnets & Routing" class=dd-item><a href=../../5-workshop/5.3-network/5.3.1-vpc/><b>5.3.1. </b>VPC, Subnets & Routing
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.3-network/5.3.2-alb/ title="Application Load Balancer (ALB)" class=dd-item><a href=../../5-workshop/5.3-network/5.3.2-alb/><b>5.3.2. </b>Application Load Balancer (ALB)
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.3-network/5.3.3-iam/ title="IAM Roles for ECS" class=dd-item><a href=../../5-workshop/5.3-network/5.3.3-iam/><b>5.3.3. </b>IAM Roles for ECS <i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.3-network/5.3.4-endpoints/ title="VPC Endpoints Setup" class=dd-item><a href=../../5-workshop/5.3-network/5.3.4-endpoints/><b>5.3.4. </b>VPC Endpoints Setup <i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/5-workshop/5.4-setup-fe/ title="Frontend Deployment (ECS Fargate)" class=dd-item><a href=../../5-workshop/5.4-setup-fe/><b>5.4. </b>Frontend Deployment (ECS Fargate)
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/5-workshop/5.4-setup-fe/5.4.1-docker/ title="Setup ECR & Push Image" class=dd-item><a href=../../5-workshop/5.4-setup-fe/5.4.1-docker/><b>5.4.1. </b>Setup ECR & Push Image
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.4-setup-fe/5.4.2-ecr/ title="Setup ECR & IAM Role" class=dd-item><a href=../../5-workshop/5.4-setup-fe/5.4.2-ecr/><b>5.4.2. </b>Setup ECR & IAM Role
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.4-setup-fe/5.4.3-sg/ title="Configure Security Group" class=dd-item><a href=../../5-workshop/5.4-setup-fe/5.4.3-sg/><b>5.4.3. </b>Configure Security Group
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.4-setup-fe/5.4.4-task/ title="Create Task Definition & Service" class=dd-item><a href=../../5-workshop/5.4-setup-fe/5.4.4-task/><b>5.4.4. </b>Create Task Definition & Service <i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/5-workshop/5.5-setup-be/ title="Backend Deployment (ECS Fargate)" class=dd-item><a href=../../5-workshop/5.5-setup-be/><b>5.5. </b>Backend Deployment (ECS Fargate)
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/5-workshop/5.5-setup-be/5.5.1-ecr/ title="Setup ECR & Push Image" class=dd-item><a href=../../5-workshop/5.5-setup-be/5.5.1-ecr/><b>5.5.1. </b>Setup ECR & Push Image <i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.5-setup-be/5.5.2-rds/ title="Create PostgreSQL RDS" class=dd-item><a href=../../5-workshop/5.5-setup-be/5.5.2-rds/><b>5.5.2. </b>Create PostgreSQL RDS <i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.5-setup-be/5.5.3-redis/ title="Create ElastiCache (Redis/Valkey)" class=dd-item><a href=../../5-workshop/5.5-setup-be/5.5.3-redis/><b>5.5.3. </b>Create ElastiCache (Redis/Valkey) <i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.5-setup-be/5.5.4-task/ title="Create Service & Task" class=dd-item><a href=../../5-workshop/5.5-setup-be/5.5.4-task/><b>5.5.4. </b>Create Service & Task <i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/5-workshop/5.6-ai-service/ title="AI Service Architecture" class=dd-item><a href=../../5-workshop/5.6-ai-service/><b>5.6. </b>AI Service Architecture
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/5-workshop/5.6-ai-service/5.6.1-api-gateway/ title="API Gateway" class=dd-item><a href=../../5-workshop/5.6-ai-service/5.6.1-api-gateway/><b>5.6.1. </b>API Gateway
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.6-ai-service/5.6.2-sqs-queues/ title="SQS Queues" class=dd-item><a href=../../5-workshop/5.6-ai-service/5.6.2-sqs-queues/><b>5.6.2. </b>SQS Queues
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.6-ai-service/5.6.3-lambda-functions/ title="Lambda Functions" class=dd-item><a href=../../5-workshop/5.6-ai-service/5.6.3-lambda-functions/><b>5.6.3. </b>Lambda Functions
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.6-ai-service/5.6.4-dynamodb/ title=DynamoDB class=dd-item><a href=../../5-workshop/5.6-ai-service/5.6.4-dynamodb/><b>5.6.4. </b>DynamoDB
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.6-ai-service/5.6.5-bedrock-integration/ title="Bedrock Integration" class=dd-item><a href=../../5-workshop/5.6-ai-service/5.6.5-bedrock-integration/><b>5.6.5. </b>Bedrock Integration
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/5-workshop/5.7-cicd-pipeline/ title="CI/CD with CodeBuild & CodePipeline" class=dd-item><a href=../../5-workshop/5.7-cicd-pipeline/><b>5.7. </b>CI/CD with CodeBuild & CodePipeline
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/5-workshop/5.7-cicd-pipeline/5.7.1-create-gwe/ title="Connect GitLab repo & create CodeBuild project" class=dd-item><a href=../../5-workshop/5.7-cicd-pipeline/5.7.1-create-gwe/><b>5.7.1 </b>Connect GitLab repo & create CodeBuild project
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.7-cicd-pipeline/5.7.2-test-gwe/ title="Create CodePipeline with GitLab tag trigger" class=dd-item><a href=../../5-workshop/5.7-cicd-pipeline/5.7.2-test-gwe/><b>5.7.2 </b>Create CodePipeline with GitLab tag trigger
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/5-workshop/5.8-cleanup/ title="Clean Up Resources" class=dd-item><a href=../../5-workshop/5.8-cleanup/><b>5.8. </b>Clean Up Resources
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/6-self-evaluation/ title=Self-Assessment class=dd-item><a href=../../6-self-evaluation/><b>6. </b>Self-Assessment
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/7-feedback/ title="Sharing and Feedback" class=dd-item><a href=../../7-feedback/><b>7. </b>Sharing and Feedback
<i class="fas fa-check read-icon"></i></a></li></ul><section id=shortcuts><h3>More</h3><ul><li><a class=padding href=https://www.facebook.com/groups/awsstudygroupfcj/><i class='fab fa-facebook'></i> AWS Study Group</a></li></ul></section><section id=prefooter><hr><ul><li><a class=padding><i class="fas fa-language fa-fw"></i><div class=select-style><select id=select-language onchange="location=this.value"><option id=en value=https://hoangworthy.github.io/AWS-Worklog/3-blogstranslated/3.1-blog1/ selected>English</option><option id=vi value=https://hoangworthy.github.io/AWS-Worklog/vi/3-blogstranslated/3.1-blog1/>Tiếng Việt</option></select><svg id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" width="255" height="255" viewBox="0 0 255 255" style="enable-background:new 0 0 255 255"><g><g id="arrow-drop-down"><polygon points="0,63.75 127.5,191.25 255,63.75"/></g></g></svg></div></a></li><li><a class=padding href=# data-clear-history-toggle><i class="fas fa-history fa-fw"></i> Clear History</a></li></ul></section><section id=footer><left><b>Workshop</b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7920860&style=0038&nbdigits=9&type=page&initCount=0" title=Migrate alt="web counter" border=0></a><br><b><a href=https://cloudjourney.awsstudygroup.com/>Cloud Journey</a></b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7830807&style=0038&nbdigits=9&type=page&initCount=0" title="Total CLoud Journey" alt="web counter" border=0>
</left><left><br><br><b>Last Updated</b><br><i><span id=lastUpdated style=color:orange></span>
</i><script>const today=new Date,formattedDate=today.toLocaleDateString("en-GB");document.getElementById("lastUpdated").textContent=formattedDate</script></left><left><br><br><b>Team</b><br><i><a href=https://www.facebook.com/groups/660548818043427 style=color:orange>BugHunters</a><br></i></left><script async defer src=https://buttons.github.io/buttons.js></script></section></div></nav><section id=body><div id=overlay></div><div class="padding highlightable"><div><div id=top-bar><div id=breadcrumbs itemscope itemtype=http://data-vocabulary.org/Breadcrumb><span id=sidebar-toggle-span><a href=# id=sidebar-toggle data-sidebar-toggle><i class="fas fa-bars"></i>
</a></span><span id=toc-menu><i class="fas fa-list-alt"></i></span>
<span class=links><a href=../../>Internship Report</a> > <a href=../../3-blogstranslated/>Translated Blogs</a> > Blog 1</span></div><div class=progress><div class=wrapper><nav id=TableOfContents><ul><li><a href=#benefit-claims-processing>Benefit claims processing</a></li><li><a href=#solution-overview>Solution overview</a><ul><li><a href=#ingestion>Ingestion</a></li><li><a href=#extraction>Extraction</a></li></ul></li><li><a href=#validation>Validation</a><ul><li><a href=#integration>Integration</a></li></ul></li><li><a href=#reducing-manual-effort-through-intelligent-business-rules-management>Reducing manual effort through intelligent business rules management</a></li><li><a href=#prerequisites>Prerequisites</a></li><li><a href=#set-up-code-in-your-local-machine>Set up code in your local machine</a></li><li><a href=#deploy-the-solution-in-your-account>Deploy the solution in your account</a></li><li><a href=#clean-up>Clean up</a></li><li><a href=#conclusion>Conclusion</a></li></ul></nav></div></div></div></div><div id=head-tags></div><div id=body-inner><h1>Blog 1</h1><h1 id=accelerate-benefits-claims-processing-with-amazon-bedrock-data-automation>Accelerate benefits claims processing with Amazon Bedrock Data Automation</h1><p>In the benefits administration industry, claims processing is a vital operational pillar that makes sure employees and beneficiaries receive timely benefits, such as health, dental, or disability payments, while controlling costs and adhering to regulations like HIPAA and ERISA. Businesses aim to optimize the workflow—covering claim submission, validation, adjudication, payment, and appeals—to enhance employee satisfaction, strengthen provider relationships, and mitigate financial risks. The process includes specific steps like claim submission (through portals or paper), data validation (verifying eligibility and accuracy), adjudication (assessing coverage against plan rules), payment or denial (including check processing for reimbursements), and appeal handling. Efficient claims processing supports competitive benefits offerings, which is crucial for talent retention and employer branding, but requires balancing speed, accuracy, and cost in a highly regulated environment.</p><p>Despite its importance, claims processing faces significant challenges in many organizations. Most notably, the reliance on legacy systems and manual processes results in frustratingly slow resolution times, high error rates, and increased administrative costs. Incomplete or inaccurate claim submissions—such as those with missing diagnosis codes or eligibility mismatches—frequently lead to denials and rework, creating frustration for both employees and healthcare providers. Additionally, fraud, waste, and abuse continue to inflate costs, yet detecting these issues without delaying legitimate claims remains challenging. Complex regulatory requirements demand constant system updates, and poor integration between systems—such as Human Resource Information Systems (HRIS) and other downstream systems—severely limits scalability. These issues drive up operational expenses, erode trust in benefits programs, and overburden customer service teams, particularly during appeals processes or peak claims periods.</p><p>Generative AI can help address these challenges. With Amazon Bedrock Data Automation, you can automate generation of useful insights from unstructured multimodal content such as documents, images, audio, and video. Amazon Bedrock Data Automation can be used in benefits claims process to automate document processing by extracting and classifying documents from claims packets, policy applications, and supporting documents with industry-leading accuracy, reducing manual errors and accelerating resolution times. Amazon Bedrock Data Automation natural language processing capabilities interpret unstructured data, such as provider notes, supporting compliance with plan rules and regulations. By automating repetitive tasks and providing insights, Amazon Bedrock Data Automation helps reduce administrative burdens, enhance experiences for both employees and providers, and support compliance in a cost-effective manner. Furthermore, its scalable architecture enables seamless integration with existing systems, improving data flow across HRIS, claims systems, and provider networks, and advanced analytics help detect fraud patterns to optimize cost control.</p><p>In this post, we examine the typical benefit claims processing workflow and identify where generative AI-powered automation can deliver the greatest impact.</p><hr><h2 id=benefit-claims-processing>Benefit claims processing</h2><p>When an employee or beneficiary pays out of pocket for an expense covered under their health benefits, they submit a claim for reimbursement. This process requires several supporting documents, including doctor’s prescriptions and proof of payment, which might include check images, receipts, or electronic payment confirmations.</p><p>The claims processing workflow involves several critical steps:</p><ul><li>Document intake and processing – The system receives and categorizes submitted documentation, including:<ul><li>Medical records and prescriptions</li><li>Proof of payment documentation</li><li>Supporting forms and eligibility verification</li></ul></li><li>Payment verification processing – For check-based reimbursements, the system must complete the following steps:<ul><li>Extract information from check images, including the account number and routing number contained in the MICR line</li><li>Verify payee and payer names against the information provided during the claim submission process</li><li>Confirm payment amounts match the claimed expenses</li><li>Flag discrepancies for human review</li></ul></li><li>Adjudication and reimbursement – When verification is complete, the system performs several actions:<ul><li>Determine eligibility based on plan rules and coverage limits</li><li>Calculate appropriate reimbursement amounts</li><li>Initiate payment processing through direct deposit or check issuance</li><li>Provide notification to the claimant regarding the status of their reimbursement</li></ul></li></ul><p>In this post, we walk through a real-world scenario to make the complexity of this multi-step process clearer. The following example demonstrates how Amazon Bedrock Data Automation can streamline the claims processing workflow, from initial submission to final reimbursement.</p><h2 id=solution-overview>Solution overview</h2><p>Let’s consider a scenario where a benefit plan participant seeks treatment and pays out of pocket for the doctor’s fee using a check. They then buy the medications prescribed by the doctor at the pharmacy store. Later, they log in to their benefit provider’s portal and submit a claim along with the image of the check and payment receipt for the medications.</p><p>This solution uses Amazon Bedrock Data Automation to automate the two most critical and time-consuming aspects of this workflow: document intake and payment verification processing. The following diagram illustrates the benefits claims processing architecture.</p><p><img alt="System Architecture" src=../../images/blog-1-1.png></p><p>The end-to-end process works through four integrated stages: ingestion, extraction, validation, and integration.Quy trình tổng thể hoạt động qua bốn giai đoạn tích hợp: nhập dữ liệu, trích xuất dữ liệu, kiểm tra, và tích hợp.</p><h3 id=ingestion>Ingestion</h3><p>When a beneficiary uploads supporting documents (check image and pharmacy receipt) through the company’s benefit claims portal, these documents are securely saved in an Amazon Simple Storage Service (Amazon S3) bucket, triggering the automated claims processing pipeline.</p><h3 id=extraction>Extraction</h3><p>After documents are ingested, the system immediately begins with intelligent data extraction:</p><p>The S3 object upload triggers an AWS Lambda function, which invokes the Amazon Bedrock Data Automation project.
Amazon Bedrock Data Automation uses blueprints for file processing and extraction. Blueprints are artifacts used to configure file processing business logic by specifying a list of field names for data extraction, along with their desired data formats (string, number, or Boolean) and natural language context for data normalization and validation rules. Amazon Bedrock Data Automation provides a catalog of sample blueprints out of the box. You can create a custom blueprint for your unique document types that aren’t predefined in the catalog. This solution uses two blueprints designed for different document types, as shown in the following screenshot:</p><ul><li><p>The catalog blueprint US-Bank-Check for check processing.</p></li><li><p>The custom blueprint benefit-claims-pharmacy-receipt-blueprint for pharmacy-specific receipts.</p></li></ul><p><img alt="System Architecture" src=../../images/blog-1-2.png></p><p>US-Bank-Check is a catalog blueprint provided out of the box by Amazon Bedrock Data Automation. The custom blueprint benefit-claims-pharmacy-receipt-blueprint is created using an AWS CloudFormation template to handle pharmacy receipt processing, addressing a specific document type that wasn’t available in the standard blueprint catalog. The benefit administrator wants to look for vendor-specific information such as name, address, and phone details for benefits claims processing. The custom blueprint schema contains natural language explanation of those fields, such as VendorName, VendorAddress, VendorPhone, and additional fields, explaining what the field represents, expected data types, and inference type for each extracted field (explained in Creating Blueprints for Extraction), as shown in the following screenshot.</p><p><img alt="System Architecture" src=../../images/blog-1-3.png></p><p>The two blueprints are added to the Amazon Bedrock Data Automation project. An Amazon Bedrock Data Automation project is a grouping of both standard and custom blueprints that you can use to process different types of files (like documents, audio, and images) using specific configuration settings, where you can control what kind of information you want to extract from each file type. When the project is invoked asynchronously, it automatically applies the appropriate blueprint, extracts information such as confidence scores and bounding box details for each field, and saves results in a separate S3 bucket. This intelligent classification alleviates the need for you to write complex document classification logic.</p><p>The following screenshot illustrates the document classification by the standard catalog blueprint US-Bank-Check.</p><p><img alt="System Architecture" src=../../images/blog-1-4.jpg></p><p>The following screenshot shows the document classification by the custom blueprint
benefit-claims-pharmacy-receipt-blueprint.</p><p><img alt="System Architecture" src=../../images/blog-1-5.png></p><h2 id=validation>Validation</h2><p>With the data extracted, the system moves to the validation and decision-making process using the business rules specific to each document type.</p><p>The business rules are documented in standard operating procedure documents (AnyCompany Benefit Checks Standard Operating procedure.docx and AnyCompany Benefit Claims Standard Operating procedure.docx) and uploaded to an S3 bucket. Then the system creates a knowledge base for Amazon Bedrock with the S3 bucket as the source, as shown in the following screenshot.</p><p><img alt="System Architecture" src=../../images/blog-1-6.jpg></p><p>When the extracted Amazon Bedrock Data Automation results are saved to the configured S3 bucket, a Lambda function is triggered automatically. Based on the business rules retrieved from the knowledge base for the specific document type and the extracted Amazon Bedrock Data Automation output, an Amazon Nova Lite large langue model (LLM) makes the automated approve/deny decision for claims.</p><p>The following screenshot shows the benefit claim adjudication automated decision for US-Bank-Check.</p><p><img alt="System Architecture" src=../../images/blog-1-7.png></p><p>The following screenshot shows the benefit claim adjudication automated decision for benefit-claims-pharmacy-receipt-blueprint.</p><p><img alt="System Architecture" src=../../images/blog-1-8.png></p><h3 id=integration>Integration</h3><p>The system seamlessly integrates with existing business processes.</p><p>When validation is complete, an event is pushed to Amazon EventBridge, which triggers a Lambda function for downstream integration. In this implementation, we use an Amazon DynamoDB table and Amazon Simple Notification Service (Amazon SNS) email for downstream integration. A DynamoDB table is created as part of the deployment stack, which is used to populate details including document classification, extracted data, and automated decision. An email notification is sent for both check and receipts after the final decision is made by the system. The following screenshot shows an example email for pharmacy receipt approval.</p><p><img alt="System Architecture" src=../../images/blog-1-9.jpeg></p><p>This flexible architecture helps you integrate with your existing applications through internal APIs or events to update claim status or trigger additional workflows when validation fails.</p><h2 id=reducing-manual-effort-through-intelligent-business-rules-management>Reducing manual effort through intelligent business rules management</h2><p>Beyond automating document processing, this solution addresses a common operational challenge: Traditionally, customers must write and maintain code for handling business rules around claims adjudication and processing. Every business rule change requires development effort and code updates, slowing time-to-market and increasing maintenance overhead.</p><p>Our approach converts business rules and standard operating procedures (SOPs) into knowledge bases using Amazon Bedrock Knowledge Bases, which you can use for automated decision-making. This approach can dramatically reduce time-to-market when business rules change, because updates can be made through knowledge management rather than code deployment.</p><p>In the following sections, we walk you through the steps to deploy the solution to your own AWS account.</p><hr><h2 id=prerequisites>Prerequisites</h2><p>To implement the solution provided in this post, you must have the following:</p><ul><li>An AWS account</li><li>Access to Amazon Titan Text Embeddings V2 and Amazon Nova Lite foundation models (FMs) enabled in Amazon Bedrock</li></ul><p>This solution uses Python 3.13 with Boto3 1.38. or later version, and the AWS Serverless Application Model Command
Line Interface (AWS SAM CLI) version 1.138.0. We assume that you have installed these in your local machine already. If not, refer to the following instructions:</p><ul><li>Python 3.13 installation</li><li>Install the AWS SAM CLI</li></ul><hr><h2 id=set-up-code-in-your-local-machine>Set up code in your local machine</h2><p>To set up the code, clone the GitHub repository. After you have cloned the repository to your local machine, the project folder structure will look like the following code, as mentioned in the README file:</p><p><img alt="System Architecture" src=../../images/blog-1-10.png></p><h2 id=deploy-the-solution-in-your-account>Deploy the solution in your account</h2><p>The sample code comes with a CloudFormation template that creates necessary resources. To deploy the solution in your account, follow the deployment instructions in the README file.</p><h2 id=clean-up>Clean up</h2><p>Deploying this solution in your account will incur costs. Follow the cleanup instructions in the README file to avoid charges when you are done.</p><h2 id=conclusion>Conclusion</h2><p>Benefits administration companies can significantly enhance their operations by automating claims processing using the solution outlined in this post. This strategic approach directly addresses the industry’s core challenges and can deliver several key advantages:</p><ul><li><p>Enhanced processing efficiency through accelerated claims resolution times, reduced manual error rates, and higher straight-through processing rates that minimize the frustrating delays and manual rework plaguing legacy systems
Streamlined document integration and fraud detection capabilities, where adding new supporting documents becomes seamless through new Amazon Bedrock Data Automation blueprints, while AI-powered analytics identify suspicious patterns without delaying legitimate claims, avoiding traditional months-long development cycles and reducing costly fraud, waste, and abuse</p></li><li><p>Agile business rule management that enables rapid adaptation to changing HIPAA and ERISA requirements and modification of business rules, significantly reducing administrative costs and time-to-market while improving scalability and integration with existing HRIS and claims, ultimately enhancing employee satisfaction, strengthening provider relationships, and supporting competitive benefits offerings that are crucial for talent retention and employer branding</p></li></ul><p>To get started with this solution, refer to the GitHub repo. For more information about Amazon Bedrock Data Automation, refer to Transform unstructured data into meaningful insights using Amazon Bedrock Data Automation and try the Document Processing Using Amazon Bedrock Data Automation workshop.</p><footer class=footline></footer></div></div><div id=navigation><a class="nav nav-prev" href=../../3-blogstranslated/ title="Translated Blogs"><i class="fa fa-chevron-left"></i></a>
<a class="nav nav-next" href=../../3-blogstranslated/3.2-blog2/ title="Blog 2" style=margin-right:0><i class="fa fa-chevron-right"></i></a></div></section><div style=left:-1000px;overflow:scroll;position:absolute;top:-1000px;border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px><div style=border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px></div></div><script src=../../js/clipboard.min.js?1765297479></script><script src=../../js/perfect-scrollbar.min.js?1765297479></script><script src=../../js/perfect-scrollbar.jquery.min.js?1765297479></script><script src=../../js/jquery.sticky.js?1765297479></script><script src=../../js/featherlight.min.js?1765297479></script><script src=../../js/highlight.pack.js?1765297479></script><script>hljs.initHighlightingOnLoad()</script><script src=../../js/modernizr.custom-3.6.0.js?1765297479></script><script src=../../js/learn.js?1765297479></script><script src=../../js/hugo-learn.js?1765297479></script><link href=../../mermaid/mermaid.css?1765297479 rel=stylesheet><script src=../../mermaid/mermaid.js?1765297479></script><script>mermaid.initialize({startOnLoad:!0})</script><script>(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,(e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date),(i=t.createElement(n),a=t.getElementsByTagName(n)[0]),i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-158079754-2","auto"),ga("send","pageview")</script></body></html>